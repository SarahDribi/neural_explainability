[INFO] Project root: /home/goofy/stage/modified-oval-bab/clean
[INFO] Experiments dir: /home/goofy/stage/modified-oval-bab/clean/experiments/coarsen_locally+20250812_122905
[INFO] Selected dir: clean/selected_images_explain_vcomp/L1+20250812_095334
[INFO] Using device: cpu
Loading ONNX model...
[INFO] Using label=1, epsilon=0.024901855468749998
[INFO] tensor shape=(784,), dtype=torch.float32, device=cpu
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.001313924789428711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006947517395019531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005645751953125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0005958080291748047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00067138671875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009195804595947266

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
/home/goofy/stage/modified-oval-bab/plnn/anderson_linear_approximation.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(c_b, device=device).unsqueeze(0)
Coarsening NAP:   0%|          | 0/20 [00:00<?, ?neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.001634836196899414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0023453235626220703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002643585205078125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003069162368774414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014994144439697266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009975433349609375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[Coarsening ]Neuron (0,0) timed out during verification.
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008153915405273438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.000827789306640625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0006392002105712891
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008478164672851562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00362396240234375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001001119613647461

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[Coarsening ]Neuron (0,1) timed out during verification.
Coarsening NAP:  10%|#         | 2/20 [00:00<00:01, 14.32neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.002862691879272461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005431175231933594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.000640869140625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006194114685058594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0006692409515380859
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008070468902587891

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[Coarsening ]Neuron (0,2) timed out during verification.
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.00099945068359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.00086212158203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009527206420898438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010950565338134766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012726783752441406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011792182922363281

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[Coarsening ]Neuron (0,3) timed out during verification.
Coarsening NAP:  20%|##        | 4/20 [00:00<00:01, 13.78neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0030465126037597656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0011043548583984375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011026859283447266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0016326904296875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014531612396240234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001714468002319336

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[Coarsening ]Neuron (0,4) timed out during verification.
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0012047290802001953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0008411407470703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012464523315429688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011196136474609375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00127410888671875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014996528625488281

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[Coarsening ]Neuron (0,5) timed out during verification.
Coarsening NAP:  30%|###       | 6/20 [00:00<00:01, 12.55neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009832382202148438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0011265277862548828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001039743423461914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013980865478515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018036365509033203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.005837678909301758

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[Coarsening ]Neuron (0,6) timed out during verification.
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009970664978027344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0011756420135498047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008103847503662109
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008492469787597656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008761882781982422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010383129119873047

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[Coarsening ]Neuron (0,7) timed out during verification.
Coarsening NAP:  40%|####      | 8/20 [00:00<00:00, 12.13neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0011026859283447266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009999275207519531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0006580352783203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010454654693603516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0019724369049072266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011110305786132812

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[Coarsening ]Neuron (0,8) timed out during verification.
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0022323131561279297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006623268127441406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005867481231689453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006303787231445312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.000766754150390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011858940124511719

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[Coarsening ]Neuron (0,9) timed out during verification.
Coarsening NAP:  50%|#####     | 10/20 [00:00<00:00, 12.37neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009584426879882812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006659030914306641
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0006754398345947266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007755756378173828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007202625274658203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008172988891601562

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[Coarsening ]Neuron (1,0) timed out during verification.
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0027952194213867188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.001966238021850586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0025017261505126953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0026345252990722656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0021648406982421875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016484260559082031

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[Coarsening ]Neuron (1,1) timed out during verification.
Coarsening NAP:  60%|######    | 12/20 [00:00<00:00, 12.39neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0007860660552978516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006151199340820312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0006334781646728516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006330013275146484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018112659454345703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0042459964752197266

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[Coarsening ]Neuron (1,2) timed out during verification.
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.003137826919555664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0035696029663085938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016283988952636719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014095306396484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001237630844116211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001331329345703125

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[Coarsening ]Neuron (1,3) timed out during verification.
Coarsening NAP:  70%|#######   | 14/20 [00:01<00:00, 11.89neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009663105010986328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0007967948913574219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001142740249633789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001130819320678711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011560916900634766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012848377227783203

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[Coarsening ]Neuron (1,4) timed out during verification.
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.001310586929321289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0010557174682617188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009391307830810547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0015211105346679688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012400150299072266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013031959533691406

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[Coarsening ]Neuron (1,5) timed out during verification.
Coarsening NAP:  80%|########  | 16/20 [00:01<00:00, 12.07neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0028641223907470703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006196498870849609
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0006442070007324219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007069110870361328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009317398071289062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001230001449584961

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[Coarsening ]Neuron (1,6) timed out during verification.
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008609294891357422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005824565887451172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005545616149902344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0005915164947509766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007526874542236328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007534027099609375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[Coarsening ]Neuron (1,7) timed out during verification.
Coarsening NAP:  90%|######### | 18/20 [00:01<00:00, 12.27neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0011951923370361328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0021851062774658203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.005153656005859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004081249237060547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002573251724243164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0025815963745117188

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[Coarsening ]Neuron (1,8) timed out during verification.
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008409023284912109
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005834102630615234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005526542663574219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007135868072509766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007779598236083984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007684230804443359

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
[Coarsening ]Neuron (1,9) timed out during verification.
Coarsening NAP: 100%|##########| 20/20 [00:01<00:00,  8.65neuron/s]Coarsening NAP: 100%|##########| 20/20 [00:01<00:00, 10.88neuron/s]
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0014696121215820312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006375312805175781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008633136749267578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007343292236328125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008716583251953125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009629726409912109

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0037653446197509766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0016951560974121094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0020716190338134766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0022568702697753906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0027060508728027344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0028748512268066406

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009627342224121094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006570816040039062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005774497985839844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006978511810302734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007882118225097656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.000789642333984375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.001016378402709961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.004041433334350586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0022611618041992188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0020830631256103516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0023338794708251953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0027310848236083984

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008568763732910156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006678104400634766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00070953369140625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008113384246826172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007176399230957031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007600784301757812

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008323192596435547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005786418914794922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00063323974609375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00061798095703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007877349853515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007767677307128906

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0020415782928466797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0008504390716552734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009429454803466797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011034011840820312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012831687927246094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013806819915771484

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.001316070556640625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0010247230529785156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001138925552368164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0020542144775390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010673999786376953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009191036224365234

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0013206005096435547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005915164947509766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0006394386291503906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007803440093994141
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007166862487792969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008273124694824219

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008366107940673828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006864070892333984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0006339550018310547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006690025329589844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008447170257568359
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008203983306884766

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008451938629150391
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006120204925537109
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005848407745361328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006740093231201172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007169246673583984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008916854858398438

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0026280879974365234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0025014877319335938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002137422561645508
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004152536392211914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014729499816894531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009386539459228516

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008895397186279297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009875297546386719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003179788589477539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0044705867767333984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004481077194213867
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0030739307403564453

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008790493011474609
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006241798400878906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005822181701660156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0005998611450195312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007240772247314453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019321441650390625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008857250213623047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005888938903808594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005450248718261719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006308555603027344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002400636672973633
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003493070602416992

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008313655853271484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005140304565429688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005893707275390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0026824474334716797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0027551651000976562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0028214454650878906

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0051577091217041016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0028214454650878906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003088712692260742
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010187625885009766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009291172027587891
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001209259033203125

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009081363677978516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0010499954223632812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014204978942871094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008115768432617188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007123947143554688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008189678192138672

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0019092559814453125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005629062652587891
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.000591278076171875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006117820739746094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007257461547851562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008144378662109375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.00416254997253418
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0007576942443847656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009670257568359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008111000061035156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007193088531494141
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008087158203125

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.00096893310546875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.000537872314453125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0006890296936035156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006480216979980469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007252693176269531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008745193481445312

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008080005645751953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006403923034667969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0006341934204101562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006296634674072266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0006678104400634766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.000820159912109375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.000949859619140625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006535053253173828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0006470680236816406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006921291351318359
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0006725788116455078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008459091186523438

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0012345314025878906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005583763122558594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0007176399230957031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006811618804931641
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007040500640869141
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009181499481201172

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008416175842285156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0007786750793457031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005829334259033203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007152557373046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001008749008178711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014543533325195312

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.002206563949584961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0018198490142822266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002207517623901367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0022499561309814453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0026721954345703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002481222152709961

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008318424224853516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005965232849121094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005929470062255859
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006186962127685547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007300376892089844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008287429809570312

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009417533874511719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0007936954498291016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005857944488525391
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006039142608642578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007390975952148438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009369850158691406

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.006388425827026367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005781650543212891
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005791187286376953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006022453308105469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007264614105224609
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011060237884521484

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009469985961914062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0033452510833740234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004293203353881836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002910137176513672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001310110092163086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013229846954345703

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008444786071777344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005502700805664062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005655288696289062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0005922317504882812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007319450378417969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008611679077148438

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0010046958923339844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006480216979980469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012197494506835938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008668899536132812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007059574127197266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008833408355712891

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.001386880874633789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0011692047119140625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012454986572265625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013570785522460938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013308525085449219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001527547836303711

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008380413055419922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006308555603027344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.000583648681640625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006289482116699219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007812976837158203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007965564727783203

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009281635284423828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006191730499267578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005600452423095703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006139278411865234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007860660552978516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007815361022949219

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.002158641815185547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005345344543457031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0006029605865478516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0005967617034912109
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0019826889038085938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004438638687133789

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008869171142578125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005495548248291016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0007252693176269531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006456375122070312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008654594421386719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007822513580322266

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008330345153808594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0007226467132568359
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005521774291992188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.000598907470703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007238388061523438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008893013000488281

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.008557796478271484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0017888545989990234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0017962455749511719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0028982162475585938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009043216705322266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009112358093261719

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0007886886596679688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0020685195922851562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002019643783569336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002272367477416992
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0025637149810791016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010485649108886719

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009038448333740234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0014302730560302734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002119779586791992
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0021238327026367188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0032546520233154297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002885103225708008

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009360313415527344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009508132934570312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014371871948242188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.007506370544433594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003054380416870117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018558502197265625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009577274322509766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.00067901611328125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005578994750976562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0005981922149658203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007236003875732422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007555484771728516

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0024492740631103516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.000591278076171875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005481243133544922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0005948543548583984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007205009460449219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007522106170654297

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.007953405380249023
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0024890899658203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0024116039276123047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008227825164794922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008547306060791016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008187294006347656

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0010433197021484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.004460334777832031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004763364791870117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012295246124267578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013413429260253906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015594959259033203

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.000911712646484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005850791931152344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0006263256072998047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006241798400878906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0006711483001708984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014209747314453125

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0019176006317138672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0008680820465087891
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008144378662109375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010190010070800781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001039743423461914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012526512145996094

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0007543563842773438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006225109100341797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0006170272827148438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006082057952880859
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007143020629882812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007989406585693359

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008580684661865234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005898475646972656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005540847778320312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0005970001220703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007700920104980469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007722377777099609

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.005145072937011719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0018267631530761719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001837015151977539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0026433467864990234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0029706954956054688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010342597961425781

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009303092956542969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005955696105957031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005521774291992188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006067752838134766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007698535919189453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009381771087646484

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0012392997741699219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005860328674316406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.000530242919921875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0005838871002197266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007925033569335938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009789466857910156

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009303092956542969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.00072479248046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005519390106201172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007874965667724609
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0006816387176513672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007569789886474609

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.006585121154785156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.002079010009765625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0021293163299560547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0027647018432617188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0021233558654785156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001608133316040039

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0011053085327148438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005471706390380859
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0006041526794433594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007748603820800781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0006837844848632812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007479190826416016

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.004824161529541016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.002305269241333008
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0024733543395996094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0026493072509765625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010039806365966797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010151863098144531

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008981227874755859
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006258487701416016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005428791046142578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.000591278076171875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008378028869628906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007653236389160156

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.001422882080078125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0008904933929443359
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010361671447753906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009846687316894531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012302398681640625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016431808471679688

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0015168190002441406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005931854248046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005624294281005859
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007021427154541016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0006766319274902344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007979869842529297

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.008168458938598633
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009543895721435547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009598731994628906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009307861328125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001108407974243164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010840892791748047

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009641647338867188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005626678466796875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005483627319335938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007715225219726562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008251667022705078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008687973022460938

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0010023117065429688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009884834289550781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001264810562133789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011982917785644531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012514591217041016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015578269958496094

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0007352828979492188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.000576019287109375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005486011505126953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0005972385406494141
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007615089416503906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007581710815429688

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.009962081909179688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0027725696563720703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002482175827026367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002505779266357422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0025582313537597656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015857219696044922

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008568763732910156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006377696990966797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0006053447723388672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006005764007568359
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.000720977783203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007517337799072266

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0013892650604248047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006856918334960938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0006940364837646484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009174346923828125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012676715850830078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010335445404052734

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.014687299728393555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0015635490417480469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001110076904296875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011076927185058594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007333755493164062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007529258728027344

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0015797615051269531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0016105175018310547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001837015151977539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0022084712982177734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0029287338256835938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001535654067993164

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008358955383300781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0007989406585693359
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008265972137451172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010471343994140625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010459423065185547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011525154113769531

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008296966552734375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005686283111572266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005533695220947266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0005981922149658203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007283687591552734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008077621459960938

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0047495365142822266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0015454292297363281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002017498016357422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0028221607208251953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002437114715576172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009741783142089844

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008931159973144531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005424022674560547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005519390106201172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006563663482666016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0006763935089111328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009043216705322266

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.001678466796875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005726814270019531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005359649658203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006420612335205078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0006723403930664062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007650852203369141

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0010113716125488281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006830692291259766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008246898651123047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010666847229003906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008170604705810547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007748603820800781

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008409023284912109
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005843639373779297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005426406860351562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0005922317504882812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007774829864501953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007593631744384766

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009281635284423828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005841255187988281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005478858947753906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006577968597412109
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007321834564208984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008409023284912109

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008857250213623047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005784034729003906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005812644958496094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006010532379150391
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007379055023193359
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007555484771728516

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.001001119613647461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005447864532470703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00072479248046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007050037384033203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009315013885498047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011148452758789062

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009272098541259766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005900859832763672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005524158477783203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0005979537963867188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007734298706054688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008215904235839844

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.004960298538208008
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0016732215881347656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003115415573120117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0021653175354003906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018837451934814453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009846687316894531

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008687973022460938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005757808685302734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005383491516113281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006544589996337891
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008924007415771484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007634162902832031

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.003138303756713867
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005414485931396484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005548000335693359
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006456375122070312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007119178771972656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016982555389404297

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0007991790771484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005800724029541016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005521774291992188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0005922317504882812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007059574127197266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007677078247070312

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008397102355957031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005815029144287109
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0026459693908691406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00217437744140625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003194570541381836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012600421905517578

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0011272430419921875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0016417503356933594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009050369262695312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011065006256103516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009942054748535156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012624263763427734

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0014348030090332031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0017590522766113281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0019097328186035156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002240419387817383
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002515554428100586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0028197765350341797

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.008789777755737305
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0008490085601806641
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009210109710693359
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010929107666015625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011317729949951172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001264333724975586

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.00089263916015625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0008041858673095703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010001659393310547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001050710678100586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001094818115234375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001119852066040039

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.014069795608520508
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0017762184143066406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0020825862884521484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0023021697998046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0025148391723632812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00302886962890625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008537769317626953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006704330444335938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008437633514404297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008280277252197266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008101463317871094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009834766387939453

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009224414825439453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005941390991210938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005619525909423828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0005993843078613281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.000713348388671875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008304119110107422

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0030944347381591797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.00164031982421875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0028879642486572266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010972023010253906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012116432189941406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012311935424804688

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009105205535888672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005509853363037109
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005972385406494141
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006017684936523438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009794235229492188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004230499267578125

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008633136749267578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0017702579498291016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015881061553955078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001004934310913086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009603500366210938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010004043579101562

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008332729339599609
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005433559417724609
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005621910095214844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006246566772460938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0038356781005859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002023458480834961

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0021593570709228516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005979537963867188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0006239414215087891
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006074905395507812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0006670951843261719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008039474487304688

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.001049041748046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005168914794921875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0006091594696044922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006232261657714844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007302761077880859
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008051395416259766

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008618831634521484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005803108215332031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00054931640625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007708072662353516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007495880126953125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008361339569091797

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008575916290283203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005779266357421875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0006802082061767578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006165504455566406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0006732940673828125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008080005645751953

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0008778572082519531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0005266666412353516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005326271057128906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009353160858154297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007147789001464844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0008745193481445312

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[Stochastic] Coarsened neurons: 0 | Remaining %: 100.00 | successful_iterations=0
[INFO] Coarsened NAP (stochastic): [[1, 1, 1, 0, 0, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 0, 1, 1, 0, 1]]
[INFO] Original NAP:               [[1, 1, 1, 0, 0, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 0, 1, 1, 0, 1]]
[OK] Results saved to /home/goofy/stage/modified-oval-bab/clean/experiments/coarsen_locally+20250812_122905/results.json
