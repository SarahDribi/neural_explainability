[INFO] Project root: /home/goofy/stage/modified-oval-bab/clean
[INFO] Experiments dir: /home/goofy/stage/modified-oval-bab/clean/experiments/first_script+20250812_073628
Loading ONNX model...
[INFO] Searching for NAP-exclusive robust inputs for label 1
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02957606315612793
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022640228271484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016198158264160156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0022356510162353516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0037174224853515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00428462028503418

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-38.2063, max=0.0000 | UB min=0.0000, max=44.5517
  Layer 2: LB min=0.0000, max=0.0000 | UB min=61.4856, max=92.1457
  Layer 3: LB min=-186.2676, max=226.6184 | UB min=106.2623, max=696.5044
  Layer 4: LB min=-266.4318, max=291.3767 | UB min=207.2865, max=677.8749
  Layer 5: LB min=-324.7933, max=369.6063 | UB min=273.1964, max=858.1282
  Layer 6: LB min=-138.0939, max=197.4918 | UB min=581.7582, max=677.8749
  Layer 7: LB min=-522.4902, max=-522.4902 | UB min=150.7498, max=150.7498
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
/home/goofy/stage/modified-oval-bab/plnn/anderson_linear_approximation.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(c_b, device=device).unsqueeze(0)
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027456998825073242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.018635034561157227
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011892318725585938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010724067687988281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011577606201171875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012679100036621094

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-19.5789, max=0.0000 | UB min=0.0000, max=24.5340
  Layer 2: LB min=0.0000, max=0.0000 | UB min=31.7551, max=48.8659
  Layer 3: LB min=-98.0328, max=130.2761 | UB min=53.1063, max=373.3441
  Layer 4: LB min=-137.8324, max=161.3686 | UB min=106.5421, max=364.7351
  Layer 5: LB min=-167.8569, max=204.7671 | UB min=141.0503, max=456.5300
  Layer 6: LB min=-71.1136, max=113.3874 | UB min=301.0940, max=364.7351
  Layer 7: LB min=-268.6675, max=-268.6675 | UB min=77.7889, max=77.7889
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.011531829833984375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.007674217224121094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012607574462890625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0017147064208984375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001972675323486328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018925666809082031

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-10.1752, max=0.0000 | UB min=0.0000, max=14.9748
  Layer 2: LB min=0.0000, max=0.0000 | UB min=16.0744, max=26.9094
  Layer 3: LB min=-51.7494, max=82.9030 | UB min=24.6743, max=206.4796
  Layer 4: LB min=-69.3198, max=96.4783 | UB min=53.6842, max=201.8145
  Layer 5: LB min=-84.5175, max=122.1129 | UB min=70.8192, max=247.6732
  Layer 6: LB min=-35.3846, max=71.6351 | UB min=154.2362, max=201.8145
  Layer 7: LB min=-133.2466, max=-133.2466 | UB min=40.1720, max=40.1720
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.001085519790649414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.00089263916015625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001276254653930664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011696815490722656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012655258178710938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002888202667236328

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.3913, max=2.7620 | UB min=0.0000, max=10.8042
  Layer 2: LB min=0.0000, max=0.1918 | UB min=8.5169, max=16.1742
  Layer 3: LB min=-27.3138, max=58.5710 | UB min=7.0556, max=116.1566
  Layer 4: LB min=-31.4842, max=64.3349 | UB min=24.1535, max=111.2119
  Layer 5: LB min=-37.9468, max=78.6345 | UB min=31.7034, max=134.0001
  Layer 6: LB min=-13.9624, max=49.0524 | UB min=74.3105, max=111.2119
  Layer 7: LB min=-56.2513, max=-56.2513 | UB min=23.6666, max=23.6666
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03329920768737793
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028593778610229492
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015382766723632812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0017650127410888672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0036897659301757812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001825094223022461

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.9753, max=4.5555 | UB min=0.0000, max=8.6876
  Layer 2: LB min=0.0000, max=3.6924 | UB min=4.7845, max=11.7993
  Layer 3: LB min=-16.9343, max=38.4209 | UB min=-1.2262, max=64.4316
  Layer 4: LB min=-13.8842, max=43.5778 | UB min=10.2120, max=63.2194
  Layer 5: LB min=-15.0651, max=50.4475 | UB min=13.2903, max=73.8129
  Layer 6: LB min=2.3355, max=33.6827 | UB min=36.7107, max=63.2194
  Layer 7: LB min=-17.1342, max=-17.1342 | UB min=12.7580, max=12.7580
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.022732019424438477
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.013042926788330078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012974739074707031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013670921325683594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001523733139038086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015714168548583984

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.0873, max=5.4564 | UB min=0.0000, max=7.6248
  Layer 2: LB min=0.0000, max=5.8195 | UB min=2.9000, max=9.7929
  Layer 3: LB min=-12.1650, max=23.1944 | UB min=-5.0337, max=35.6010
  Layer 4: LB min=-6.5691, max=28.5729 | UB min=1.9727, max=37.4217
  Layer 5: LB min=-5.0981, max=32.7846 | UB min=5.6811, max=42.1726
  Layer 6: LB min=5.1065, max=20.7711 | UB min=20.4170, max=34.9953
  Layer 7: LB min=-3.0407, max=-3.0407 | UB min=9.2485, max=9.2485
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0281219482421875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01573657989501953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010766983032226562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010271072387695312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012557506561279297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001110076904296875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.4145, max=5.0058 | UB min=0.0000, max=8.1562
  Layer 2: LB min=0.0000, max=4.7616 | UB min=3.8929, max=10.7923
  Layer 3: LB min=-14.5459, max=31.8937 | UB min=-3.1567, max=50.9381
  Layer 4: LB min=-10.1272, max=37.6573 | UB min=5.9354, max=51.2101
  Layer 5: LB min=-9.8099, max=42.5966 | UB min=9.1807, max=58.6595
  Layer 6: LB min=4.6498, max=28.9415 | UB min=28.1499, max=50.6645
  Layer 7: LB min=-9.5092, max=-9.5092 | UB min=10.8886, max=10.8886
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03898167610168457
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0319666862487793
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014503002166748047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00825810432434082
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004264116287231445
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014162063598632812

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.2509, max=5.2311 | UB min=0.0000, max=7.8905
  Layer 2: LB min=0.0000, max=5.2907 | UB min=3.4694, max=10.2912
  Layer 3: LB min=-13.3392, max=27.6511 | UB min=-4.0974, max=43.3854
  Layer 4: LB min=-8.3352, max=33.3368 | UB min=3.8918, max=44.4800
  Layer 5: LB min=-7.3571, max=37.7515 | UB min=7.3940, max=50.4287
  Layer 6: LB min=3.4405, max=25.1173 | UB min=24.1854, max=43.0745
  Layer 7: LB min=-6.1616, max=-6.1616 | UB min=10.0650, max=10.0650
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03318309783935547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023626327514648438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0018668174743652344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.012145280838012695
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018291473388671875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001739501953125

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.1691, max=5.3438 | UB min=0.0000, max=7.7576
  Layer 2: LB min=0.0000, max=5.5551 | UB min=3.1938, max=10.0418
  Layer 3: LB min=-12.7281, max=25.4384 | UB min=-4.5655, max=39.5008
  Layer 4: LB min=-7.4472, max=30.9574 | UB min=2.8872, max=40.9503
  Layer 5: LB min=-6.1876, max=35.2693 | UB min=6.5355, max=46.2741
  Layer 6: LB min=4.2688, max=22.9451 | UB min=22.2703, max=39.0274
  Layer 7: LB min=-4.5736, max=-4.5736 | UB min=9.6609, max=9.6609
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.015386819839477539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023203372955322266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.012451410293579102
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0015747547149658203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016694068908691406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017979145050048828

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.1282, max=5.4001 | UB min=0.0000, max=7.6912
  Layer 2: LB min=0.0000, max=5.6873 | UB min=3.0468, max=9.9172
  Layer 3: LB min=-12.4315, max=24.3213 | UB min=-4.7997, max=37.5508
  Layer 4: LB min=-7.0062, max=29.7668 | UB min=2.4054, max=39.1860
  Layer 5: LB min=-5.6236, max=34.0313 | UB min=6.1073, max=44.2083
  Layer 6: LB min=4.6920, max=21.8584 | UB min=21.3300, max=37.0068
  Layer 7: LB min=-3.7962, max=-3.7962 | UB min=9.4534, max=9.4534
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.015963077545166016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.010278701782226562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013859272003173828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013654232025146484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004420042037963867
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019483566284179688

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.1077, max=5.4282 | UB min=0.0000, max=7.6580
  Layer 2: LB min=0.0000, max=5.7534 | UB min=2.9734, max=9.8550
  Layer 3: LB min=-12.2981, max=23.7579 | UB min=-4.9167, max=36.5759
  Layer 4: LB min=-6.7875, max=29.1699 | UB min=2.1876, max=38.3039
  Layer 5: LB min=-5.3593, max=33.4122 | UB min=5.8941, max=43.1856
  Layer 6: LB min=4.8979, max=21.3149 | UB min=20.8719, max=36.0010
  Layer 7: LB min=-3.4170, max=-3.4170 | UB min=9.3516, max=9.3516
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.005432605743408203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022585391998291016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0033845901489257812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003012418746948242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015506744384765625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013647079467773438

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.0975, max=5.4423 | UB min=0.0000, max=7.6414
  Layer 2: LB min=0.0000, max=5.7864 | UB min=2.9367, max=9.8239
  Layer 3: LB min=-12.2315, max=23.4761 | UB min=-4.9752, max=36.0884
  Layer 4: LB min=-6.6783, max=28.8714 | UB min=2.0801, max=37.8628
  Layer 5: LB min=-5.2285, max=33.0981 | UB min=5.7876, max=42.6787
  Layer 6: LB min=5.0018, max=21.0430 | UB min=20.6441, max=35.4982
  Layer 7: LB min=-3.2286, max=-3.2286 | UB min=9.3002, max=9.3002
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02148914337158203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.012215614318847656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00573420524597168
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012276172637939453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.006757259368896484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003584623336791992

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.1026, max=5.4353 | UB min=0.0000, max=7.6497
  Layer 2: LB min=0.0000, max=5.7699 | UB min=2.9550, max=9.8395
  Layer 3: LB min=-12.2648, max=23.6170 | UB min=-4.9460, max=36.3322
  Layer 4: LB min=-6.7329, max=29.0206 | UB min=2.1338, max=38.0834
  Layer 5: LB min=-5.2938, max=33.2550 | UB min=5.8408, max=42.9321
  Layer 6: LB min=4.9497, max=21.1790 | UB min=20.7579, max=35.7496
  Layer 7: LB min=-3.3227, max=-3.3227 | UB min=9.3259, max=9.3259
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01940464973449707
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01699519157409668
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004348039627075195
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0032761096954345703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0024220943450927734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011563301086425781

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.1001, max=5.4388 | UB min=0.0000, max=7.6455
  Layer 2: LB min=0.0000, max=5.7782 | UB min=2.9458, max=9.8317
  Layer 3: LB min=-12.2482, max=23.5466 | UB min=-4.9606, max=36.2103
  Layer 4: LB min=-6.7056, max=28.9460 | UB min=2.1070, max=37.9731
  Layer 5: LB min=-5.2611, max=33.1765 | UB min=5.8142, max=42.8054
  Layer 6: LB min=4.9757, max=21.1110 | UB min=20.7010, max=35.6239
  Layer 7: LB min=-3.2757, max=-3.2757 | UB min=9.3131, max=9.3131
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.009805917739868164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.011688470840454102
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0029175281524658203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003544330596923828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011453628540039062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010356903076171875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.0975, max=5.4423 | UB min=0.0000, max=7.6414
  Layer 2: LB min=0.0000, max=5.7864 | UB min=2.9367, max=9.8239
  Layer 3: LB min=-12.2315, max=23.4761 | UB min=-4.9752, max=36.0884
  Layer 4: LB min=-6.6783, max=28.8714 | UB min=2.0801, max=37.8628
  Layer 5: LB min=-5.2285, max=33.0981 | UB min=5.7876, max=42.6787
  Layer 6: LB min=5.0018, max=21.0430 | UB min=20.6441, max=35.4982
  Layer 7: LB min=-3.2286, max=-3.2286 | UB min=9.3002, max=9.3002
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.003939151763916016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009641647338867188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0007996559143066406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.000843048095703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0024347305297851562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017085075378417969
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.005864143371582031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0023725032806396484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0028715133666992188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.013744354248046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002262115478515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012440681457519531
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01315927505493164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023095130920410156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0031075477600097656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.007500410079956055
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0057489871978759766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004211902618408203
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02089691162109375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.005884647369384766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004119396209716797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.005637645721435547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0048313140869140625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017480850219726562
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.018764495849609375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01648402214050293
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0028612613677978516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.008611440658569336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0046956539154052734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016336441040039062
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02031087875366211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023694753646850586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.013917684555053711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00478816032409668
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002696514129638672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014309883117675781
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.010977506637573242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017227649688720703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.009222269058227539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.006392478942871094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001361846923828125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001544952392578125
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.015000343322753906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.004886627197265625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0030012130737304688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.009728431701660156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0026750564575195312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011973381042480469
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.006010532379150391
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.011418819427490234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.005406856536865234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0039288997650146484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0045588016510009766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001996278762817383
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.025842666625976562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.018442392349243164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003380298614501953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0036449432373046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005163908004760742
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.005203962326049805
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0010209083557128906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.013974189758300781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010828971862792969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008795261383056641
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009605884552001953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009491443634033203
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.011586666107177734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.016895055770874023
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002795696258544922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003340005874633789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004213571548461914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004302024841308594
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03789782524108887
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02730107307434082
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.009398937225341797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00482177734375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0040531158447265625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004376649856567383
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03967785835266113
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03359413146972656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0031108856201171875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.013431072235107422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.008000373840332031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018463134765625
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.046007394790649414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.031883955001831055
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002973794937133789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.011605024337768555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016145706176757812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014417171478271484
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03574252128601074
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022598743438720703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011782646179199219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013833045959472656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013093948364257812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0032837390899658203

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-39.5999, max=0.0000 | UB min=0.0000, max=53.5932
  Layer 2: LB min=-60.0331, max=0.0000 | UB min=0.0000, max=91.8840
  Layer 3: LB min=-187.1825, max=227.6416 | UB min=104.5682, max=695.9067
  Layer 4: LB min=-267.9748, max=293.8542 | UB min=206.0851, max=673.6639
  Layer 5: LB min=-325.5292, max=370.8131 | UB min=272.5370, max=856.1168
  Layer 6: LB min=-138.4988, max=199.8865 | UB min=580.3879, max=673.6639
  Layer 7: LB min=-518.8408, max=-518.8408 | UB min=151.2998, max=151.2998
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.001501321792602539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0010154247283935547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016810894012451172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001436471939086914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001308441162109375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001247406005859375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-21.5364, max=0.0000 | UB min=0.0000, max=28.4712
  Layer 2: LB min=-32.6776, max=0.0000 | UB min=0.0000, max=48.0408
  Layer 3: LB min=-97.8626, max=132.3947 | UB min=49.2602, max=369.5156
  Layer 4: LB min=-137.8967, max=164.8900 | UB min=102.7827, max=347.6699
  Layer 5: LB min=-166.1539, max=205.8547 | UB min=137.2880, max=445.8500
  Layer 6: LB min=-70.5253, max=117.6321 | UB min=293.8061, max=347.6699
  Layer 7: LB min=-254.7386, max=-254.7386 | UB min=77.9647, max=77.9647
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02027297019958496
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.031514644622802734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010945796966552734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002122163772583008
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004578590393066406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002471446990966797

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-12.3054, max=1.6462 | UB min=0.0000, max=18.0809
  Layer 2: LB min=-18.4452, max=0.0000 | UB min=0.0000, max=28.7518
  Layer 3: LB min=-51.6135, max=84.6528 | UB min=16.1546, max=198.6285
  Layer 4: LB min=-66.7159, max=99.3392 | UB min=45.6466, max=180.6946
  Layer 5: LB min=-79.5378, max=120.9372 | UB min=63.5761, max=231.4058
  Layer 6: LB min=-33.9386, max=76.9234 | UB min=139.2529, max=180.6946
  Layer 7: LB min=-113.0977, max=-113.0977 | UB min=40.3706, max=40.3706
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0010077953338623047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006983280181884766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014109611511230469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007367134094238281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009477138519287109
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010056495666503906

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-7.6281, max=5.5818 | UB min=0.0000, max=13.9241
  Layer 2: LB min=-11.8155, max=6.6333 | UB min=0.0000, max=20.9872
  Layer 3: LB min=-29.0072, max=53.7404 | UB min=-1.3845, max=97.8952
  Layer 4: LB min=-30.1224, max=57.8184 | UB min=17.2337, max=91.3434
  Layer 5: LB min=-32.4934, max=65.8484 | UB min=26.9547, max=111.1042
  Layer 6: LB min=-9.6564, max=47.4890 | UB min=60.2424, max=91.3434
  Layer 7: LB min=-39.5947, max=-39.5947 | UB min=21.1724, max=21.1724
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03481435775756836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03835892677307129
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.012842655181884766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0025382041931152344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009744167327880859
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00110626220703125

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.2715, max=7.5504 | UB min=-0.6968, max=11.8346
  Layer 2: LB min=-8.7571, max=10.5367 | UB min=-2.1411, max=17.6296
  Layer 3: LB min=-20.8528, max=27.5665 | UB min=-9.1031, max=47.0800
  Layer 4: LB min=-14.5198, max=33.2112 | UB min=7.0353, max=47.3061
  Layer 5: LB min=-13.1736, max=32.2244 | UB min=12.3637, max=50.5310
  Layer 6: LB min=-1.5349, max=27.5665 | UB min=28.8473, max=47.0800
  Layer 7: LB min=-10.3452, max=-10.3452 | UB min=13.7558, max=13.7558
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028718948364257812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0421757698059082
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0030863285064697266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.016282320022583008
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.012786865234375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018558502197265625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-4.0932, max=8.5347 | UB min=-1.7123, max=10.7892
  Layer 2: LB min=-7.2327, max=12.3263 | UB min=-3.9835, max=15.9522
  Layer 3: LB min=-17.6856, max=16.7380 | UB min=-12.2094, max=26.2396
  Layer 4: LB min=-7.3761, max=20.4852 | UB min=2.9845, max=27.1070
  Layer 5: LB min=-5.5037, max=17.8077 | UB min=5.8343, max=26.2396
  Layer 6: LB min=3.1463, max=16.7380 | UB min=16.0575, max=26.2396
  Layer 7: LB min=0.8326, max=0.8326 | UB min=10.8141, max=10.8141
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01584601402282715
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.016947507858276367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002805948257446289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.01437687873840332
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0038204193115234375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002882719039916992

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-4.6823, max=8.0426 | UB min=-1.2046, max=11.3119
  Layer 2: LB min=-7.9942, max=11.4316 | UB min=-3.0536, max=16.7907
  Layer 3: LB min=-19.2645, max=22.1341 | UB min=-10.7364, max=36.5771
  Layer 4: LB min=-10.7305, max=26.8507 | UB min=4.8077, max=37.0308
  Layer 5: LB min=-9.1222, max=24.6227 | UB min=8.8659, max=37.2799
  Layer 6: LB min=0.2973, max=22.1341 | UB min=22.0774, max=36.5771
  Layer 7: LB min=-4.0331, max=-4.0331 | UB min=12.0406, max=12.0406
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02697920799255371
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02115917205810547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011973381042480469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011382102966308594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012249946594238281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014064311981201172

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-4.9769, max=7.7965 | UB min=-0.9507, max=11.5733
  Layer 2: LB min=-8.3756, max=10.9842 | UB min=-2.5967, max=17.2101
  Layer 3: LB min=-20.0580, max=24.8648 | UB min=-9.9522, max=41.8167
  Layer 4: LB min=-12.5456, max=30.0575 | UB min=5.8351, max=42.1496
  Layer 5: LB min=-11.0656, max=28.1787 | UB min=10.5495, max=43.4888
  Layer 6: LB min=-0.6106, max=24.8648 | UB min=25.3191, max=41.8167
  Layer 7: LB min=-6.9740, max=-6.9740 | UB min=12.8414, max=12.8414
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.031493425369262695
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.05532526969909668
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.012825489044189453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0028181076049804688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013284683227539062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015549659729003906

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.1242, max=7.6735 | UB min=-0.8238, max=11.7040
  Layer 2: LB min=-8.5664, max=10.7604 | UB min=-2.3688, max=17.4199
  Layer 3: LB min=-20.4551, max=26.2157 | UB min=-9.5277, max=44.4481
  Layer 4: LB min=-13.5436, max=31.6343 | UB min=6.4345, max=44.7253
  Layer 5: LB min=-12.1235, max=30.2016 | UB min=11.4553, max=47.0093
  Layer 6: LB min=-1.0727, max=26.2157 | UB min=27.0837, max=44.4481
  Layer 7: LB min=-8.6599, max=-8.6599 | UB min=13.3150, max=13.3150
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04087686538696289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03507280349731445
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001340627670288086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011017322540283203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00565338134765625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0020520687103271484

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.1978, max=7.6120 | UB min=-0.7603, max=11.7693
  Layer 2: LB min=-8.6617, max=10.6486 | UB min=-2.2549, max=17.5247
  Layer 3: LB min=-20.6539, max=26.8911 | UB min=-9.3154, max=45.7640
  Layer 4: LB min=-14.0343, max=32.4227 | UB min=6.7347, max=46.0153
  Layer 5: LB min=-12.6495, max=31.2130 | UB min=11.9091, max=48.7702
  Layer 6: LB min=-1.3038, max=26.8911 | UB min=27.9657, max=45.7640
  Layer 7: LB min=-9.5028, max=-9.5028 | UB min=13.5392, max=13.5392
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.023270368576049805
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0127105712890625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016181468963623047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011463165283203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010776519775390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004057645797729492

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.1610, max=7.6427 | UB min=-0.7920, max=11.7366
  Layer 2: LB min=-8.6141, max=10.7045 | UB min=-2.3118, max=17.4723
  Layer 3: LB min=-20.5545, max=26.5534 | UB min=-9.4216, max=45.1060
  Layer 4: LB min=-13.7896, max=32.0286 | UB min=6.5846, max=45.3702
  Layer 5: LB min=-12.3866, max=30.7073 | UB min=11.6821, max=47.8898
  Layer 6: LB min=-1.1882, max=26.5534 | UB min=27.5245, max=45.1060
  Layer 7: LB min=-9.0813, max=-9.0813 | UB min=13.4280, max=13.4280
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027996301651000977
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0172731876373291
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001987457275390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001177072525024414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011093616485595703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011744499206542969

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.1426, max=7.6581 | UB min=-0.8079, max=11.7203
  Layer 2: LB min=-8.5902, max=10.7325 | UB min=-2.3403, max=17.4461
  Layer 3: LB min=-20.5048, max=26.3845 | UB min=-9.4747, max=44.7771
  Layer 4: LB min=-13.6667, max=31.8315 | UB min=6.5095, max=45.0477
  Layer 5: LB min=-12.2551, max=30.4545 | UB min=11.5686, max=47.4495
  Layer 6: LB min=-1.1305, max=26.3845 | UB min=27.3041, max=44.7771
  Layer 7: LB min=-8.8706, max=-8.8706 | UB min=13.3718, max=13.3718
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.033722877502441406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030039310455322266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011754035949707031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010998249053955078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0048253536224365234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019142627716064453

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.1334, max=7.6658 | UB min=-0.8158, max=11.7121
  Layer 2: LB min=-8.5783, max=10.7465 | UB min=-2.3545, max=17.4330
  Layer 3: LB min=-20.4800, max=26.3001 | UB min=-9.5012, max=44.6126
  Layer 4: LB min=-13.6051, max=31.7329 | UB min=6.4720, max=44.8865
  Layer 5: LB min=-12.1893, max=30.3280 | UB min=11.5120, max=47.2294
  Layer 6: LB min=-1.1015, max=26.3001 | UB min=27.1939, max=44.6126
  Layer 7: LB min=-8.7653, max=-8.7653 | UB min=13.3435, max=13.3435
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.034386396408081055
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02054619789123535
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013403892517089844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004172086715698242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001251220703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001367330551147461

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.1288, max=7.6696 | UB min=-0.8198, max=11.7081
  Layer 2: LB min=-8.5723, max=10.7534 | UB min=-2.3616, max=17.4264
  Layer 3: LB min=-20.4675, max=26.2579 | UB min=-9.5145, max=44.5303
  Layer 4: LB min=-13.5744, max=31.6836 | UB min=6.4533, max=44.8059
  Layer 5: LB min=-12.1564, max=30.2648 | UB min=11.4836, max=47.1193
  Layer 6: LB min=-1.0871, max=26.2579 | UB min=27.1388, max=44.5303
  Layer 7: LB min=-8.7126, max=-8.7126 | UB min=13.3293, max=13.3293
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03559160232543945
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03391098976135254
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001100778579711914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004181623458862305
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018260478973388672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.006773710250854492

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.1242, max=7.6735 | UB min=-0.8238, max=11.7040
  Layer 2: LB min=-8.5664, max=10.7604 | UB min=-2.3688, max=17.4199
  Layer 3: LB min=-20.4551, max=26.2157 | UB min=-9.5277, max=44.4481
  Layer 4: LB min=-13.5436, max=31.6343 | UB min=6.4345, max=44.7253
  Layer 5: LB min=-12.1235, max=30.2016 | UB min=11.4553, max=47.0093
  Layer 6: LB min=-1.0727, max=26.2157 | UB min=27.0837, max=44.4481
  Layer 7: LB min=-8.6599, max=-8.6599 | UB min=13.3150, max=13.3150
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028017044067382812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01868438720703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002119779586791992
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004293203353881836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001199960708618164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0076999664306640625
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.008575439453125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.004843711853027344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001333475112915039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001355886459350586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005433082580566406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0049974918365478516
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0016961097717285156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0007333755493164062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011284351348876953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0017251968383789062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009899139404296875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001135110855102539
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.014935731887817383
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022722721099853516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011756420135498047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012590885162353516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014083385467529297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001798391342163086
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03400778770446777
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0529177188873291
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002242565155029297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001247406005859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011167526245117188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001168966293334961
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03441500663757324
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04045677185058594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001359701156616211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004816770553588867
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014028549194335938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016360282897949219
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02061939239501953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.014102697372436523
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010752677917480469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001039266586303711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001104116439819336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011882781982421875
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03707480430603027
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04172563552856445
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008161067962646484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007870197296142578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003713846206665039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013360977172851562
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03900575637817383
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04564237594604492
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003245115280151367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0030629634857177734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016894340515136719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001363515853881836
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03484201431274414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03570890426635742
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011289119720458984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00122833251953125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0021905899047851562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012164115905761719
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05463981628417969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03155112266540527
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001184225082397461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011496543884277344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010848045349121094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012581348419189453
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02440047264099121
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009312629699707031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008218288421630859
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008556842803955078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010330677032470703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009524822235107422
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.023815155029296875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.008886337280273438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012423992156982422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002738475799560547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012423992156982422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012392997741699219
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02205657958984375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01177978515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014238357543945312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.005271434783935547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003083944320678711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0025238990783691406
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04211163520812988
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0233919620513916
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0036966800689697266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004899024963378906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.006760358810424805
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004411935806274414
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02917313575744629
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0180666446685791
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014529228210449219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014452934265136719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011723041534423828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012161731719970703

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-38.1396, max=0.0000 | UB min=0.0000, max=53.3740
  Layer 2: LB min=-59.7523, max=0.0000 | UB min=0.0000, max=91.3982
  Layer 3: LB min=-184.8863, max=222.4479 | UB min=105.5639, max=689.1536
  Layer 4: LB min=-265.7149, max=288.7630 | UB min=205.7368, max=667.5762
  Layer 5: LB min=-323.9898, max=364.6531 | UB min=270.9888, max=850.1638
  Layer 6: LB min=-138.0440, max=194.7981 | UB min=577.8207, max=667.5762
  Layer 7: LB min=-519.0209, max=-519.0209 | UB min=149.5644, max=149.5644
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027856826782226562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.032282352447509766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002199888229370117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003904104232788086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001216888427734375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0031385421752929688

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-19.6893, max=0.0000 | UB min=0.0000, max=28.2907
  Layer 2: LB min=-32.2719, max=0.0000 | UB min=0.0000, max=47.7740
  Layer 3: LB min=-95.7442, max=124.3520 | UB min=51.8724, max=362.5962
  Layer 4: LB min=-136.6211, max=157.9652 | UB min=103.8759, max=346.6880
  Layer 5: LB min=-166.5703, max=197.7649 | UB min=137.5377, max=441.5319
  Layer 6: LB min=-70.9659, max=110.0787 | UB min=294.5009, max=346.6880
  Layer 7: LB min=-259.7729, max=-259.7729 | UB min=75.8993, max=75.8993
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03285479545593262
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02473902702331543
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0018696784973144531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001775979995727539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016884803771972656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002149343490600586

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-10.3484, max=0.0000 | UB min=0.0000, max=15.6002
  Layer 2: LB min=-18.0052, max=0.0000 | UB min=0.0000, max=25.6818
  Layer 3: LB min=-49.2462, max=76.2306 | UB min=20.3688, max=194.7134
  Layer 4: LB min=-67.8114, max=92.8052 | UB min=48.8037, max=180.3871
  Layer 5: LB min=-83.5692, max=113.7181 | UB min=66.2532, max=230.5850
  Layer 6: LB min=-35.7623, max=68.6030 | UB min=144.6362, max=180.3871
  Layer 7: LB min=-122.5621, max=-122.5621 | UB min=38.0827, max=38.0827
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.020598173141479492
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022995710372924805
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014605522155761719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009899139404296875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002414703369140625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013818740844726562

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.6399, max=2.5794 | UB min=0.0000, max=11.0923
  Layer 2: LB min=-11.2869, max=1.3771 | UB min=0.0000, max=16.5071
  Layer 3: LB min=-26.0283, max=46.3134 | UB min=4.0505, max=100.0628
  Layer 4: LB min=-30.4791, max=55.7333 | UB min=19.2900, max=93.5127
  Layer 5: LB min=-37.0832, max=65.3197 | UB min=29.4059, max=116.1132
  Layer 6: LB min=-13.7781, max=43.1867 | UB min=64.6026, max=93.5127
  Layer 7: LB min=-49.3697, max=-49.3697 | UB min=21.5233, max=21.5233
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027713298797607422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02430438995361328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015227794647216797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002756357192993164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0025234222412109375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.010094881057739258

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.2719, max=4.4554 | UB min=0.0000, max=8.8264
  Layer 2: LB min=-8.0867, max=5.2772 | UB min=-1.0966, max=12.6441
  Layer 3: LB min=-15.7581, max=26.3617 | UB min=-3.5061, max=48.1756
  Layer 4: LB min=-13.7454, max=32.8245 | UB min=6.2735, max=48.2164
  Layer 5: LB min=-15.0738, max=33.9558 | UB min=13.0604, max=55.2702
  Layer 6: LB min=-5.4402, max=26.3617 | UB min=28.0218, max=48.1756
  Layer 7: LB min=-16.4177, max=-16.4177 | UB min=13.3655, max=13.3655
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03864598274230957
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020599842071533203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011749267578125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012149810791015625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0076830387115478516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019497871398925781

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.0854, max=5.3958 | UB min=0.0000, max=7.6885
  Layer 2: LB min=-6.5960, max=7.1993 | UB min=-3.2588, max=10.8499
  Layer 3: LB min=-12.3872, max=15.7466 | UB min=-7.1225, max=25.4126
  Layer 4: LB min=-7.0233, max=19.7948 | UB min=1.4168, max=26.0348
  Layer 5: LB min=-4.9833, max=18.1378 | UB min=6.2435, max=26.6714
  Layer 6: LB min=0.1306, max=15.7466 | UB min=12.2605, max=25.4126
  Layer 7: LB min=-1.5071, max=-1.5071 | UB min=7.8103, max=7.8103
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03091144561767578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020554542541503906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015614032745361328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011444091796875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.006819009780883789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014634132385253906

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.6787, max=4.9253 | UB min=0.0000, max=8.2574
  Layer 2: LB min=-7.3338, max=6.2435 | UB min=-2.1793, max=11.7470
  Layer 3: LB min=-14.0601, max=20.6893 | UB min=-5.3533, max=36.2385
  Layer 4: LB min=-10.1256, max=25.9296 | UB min=3.8435, max=36.4704
  Layer 5: LB min=-9.9342, max=24.8740 | UB min=9.5591, max=39.7027
  Layer 6: LB min=-3.6087, max=20.6893 | UB min=19.9547, max=36.2385
  Layer 7: LB min=-9.0449, max=-9.0449 | UB min=11.4172, max=11.4172
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.010275125503540039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.006143331527709961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015070438385009766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014121532440185547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015332698822021484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.006731986999511719

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.3820, max=5.1603 | UB min=0.0000, max=7.9729
  Layer 2: LB min=-6.9591, max=6.7260 | UB min=-2.7192, max=11.2984
  Layer 3: LB min=-13.2230, max=18.1394 | UB min=-6.2566, max=30.7255
  Layer 4: LB min=-8.3952, max=22.7782 | UB min=2.6276, max=31.0388
  Layer 5: LB min=-7.4323, max=21.2426 | UB min=7.8631, max=32.9403
  Layer 6: LB min=-0.6882, max=18.1394 | UB min=16.0174, max=30.7255
  Layer 7: LB min=-4.7814, max=-4.7814 | UB min=8.6679, max=8.6679
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0320277214050293
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027467966079711914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015063285827636719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002386808395385742
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014116764068603516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014197826385498047

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.5303, max=5.0428 | UB min=0.0000, max=8.1152
  Layer 2: LB min=-7.1463, max=6.4849 | UB min=-2.4494, max=11.5227
  Layer 3: LB min=-13.6416, max=19.2892 | UB min=-5.8085, max=33.3556
  Layer 4: LB min=-9.2605, max=24.2383 | UB min=3.2356, max=33.6329
  Layer 5: LB min=-8.6793, max=22.8118 | UB min=8.7122, max=36.0813
  Layer 6: LB min=-1.1080, max=19.2892 | UB min=17.9849, max=33.3556
  Layer 7: LB min=-6.5467, max=-6.5467 | UB min=9.0988, max=9.0988
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.031000614166259766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023395776748657227
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012021064758300781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011126995086669922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00589442253112793
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014758110046386719

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.4562, max=5.1016 | UB min=0.0000, max=8.0441
  Layer 2: LB min=-7.0527, max=6.6055 | UB min=-2.5844, max=11.4106
  Layer 3: LB min=-13.4323, max=18.7148 | UB min=-6.0334, max=32.0406
  Layer 4: LB min=-8.8280, max=23.5085 | UB min=2.9315, max=32.3341
  Layer 5: LB min=-8.0550, max=22.0245 | UB min=8.2879, max=34.5099
  Layer 6: LB min=-0.8979, max=18.7148 | UB min=17.0006, max=32.0406
  Layer 7: LB min=-5.6632, max=-5.6632 | UB min=8.8831, max=8.8831
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.026015043258666992
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028273820877075195
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0018150806427001953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013031959533691406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013797283172607422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018157958984375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.4933, max=5.0722 | UB min=0.0000, max=8.0796
  Layer 2: LB min=-7.0995, max=6.5452 | UB min=-2.5169, max=11.4666
  Layer 3: LB min=-13.5369, max=19.0020 | UB min=-5.9213, max=32.6981
  Layer 4: LB min=-9.0443, max=23.8735 | UB min=3.0836, max=32.9831
  Layer 5: LB min=-8.3669, max=22.4174 | UB min=8.5000, max=35.2952
  Layer 6: LB min=-1.0030, max=19.0020 | UB min=17.4926, max=32.6981
  Layer 7: LB min=-6.1047, max=-6.1047 | UB min=8.9909, max=8.9909
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.008329153060913086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.006365060806274414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009696483612060547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012378692626953125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001094818115234375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011112689971923828

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.4747, max=5.0869 | UB min=0.0000, max=8.0618
  Layer 2: LB min=-7.0761, max=6.5754 | UB min=-2.5506, max=11.4386
  Layer 3: LB min=-13.4846, max=18.8585 | UB min=-5.9775, max=32.3694
  Layer 4: LB min=-8.9361, max=23.6910 | UB min=3.0076, max=32.6585
  Layer 5: LB min=-8.2109, max=22.2208 | UB min=8.3940, max=34.9025
  Layer 6: LB min=-0.9504, max=18.8585 | UB min=17.2466, max=32.3694
  Layer 7: LB min=-5.8839, max=-5.8839 | UB min=8.9370, max=8.9370
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.014322042465209961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0038967132568359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011849403381347656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010721683502197266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001184225082397461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018699169158935547

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.4654, max=5.0942 | UB min=0.0000, max=8.0529
  Layer 2: LB min=-7.0644, max=6.5904 | UB min=-2.5675, max=11.4246
  Layer 3: LB min=-13.4585, max=18.7867 | UB min=-6.0054, max=32.2050
  Layer 4: LB min=-8.8821, max=23.5998 | UB min=2.9695, max=32.4962
  Layer 5: LB min=-8.1329, max=22.1226 | UB min=8.3409, max=34.7062
  Layer 6: LB min=-0.9242, max=18.7867 | UB min=17.1236, max=32.2050
  Layer 7: LB min=-5.7735, max=-5.7735 | UB min=8.9100, max=8.9100
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029591083526611328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03904366493225098
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002005338668823242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012383460998535156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010519027709960938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001764059066772461

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.4701, max=5.0905 | UB min=0.0000, max=8.0574
  Layer 2: LB min=-7.0703, max=6.5829 | UB min=-2.5591, max=11.4316
  Layer 3: LB min=-13.4715, max=18.8226 | UB min=-5.9915, max=32.2872
  Layer 4: LB min=-8.9091, max=23.6454 | UB min=2.9886, max=32.5773
  Layer 5: LB min=-8.1719, max=22.1717 | UB min=8.3674, max=34.8043
  Layer 6: LB min=-0.9373, max=18.8226 | UB min=17.1851, max=32.2872
  Layer 7: LB min=-5.8287, max=-5.8287 | UB min=8.9235, max=8.9235
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.030505895614624023
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03617548942565918
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0017156600952148438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007994174957275391
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009129047393798828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009808540344238281

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.4654, max=5.0942 | UB min=0.0000, max=8.0529
  Layer 2: LB min=-7.0644, max=6.5904 | UB min=-2.5675, max=11.4246
  Layer 3: LB min=-13.4585, max=18.7867 | UB min=-6.0054, max=32.2050
  Layer 4: LB min=-8.8821, max=23.5998 | UB min=2.9695, max=32.4962
  Layer 5: LB min=-8.1329, max=22.1226 | UB min=8.3409, max=34.7062
  Layer 6: LB min=-0.9242, max=18.7867 | UB min=17.1236, max=32.2050
  Layer 7: LB min=-5.7735, max=-5.7735 | UB min=8.9100, max=8.9100
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.037076473236083984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029036521911621094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010819435119628906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001299142837524414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010950565338134766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0026760101318359375
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027489662170410156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023897886276245117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011093616485595703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011110305786132812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013189315795898438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0040740966796875
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.009921789169311523
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.010857343673706055
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010290145874023438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011036396026611328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002801179885864258
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014121532440185547
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02777409553527832
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026566267013549805
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001369476318359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001527547836303711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014071464538574219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012488365173339844
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.038392066955566406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04612994194030762
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012087821960449219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012729167938232422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011997222900390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013725757598876953
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03212571144104004
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.018771648406982422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010929107666015625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0018458366394042969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004952907562255859
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013675689697265625
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04009437561035156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.042333126068115234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009970664978027344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008270740509033203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008656978607177734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0024056434631347656
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03462386131286621
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03276181221008301
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013802051544189453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010597705841064453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011696815490722656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010542869567871094
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0296328067779541
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04591560363769531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016603469848632812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013937950134277344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014405250549316406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014727115631103516
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.047997236251831055
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.035845041275024414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001294851303100586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010662078857421875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016150474548339844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014767646789550781
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02476811408996582
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.032427310943603516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016865730285644531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0033817291259765625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013663768768310547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013189315795898438
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.026870012283325195
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02390909194946289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015952587127685547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.005637645721435547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0017981529235839844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002197742462158203
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.012245893478393555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.013080120086669922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0035295486450195312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0016481876373291016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0034439563751220703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016350746154785156
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04581880569458008
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029194116592407227
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012319087982177734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004242420196533203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011897087097167969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011661052703857422
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.026991844177246094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03984260559082031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011129379272460938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0027611255645751953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013039112091064453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016949176788330078
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.021716594696044922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.031733036041259766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012624263763427734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009968280792236328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0017936229705810547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012936592102050781

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-38.7181, max=0.0000 | UB min=0.0000, max=53.5911
  Layer 2: LB min=-59.4868, max=0.0000 | UB min=0.0000, max=91.2738
  Layer 3: LB min=-184.8277, max=223.6259 | UB min=105.1413, max=689.9818
  Layer 4: LB min=-265.5284, max=290.0323 | UB min=205.8919, max=668.7595
  Layer 5: LB min=-323.8907, max=365.7060 | UB min=270.8965, max=850.6973
  Layer 6: LB min=-137.8191, max=196.0179 | UB min=578.1852, max=668.7595
  Layer 7: LB min=-518.6059, max=-518.6059 | UB min=149.1776, max=149.1776
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03275012969970703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.034734487533569336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004450559616088867
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009262561798095703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008325576782226562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009853839874267578

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-20.4862, max=0.0000 | UB min=0.0000, max=28.5978
  Layer 2: LB min=-31.8529, max=0.0000 | UB min=0.0000, max=47.4488
  Layer 3: LB min=-95.3704, max=126.1051 | UB min=51.2248, max=362.9197
  Layer 4: LB min=-136.0268, max=159.5990 | UB min=103.9078, max=345.5271
  Layer 5: LB min=-165.8014, max=198.8670 | UB min=136.8170, max=441.0629
  Layer 6: LB min=-70.2536, max=111.4851 | UB min=294.0691, max=345.5271
  Layer 7: LB min=-257.5300, max=-257.5300 | UB min=75.1919, max=75.1919
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.044085025787353516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.025476694107055664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004548311233520508
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00118255615234375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005621194839477539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013659000396728516

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-11.2423, max=0.0000 | UB min=0.0000, max=15.9472
  Layer 2: LB min=-17.7292, max=0.0000 | UB min=0.0000, max=25.4267
  Layer 3: LB min=-48.9841, max=78.4801 | UB min=22.1686, max=195.6392
  Layer 4: LB min=-67.3543, max=94.6327 | UB min=49.5001, max=179.8177
  Layer 5: LB min=-82.5551, max=115.3066 | UB min=65.2833, max=231.0688
  Layer 6: LB min=-34.8550, max=70.3943 | UB min=144.5742, max=179.8177
  Layer 7: LB min=-120.3470, max=-120.3470 | UB min=37.3813, max=37.3813
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03623795509338379
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028240442276000977
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012660026550292969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013644695281982422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0036935806274414062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.000980377197265625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.5399, max=3.1971 | UB min=0.0000, max=11.5797
  Layer 2: LB min=-10.3557, max=2.1873 | UB min=0.0000, max=16.5845
  Layer 3: LB min=-25.2776, max=48.6388 | UB min=2.9786, max=100.1543
  Layer 4: LB min=-29.2285, max=58.2266 | UB min=19.1920, max=92.4417
  Layer 5: LB min=-35.4940, max=65.4261 | UB min=27.5537, max=114.0590
  Layer 6: LB min=-9.9748, max=45.6964 | UB min=63.5203, max=92.4417
  Layer 7: LB min=-45.0539, max=-45.0539 | UB min=20.1650, max=20.1650
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03600645065307617
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.024746417999267578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012576580047607422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004798412322998047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013997554779052734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014522075653076172

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-4.1683, max=5.1316 | UB min=0.0000, max=9.4051
  Layer 2: LB min=-7.1562, max=6.0861 | UB min=-0.5928, max=12.8726
  Layer 3: LB min=-15.0505, max=28.0475 | UB min=-4.5193, max=47.5423
  Layer 4: LB min=-13.0875, max=34.5616 | UB min=7.0262, max=47.7648
  Layer 5: LB min=-14.1961, max=34.7700 | UB min=10.5181, max=53.2989
  Layer 6: LB min=-1.3502, max=28.0475 | UB min=28.0949, max=47.2260
  Layer 7: LB min=-12.8338, max=-12.8338 | UB min=10.4844, max=10.4844
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03518199920654297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028836488723754883
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001432180404663086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001043558120727539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015604496002197266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019626617431640625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.9810, max=6.1009 | UB min=-0.6602, max=8.3163
  Layer 2: LB min=-5.6579, max=7.8619 | UB min=-2.4392, max=11.1765
  Layer 3: LB min=-11.8441, max=15.9394 | UB min=-7.3913, max=25.1041
  Layer 4: LB min=-6.2950, max=20.2024 | UB min=2.4626, max=26.1003
  Layer 5: LB min=-5.8738, max=17.9250 | UB min=3.7028, max=25.1041
  Layer 6: LB min=2.3067, max=15.9394 | UB min=13.9621, max=25.1041
  Layer 7: LB min=-0.8290, max=-0.8290 | UB min=7.4584, max=7.4584
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03533601760864258
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030284404754638672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003559112548828125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001115560531616211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012049674987792969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004529476165771484

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.5747, max=5.6157 | UB min=-0.1687, max=8.8607
  Layer 2: LB min=-6.3971, max=7.0186 | UB min=-1.5537, max=12.0224
  Layer 3: LB min=-13.4021, max=22.3546 | UB min=-6.1832, max=36.1753
  Layer 4: LB min=-9.5669, max=27.6744 | UB min=4.7845, max=36.7692
  Layer 5: LB min=-9.8017, max=26.2130 | UB min=6.8610, max=38.4728
  Layer 6: LB min=0.5353, max=22.3546 | UB min=20.6147, max=36.1753
  Layer 7: LB min=-6.2506, max=-6.2506 | UB min=8.8002, max=8.8002
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0310516357421875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029709577560424805
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012629032135009766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001138448715209961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005880594253540039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001478433609008789

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.2778, max=5.8583 | UB min=-0.4144, max=8.5885
  Layer 2: LB min=-6.0184, max=7.4475 | UB min=-1.9972, max=11.5969
  Layer 3: LB min=-12.6127, max=19.3027 | UB min=-6.8495, max=30.7422
  Layer 4: LB min=-7.8989, max=24.0856 | UB min=3.6799, max=31.5287
  Layer 5: LB min=-7.8104, max=21.8975 | UB min=5.2313, max=31.3266
  Layer 6: LB min=1.4531, max=19.3027 | UB min=17.2370, max=30.7422
  Layer 7: LB min=-3.4527, max=-3.4527 | UB min=8.1260, max=8.1260
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03414344787597656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019501209259033203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001155853271484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010802745819091797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011980533599853516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011816024780273438

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.4262, max=5.7370 | UB min=-0.2915, max=8.7246
  Layer 2: LB min=-6.2077, max=7.2331 | UB min=-1.7754, max=11.8096
  Layer 3: LB min=-13.0068, max=20.9048 | UB min=-6.5373, max=33.5235
  Layer 4: LB min=-8.7321, max=25.9541 | UB min=4.2315, max=34.1937
  Layer 5: LB min=-8.7920, max=24.1341 | UB min=6.0201, max=34.9669
  Layer 6: LB min=0.9988, max=20.9048 | UB min=18.8998, max=33.5235
  Layer 7: LB min=-4.8193, max=-4.8193 | UB min=8.4630, max=8.4630
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0381925106048584
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02908945083618164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013659000396728516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011136531829833984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011661052703857422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013356208801269531

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.5005, max=5.6763 | UB min=-0.2301, max=8.7926
  Layer 2: LB min=-6.3024, max=7.1259 | UB min=-1.6646, max=11.9160
  Layer 3: LB min=-13.2044, max=21.6298 | UB min=-6.3605, max=34.8495
  Layer 4: LB min=-9.1500, max=26.8143 | UB min=4.5079, max=35.4584
  Layer 5: LB min=-9.2873, max=25.1820 | UB min=6.4204, max=36.7279
  Layer 6: LB min=0.7669, max=21.6298 | UB min=19.7369, max=34.8495
  Layer 7: LB min=-5.5137, max=-5.5137 | UB min=8.6315, max=8.6315
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02898097038269043
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022331953048706055
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010776519775390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010273456573486328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004274129867553711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001954793930053711

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.5376, max=5.6460 | UB min=-0.1994, max=8.8266
  Layer 2: LB min=-6.3498, max=7.0723 | UB min=-1.6091, max=11.9692
  Layer 3: LB min=-13.3032, max=21.9922 | UB min=-6.2719, max=35.5124
  Layer 4: LB min=-9.3585, max=27.2444 | UB min=4.6462, max=36.1136
  Layer 5: LB min=-9.5450, max=25.6975 | UB min=6.6406, max=37.6003
  Layer 6: LB min=0.6511, max=21.9922 | UB min=20.1759, max=35.5124
  Layer 7: LB min=-5.8823, max=-5.8823 | UB min=8.7158, max=8.7158
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.031540870666503906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03568291664123535
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016324520111083984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014712810516357422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015454292297363281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0023164749145507812

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.5561, max=5.6309 | UB min=-0.1840, max=8.8437
  Layer 2: LB min=-6.3734, max=7.0455 | UB min=-1.5814, max=11.9958
  Layer 3: LB min=-13.3526, max=22.1734 | UB min=-6.2276, max=35.8439
  Layer 4: LB min=-9.4627, max=27.4594 | UB min=4.7153, max=36.4414
  Layer 5: LB min=-9.6735, max=25.9553 | UB min=6.7508, max=38.0366
  Layer 6: LB min=0.5932, max=22.1734 | UB min=20.3953, max=35.8439
  Layer 7: LB min=-6.0665, max=-6.0665 | UB min=8.7580, max=8.7580
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.037113189697265625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03318452835083008
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012137889862060547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011284351348876953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0034027099609375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018200874328613281

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.5654, max=5.6233 | UB min=-0.1764, max=8.8522
  Layer 2: LB min=-6.3852, max=7.0321 | UB min=-1.5675, max=12.0091
  Layer 3: LB min=-13.3774, max=22.2640 | UB min=-6.2054, max=36.0096
  Layer 4: LB min=-9.5148, max=27.5669 | UB min=4.7499, max=36.6053
  Layer 5: LB min=-9.7376, max=26.0841 | UB min=6.8059, max=38.2547
  Layer 6: LB min=0.5643, max=22.2640 | UB min=20.5050, max=36.0096
  Layer 7: LB min=-6.1586, max=-6.1586 | UB min=8.7791, max=8.7791
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.025133371353149414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030704498291015625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011131763458251953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011508464813232422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0021791458129882812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014252662658691406

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.5700, max=5.6195 | UB min=-0.1725, max=8.8564
  Layer 2: LB min=-6.3912, max=7.0254 | UB min=-1.5606, max=12.0158
  Layer 3: LB min=-13.3897, max=22.3093 | UB min=-6.1943, max=36.0924
  Layer 4: LB min=-9.5408, max=27.6207 | UB min=4.7672, max=36.6873
  Layer 5: LB min=-9.7697, max=26.1485 | UB min=6.8334, max=38.3638
  Layer 6: LB min=0.5498, max=22.3093 | UB min=20.5598, max=36.0924
  Layer 7: LB min=-6.2046, max=-6.2046 | UB min=8.7897, max=8.7897
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.032779693603515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.018900632858276367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012156963348388672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010712146759033203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004913806915283203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013651847839355469

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.5654, max=5.6233 | UB min=-0.1764, max=8.8522
  Layer 2: LB min=-6.3852, max=7.0321 | UB min=-1.5675, max=12.0091
  Layer 3: LB min=-13.3774, max=22.2640 | UB min=-6.2054, max=36.0096
  Layer 4: LB min=-9.5148, max=27.5669 | UB min=4.7499, max=36.6053
  Layer 5: LB min=-9.7376, max=26.0841 | UB min=6.8059, max=38.2547
  Layer 6: LB min=0.5643, max=22.2640 | UB min=20.5050, max=36.0096
  Layer 7: LB min=-6.1586, max=-6.1586 | UB min=8.7791, max=8.7791
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.031466007232666016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02728414535522461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.005609273910522461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012736320495605469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012965202331542969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012447834014892578
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.011204957962036133
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.007452726364135742
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013320446014404297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004302263259887695
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0017206668853759766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0033979415893554688
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.001020193099975586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0007872581481933594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0006682872772216797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.000978708267211914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015549659729003906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011336803436279297
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03497958183288574
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0242002010345459
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0048139095306396484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0018393993377685547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002266407012939453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015645027160644531
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0351710319519043
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01823115348815918
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0025131702423095703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.006620168685913086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013713836669921875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00122833251953125
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03422713279724121
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02638554573059082
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002376079559326172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0022764205932617188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0026502609252929688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0023725032806396484
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.025891780853271484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01997852325439453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012357234954833984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011725425720214844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011746883392333984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001188516616821289
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.022663593292236328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.025444507598876953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0022580623626708984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002031087875366211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015745162963867188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00249481201171875
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.023314952850341797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019002914428710938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001331329345703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011835098266601562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.008989334106445312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0020644664764404297
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027266740798950195
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01949477195739746
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013484954833984375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012133121490478516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014736652374267578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018203258514404297
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.037817955017089844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0246732234954834
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013968944549560547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001672506332397461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004240989685058594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015587806701660156
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02723979949951172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019864559173583984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001138925552368164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001130819320678711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012257099151611328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012629032135009766
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.018585920333862305
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02313971519470215
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015895366668701172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011951923370361328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010311603546142578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016260147094726562
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03148055076599121
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.035125732421875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013189315795898438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003927707672119141
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0017206668853759766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001316070556640625
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0317995548248291
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.032521963119506836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013363361358642578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012028217315673828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013210773468017578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013537406921386719
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0261843204498291
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015913724899291992
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008580684661865234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0026590824127197266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013918876647949219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013551712036132812

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-38.2528, max=0.0000 | UB min=0.0000, max=44.3853
  Layer 2: LB min=0.0000, max=0.0000 | UB min=61.5918, max=92.1276
  Layer 3: LB min=-186.8806, max=226.6009 | UB min=106.5619, max=698.0765
  Layer 4: LB min=-267.5422, max=291.3498 | UB min=207.8294, max=679.2784
  Layer 5: LB min=-325.6925, max=370.0150 | UB min=273.8602, max=860.0093
  Layer 6: LB min=-138.7601, max=197.8246 | UB min=582.9850, max=679.2784
  Layer 7: LB min=-524.0948, max=-524.0948 | UB min=151.8792, max=151.8792
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.00864553451538086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01138162612915039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010852813720703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011589527130126953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010654926300048828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011966228485107422

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-19.6006, max=0.0000 | UB min=0.0000, max=24.2218
  Layer 2: LB min=0.0000, max=0.0000 | UB min=31.6944, max=48.5783
  Layer 3: LB min=-98.3327, max=129.9475 | UB min=53.3753, max=374.1370
  Layer 4: LB min=-138.7225, max=160.7973 | UB min=106.7887, max=365.3714
  Layer 5: LB min=-168.2804, max=204.7945 | UB min=141.2402, max=457.3926
  Layer 6: LB min=-71.8454, max=113.3504 | UB min=301.4164, max=365.3714
  Layer 7: LB min=-269.6901, max=-269.6901 | UB min=78.7443, max=78.7443
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0060329437255859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01820540428161621
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0017735958099365234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002946615219116211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010149478912353516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010952949523925781

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-10.1725, max=0.0000 | UB min=0.0000, max=14.6882
  Layer 2: LB min=0.0000, max=0.0000 | UB min=15.9739, max=26.6052
  Layer 3: LB min=-52.0013, max=82.6259 | UB min=24.9387, max=207.1259
  Layer 4: LB min=-70.2949, max=95.8252 | UB min=53.8673, max=202.6215
  Layer 5: LB min=-84.8763, max=122.1686 | UB min=70.7771, max=248.5803
  Layer 6: LB min=-36.3027, max=71.5739 | UB min=154.2939, max=202.6215
  Layer 7: LB min=-134.2800, max=-134.2800 | UB min=44.4692, max=44.4692
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.016000032424926758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.012930154800415039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009331703186035156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014319419860839844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010447502136230469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012054443359375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.3873, max=2.4987 | UB min=0.0000, max=10.5054
  Layer 2: LB min=0.0000, max=0.0100 | UB min=8.3561, max=15.8141
  Layer 3: LB min=-27.1693, max=59.8681 | UB min=7.2222, max=116.3836
  Layer 4: LB min=-32.0777, max=63.7511 | UB min=23.9210, max=111.8130
  Layer 5: LB min=-37.6743, max=79.2210 | UB min=30.9997, max=134.5479
  Layer 6: LB min=-14.7877, max=49.5242 | UB min=73.2288, max=111.8130
  Layer 7: LB min=-56.1928, max=-56.1928 | UB min=24.1133, max=24.1133
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.005820274353027344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0022935867309570312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0007944107055664062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002047300338745117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001323699951171875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011951923370361328

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.4621, max=4.2883 | UB min=0.0000, max=8.3921
  Layer 2: LB min=0.0000, max=3.7580 | UB min=4.6189, max=11.5122
  Layer 3: LB min=-16.2496, max=39.4793 | UB min=-1.0089, max=64.1039
  Layer 4: LB min=-13.4057, max=42.9760 | UB min=9.6516, max=62.2830
  Layer 5: LB min=-14.8021, max=51.3567 | UB min=12.4777, max=73.8222
  Layer 6: LB min=2.1229, max=33.8834 | UB min=35.1476, max=62.2830
  Layer 7: LB min=-15.8298, max=-15.8298 | UB min=12.9306, max=12.9306
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02578425407409668
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.014009475708007812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001070261001586914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.006152153015136719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001123189926147461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010132789611816406

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.8223, max=5.1889 | UB min=-0.2996, max=7.3319
  Layer 2: LB min=0.0000, max=5.8524 | UB min=2.4908, max=9.5882
  Layer 3: LB min=-11.4938, max=24.6358 | UB min=-4.7106, max=36.3492
  Layer 4: LB min=-6.2969, max=28.4401 | UB min=2.1906, max=36.8468
  Layer 5: LB min=-5.4929, max=34.0240 | UB min=5.1859, max=43.4535
  Layer 6: LB min=6.4377, max=21.2358 | UB min=19.7420, max=34.7877
  Layer 7: LB min=-2.4922, max=-2.4922 | UB min=9.6714, max=9.6714
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04851722717285156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022817611694335938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012967586517333984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004631519317626953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002195596694946289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0020585060119628906

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.1426, max=4.7386 | UB min=0.0000, max=7.8626
  Layer 2: LB min=0.0000, max=4.8231 | UB min=3.5454, max=10.5089
  Layer 3: LB min=-13.7704, max=32.7598 | UB min=-2.8984, max=50.8483
  Layer 4: LB min=-9.7562, max=36.8121 | UB min=5.5702, max=49.9535
  Layer 5: LB min=-9.7910, max=43.2863 | UB min=8.5832, max=58.9483
  Layer 6: LB min=4.3377, max=28.8285 | UB min=26.8941, max=49.6195
  Layer 7: LB min=-8.6790, max=-8.6790 | UB min=11.2527, max=11.2527
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0388035774230957
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02135181427001953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011544227600097656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012104511260986328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001132965087890625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014960765838623047

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.9828, max=4.9638 | UB min=0.0000, max=7.5975
  Layer 2: LB min=0.0000, max=5.3516 | UB min=2.9673, max=10.0115
  Layer 3: LB min=-12.5597, max=28.9768 | UB min=-3.8337, max=43.8067
  Layer 4: LB min=-7.9659, max=32.9219 | UB min=3.5545, max=43.4987
  Layer 5: LB min=-7.3484, max=38.9020 | UB min=6.7546, max=51.2480
  Layer 6: LB min=5.4156, max=25.3750 | UB min=22.9181, max=42.4147
  Layer 7: LB min=-5.3140, max=-5.3140 | UB min=10.4046, max=10.4046
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0246732234954834
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020443201065063477
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0037217140197753906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010993480682373047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012640953063964844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011487007141113281

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.9027, max=5.0763 | UB min=-0.0884, max=7.4648
  Layer 2: LB min=0.0000, max=5.6101 | UB min=2.7090, max=9.7856
  Layer 3: LB min=-11.9864, max=26.8274 | UB min=-4.2841, max=40.0405
  Layer 4: LB min=-7.0974, max=30.6488 | UB min=2.6878, max=40.1085
  Layer 5: LB min=-6.2848, max=36.4972 | UB min=5.9401, max=47.2491
  Layer 6: LB min=5.9434, max=23.2830 | UB min=21.1614, max=38.5171
  Layer 7: LB min=-3.8067, max=-3.8067 | UB min=10.0171, max=10.0171
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.026361465454101562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.016506671905517578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0018491744995117188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014400482177734375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011000633239746094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011785030364990234

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.8625, max=5.1326 | UB min=-0.1940, max=7.3983
  Layer 2: LB min=0.0000, max=5.7312 | UB min=2.5999, max=9.6869
  Layer 3: LB min=-11.7400, max=25.7317 | UB min=-4.4973, max=38.1964
  Layer 4: LB min=-6.6973, max=29.5444 | UB min=2.3853, max=38.4775
  Layer 5: LB min=-5.8445, max=35.2809 | UB min=5.5495, max=45.3169
  Layer 6: LB min=6.1905, max=22.2593 | UB min=20.4112, max=36.6521
  Layer 7: LB min=-3.1188, max=-3.1188 | UB min=9.8361, max=9.8361
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.026092529296875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029573678970336914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011835098266601562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010118484497070312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018503665924072266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002306222915649414

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.8826, max=5.1045 | UB min=-0.1412, max=7.4315
  Layer 2: LB min=0.0000, max=5.6707 | UB min=2.6545, max=9.7363
  Layer 3: LB min=-11.8632, max=26.2796 | UB min=-4.3907, max=39.1188
  Layer 4: LB min=-6.8974, max=30.0966 | UB min=2.5312, max=39.2929
  Layer 5: LB min=-6.0604, max=35.8902 | UB min=5.7514, max=46.2795
  Layer 6: LB min=6.0670, max=22.7712 | UB min=20.7846, max=37.5846
  Layer 7: LB min=-3.4619, max=-3.4619 | UB min=9.9265, max=9.9265
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04331254959106445
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.031945228576660156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012843608856201172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001226663589477539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016334056854248047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019078254699707031

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.8725, max=5.1186 | UB min=-0.1676, max=7.4149
  Layer 2: LB min=0.0000, max=5.7010 | UB min=2.6272, max=9.7116
  Layer 3: LB min=-11.8016, max=26.0057 | UB min=-4.4440, max=38.6577
  Layer 4: LB min=-6.7974, max=29.8205 | UB min=2.4537, max=38.8852
  Layer 5: LB min=-5.9487, max=35.5872 | UB min=5.6489, max=45.7953
  Layer 6: LB min=6.1287, max=22.5153 | UB min=20.5943, max=37.1183
  Layer 7: LB min=-3.2877, max=-3.2877 | UB min=9.8806, max=9.8806
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028761863708496094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.035860538482666016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011746883392333984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011861324310302734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011439323425292969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0032968521118164062

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.8675, max=5.1256 | UB min=-0.1808, max=7.4066
  Layer 2: LB min=0.0000, max=5.7161 | UB min=2.6135, max=9.6993
  Layer 3: LB min=-11.7708, max=25.8687 | UB min=-4.4707, max=38.4271
  Layer 4: LB min=-6.7474, max=29.6825 | UB min=2.4153, max=38.6814
  Layer 5: LB min=-5.8931, max=35.4358 | UB min=5.5965, max=45.5535
  Layer 6: LB min=6.1596, max=22.3873 | UB min=20.4991, max=36.8852
  Layer 7: LB min=-3.2004, max=-3.2004 | UB min=9.8576, max=9.8576
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03097367286682129
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017243146896362305
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010800361633300781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011746883392333984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011093616485595703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002020597457885742

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.8650, max=5.1291 | UB min=-0.1874, max=7.4025
  Layer 2: LB min=0.0000, max=5.7237 | UB min=2.6067, max=9.6931
  Layer 3: LB min=-11.7554, max=25.8002 | UB min=-4.4840, max=38.3117
  Layer 4: LB min=-6.7223, max=29.6135 | UB min=2.3975, max=38.5794
  Layer 5: LB min=-5.8664, max=35.3596 | UB min=5.5712, max=45.4334
  Layer 6: LB min=6.1751, max=22.3233 | UB min=20.4527, max=36.7687
  Layer 7: LB min=-3.1577, max=-3.1577 | UB min=9.8463, max=9.8463
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.033028602600097656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026287555694580078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001165628433227539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012083053588867188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011665821075439453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012044906616210938

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.8625, max=5.1326 | UB min=-0.1940, max=7.3983
  Layer 2: LB min=0.0000, max=5.7312 | UB min=2.5999, max=9.6869
  Layer 3: LB min=-11.7400, max=25.7317 | UB min=-4.4973, max=38.1964
  Layer 4: LB min=-6.6973, max=29.5444 | UB min=2.3853, max=38.4775
  Layer 5: LB min=-5.8445, max=35.2809 | UB min=5.5495, max=45.3169
  Layer 6: LB min=6.1905, max=22.2593 | UB min=20.4112, max=36.6521
  Layer 7: LB min=-3.1188, max=-3.1188 | UB min=9.8361, max=9.8361
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03174591064453125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03573417663574219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001176595687866211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0025997161865234375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018391609191894531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013184547424316406
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.012664794921875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.016129732131958008
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011036396026611328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011525154113769531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011103153228759766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013310909271240234
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03415346145629883
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0120697021484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013349056243896484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011551380157470703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002528667449951172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0023641586303710938
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0014119148254394531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0016586780548095703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002910614013671875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0016796588897705078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015892982482910156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017063617706298828
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.043290138244628906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027262449264526367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001371145248413086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010211467742919922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012073516845703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011606216430664062
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03670024871826172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03992509841918945
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011420249938964844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010652542114257812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010323524475097656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004189014434814453
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.036887407302856445
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03714799880981445
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001283884048461914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010650157928466797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0041692256927490234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015401840209960938
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03498482704162598
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.05100870132446289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013480186462402344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011184215545654297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012934207916259766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0032460689544677734
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.024409770965576172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04413008689880371
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012712478637695312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012912750244140625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011129379272460938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012392997741699219
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027190208435058594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.031420230865478516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014984607696533203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011150836944580078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011816024780273438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017600059509277344
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.047263145446777344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022075414657592773
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003180980682373047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0015659332275390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0017423629760742188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003683328628540039
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03714609146118164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.039118051528930664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013570785522460938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0033872127532958984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013756752014160156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013120174407958984
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04553627967834473
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.025707006454467773
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014743804931640625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011518001556396484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011730194091796875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012793540954589844
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03223991394042969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028980255126953125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002502918243408203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001500844955444336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012428760528564453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012366771697998047
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027607440948486328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028231143951416016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016453266143798828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004255771636962891
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014996528625488281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017321109771728516
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.025323867797851562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.010477066040039062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012462139129638672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010952949523925781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001107931137084961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004110574722290039

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-27.1018, max=0.0000 | UB min=0.0000, max=53.1439
  Layer 2: LB min=-59.8695, max=0.0000 | UB min=0.0000, max=94.1571
  Layer 3: LB min=-188.3474, max=226.5066 | UB min=109.3038, max=704.2079
  Layer 4: LB min=-269.9059, max=293.6142 | UB min=210.4079, max=684.2476
  Layer 5: LB min=-329.5589, max=371.0576 | UB min=277.7060, max=868.0325
  Layer 6: LB min=-140.6199, max=196.5759 | UB min=591.0344, max=684.2476
  Layer 7: LB min=-531.4607, max=-531.4607 | UB min=152.1028, max=152.1028
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0012173652648925781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0018346309661865234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002073049545288086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0020380020141601562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002766132354736328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0022225379943847656

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-14.1565, max=0.0000 | UB min=0.0000, max=27.6521
  Layer 2: LB min=-31.2926, max=0.0000 | UB min=0.0000, max=50.9664
  Layer 3: LB min=-98.4984, max=128.1534 | UB min=56.1881, max=375.5697
  Layer 4: LB min=-139.7264, max=161.7254 | UB min=108.6031, max=364.9220
  Layer 5: LB min=-171.0219, max=202.8391 | UB min=143.9009, max=460.4019
  Layer 6: LB min=-72.8182, max=110.1037 | UB min=307.0939, max=364.9220
  Layer 7: LB min=-274.6605, max=-274.6605 | UB min=77.7441, max=77.7441
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.00107574462890625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0027709007263183594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002043485641479492
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0020341873168945312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002729654312133789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0023202896118164062

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-7.4186, max=0.0000 | UB min=0.0000, max=15.6052
  Layer 2: LB min=-16.3505, max=0.0000 | UB min=0.0000, max=28.4917
  Layer 3: LB min=-52.1811, max=78.7194 | UB min=28.5371, max=205.9745
  Layer 4: LB min=-71.0284, max=94.3879 | UB min=55.0742, max=198.6330
  Layer 5: LB min=-87.9959, max=116.7314 | UB min=73.7555, max=247.9103
  Layer 6: LB min=-36.8309, max=66.5042 | UB min=158.5772, max=198.6330
  Layer 7: LB min=-139.4216, max=-139.4216 | UB min=38.9630, max=38.9630
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.045217037200927734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.049271345138549805
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0031032562255859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003009319305419922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0036509037017822266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0056226253509521484

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-4.0133, max=1.3064 | UB min=0.0000, max=10.3088
  Layer 2: LB min=-8.3805, max=0.4688 | UB min=0.0000, max=17.2023
  Layer 3: LB min=-26.8500, max=54.8698 | UB min=12.9508, max=115.0795
  Layer 4: LB min=-32.4967, max=61.5973 | UB min=25.0274, max=108.5998
  Layer 5: LB min=-41.3394, max=72.7675 | UB min=34.1830, max=131.8016
  Layer 6: LB min=-16.3817, max=46.0570 | UB min=76.3736, max=108.5998
  Layer 7: LB min=-62.3055, max=-62.3055 | UB min=18.9265, max=18.9265
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03864550590515137
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023445606231689453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014064311981201172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001190185546875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013759136199951172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013623237609863281

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.2892, max=3.2214 | UB min=0.0000, max=7.6398
  Layer 2: LB min=-4.3451, max=3.9099 | UB min=0.0000, max=12.2063
  Layer 3: LB min=-14.6459, max=34.3674 | UB min=4.6479, max=62.5726
  Layer 4: LB min=-13.1308, max=40.8652 | UB min=9.3466, max=60.3160
  Layer 5: LB min=-18.6218, max=42.8014 | UB min=15.9258, max=68.5407
  Layer 6: LB min=-5.4121, max=31.7312 | UB min=36.1728, max=59.5617
  Layer 7: LB min=-24.2469, max=-24.2469 | UB min=10.8316, max=10.8316
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.054033517837524414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03922295570373535
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016465187072753906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010426044464111328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012881755828857422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010781288146972656

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.4211, max=4.1828 | UB min=0.0000, max=6.4743
  Layer 2: LB min=-2.4613, max=5.7848 | UB min=0.0000, max=9.8075
  Layer 3: LB min=-10.3611, max=21.5786 | UB min=0.0882, max=34.5289
  Layer 4: LB min=-8.4785, max=28.2182 | UB min=1.6166, max=36.6972
  Layer 5: LB min=-7.0141, max=26.1293 | UB min=5.7807, max=36.7873
  Layer 6: LB min=1.5008, max=21.5786 | UB min=16.8763, max=34.5038
  Layer 7: LB min=-6.5496, max=-6.5496 | UB min=6.2008, max=6.2008
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05380964279174805
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0238039493560791
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010802745819091797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011241436004638672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005688667297363281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012979507446289062

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-0.9871, max=4.6688 | UB min=0.0000, max=5.8959
  Layer 2: LB min=-1.4922, max=6.7285 | UB min=0.0000, max=8.7931
  Layer 3: LB min=-8.2349, max=13.3823 | UB min=-3.3105, max=19.7422
  Layer 4: LB min=-6.3693, max=19.4478 | UB min=-1.8959, max=23.4020
  Layer 5: LB min=-2.2332, max=16.1750 | UB min=2.5937, max=20.5273
  Layer 6: LB min=4.3336, max=13.3823 | UB min=10.0131, max=19.7422
  Layer 7: LB min=-1.1484, max=-1.1484 | UB min=3.6925, max=3.6925
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03003072738647461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017856836318969727
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001214742660522461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010368824005126953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001123666763305664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012695789337158203

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-0.7700, max=4.9121 | UB min=-0.1337, max=5.6055
  Layer 2: LB min=-1.0390, max=7.1681 | UB min=0.0000, max=8.2996
  Layer 3: LB min=-7.2125, max=7.6892 | UB min=-4.6670, max=11.0582
  Layer 4: LB min=-5.4184, max=14.2129 | UB min=-3.1060, max=16.2521
  Layer 5: LB min=-0.6316, max=12.0373 | UB min=1.4794, max=14.0232
  Layer 6: LB min=5.1253, max=7.6892 | UB min=7.7985, max=11.0582
  Layer 7: LB min=0.5420, max=0.5420 | UB min=2.7588, max=2.7588
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03264784812927246
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02754974365234375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0046269893646240234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0015201568603515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001524209976196289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016849040985107422

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-0.8785, max=4.7904 | UB min=0.0000, max=5.7509
  Layer 2: LB min=-1.2503, max=6.9635 | UB min=0.0000, max=8.5465
  Layer 3: LB min=-7.7240, max=10.4504 | UB min=-4.0600, max=15.2733
  Layer 4: LB min=-5.8938, max=16.8198 | UB min=-2.5967, max=19.7431
  Layer 5: LB min=-1.2096, max=13.7787 | UB min=2.0342, max=16.8156
  Layer 6: LB min=4.7575, max=10.4504 | UB min=8.7350, max=15.2733
  Layer 7: LB min=-0.1815, max=-0.1815 | UB min=3.1554, max=3.1554
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.042516231536865234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03270363807678223
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011622905731201172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002046346664428711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0017392635345458984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.007753610610961914

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-0.9328, max=4.7296 | UB min=0.0000, max=5.8236
  Layer 2: LB min=-1.3712, max=6.8460 | UB min=0.0000, max=8.6699
  Layer 3: LB min=-7.9797, max=11.9178 | UB min=-3.6952, max=17.5051
  Layer 4: LB min=-6.1316, max=18.1357 | UB min=-2.2570, max=21.5713
  Layer 5: LB min=-1.7040, max=14.7871 | UB min=2.3135, max=18.4628
  Layer 6: LB min=4.5474, max=11.9178 | UB min=9.3570, max=17.5051
  Layer 7: LB min=-0.6483, max=-0.6483 | UB min=3.4237, max=3.4237
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.030689716339111328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03545212745666504
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001104116439819336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001753091812133789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018198490142822266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015439987182617188

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-0.9057, max=4.7600 | UB min=0.0000, max=5.7873
  Layer 2: LB min=-1.3108, max=6.9048 | UB min=0.0000, max=8.6082
  Layer 3: LB min=-7.8519, max=11.1840 | UB min=-3.8778, max=16.3892
  Layer 4: LB min=-6.0127, max=17.4779 | UB min=-2.4274, max=20.6572
  Layer 5: LB min=-1.4545, max=14.2272 | UB min=2.1738, max=17.5807
  Layer 6: LB min=4.6525, max=11.1840 | UB min=9.0431, max=16.3892
  Layer 7: LB min=-0.4129, max=-0.4129 | UB min=3.2894, max=3.2894
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.021639347076416016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02791142463684082
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012829303741455078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010933876037597656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011065006256103516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013110637664794922

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-0.9192, max=4.7448 | UB min=0.0000, max=5.8055
  Layer 2: LB min=-1.3410, max=6.8754 | UB min=0.0000, max=8.6391
  Layer 3: LB min=-7.9158, max=11.5509 | UB min=-3.7865, max=16.9471
  Layer 4: LB min=-6.0721, max=17.8069 | UB min=-2.3424, max=21.1142
  Layer 5: LB min=-1.5784, max=14.4514 | UB min=2.2436, max=17.9651
  Layer 6: LB min=4.6000, max=11.5509 | UB min=9.1992, max=16.9471
  Layer 7: LB min=-0.5299, max=-0.5299 | UB min=3.3565, max=3.3565
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02839803695678711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0418543815612793
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011289119720458984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010192394256591797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011525154113769531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002222776412963867

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-0.9260, max=4.7372 | UB min=0.0000, max=5.8145
  Layer 2: LB min=-1.3561, max=6.8607 | UB min=0.0000, max=8.6545
  Layer 3: LB min=-7.9478, max=11.7343 | UB min=-3.7409, max=17.2261
  Layer 4: LB min=-6.1019, max=17.9713 | UB min=-2.2997, max=21.3427
  Layer 5: LB min=-1.6410, max=14.6132 | UB min=2.2786, max=18.2077
  Layer 6: LB min=4.5737, max=11.7343 | UB min=9.2779, max=17.2261
  Layer 7: LB min=-0.5889, max=-0.5889 | UB min=3.3901, max=3.3901
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028474807739257812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.031974077224731445
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015292167663574219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010302066802978516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009624958038330078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010809898376464844

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-0.9294, max=4.7334 | UB min=0.0000, max=5.8191
  Layer 2: LB min=-1.3637, max=6.8534 | UB min=0.0000, max=8.6622
  Layer 3: LB min=-7.9638, max=11.8261 | UB min=-3.7180, max=17.3656
  Layer 4: LB min=-6.1167, max=18.0535 | UB min=-2.2783, max=21.4570
  Layer 5: LB min=-1.6725, max=14.7001 | UB min=2.2960, max=18.3352
  Layer 6: LB min=4.5606, max=11.8261 | UB min=9.3174, max=17.3656
  Layer 7: LB min=-0.6185, max=-0.6185 | UB min=3.4069, max=3.4069
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.044447898864746094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04127049446105957
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009098052978515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0036034584045410156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013768672943115234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0029480457305908203

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-0.9294, max=4.7334 | UB min=0.0000, max=5.8191
  Layer 2: LB min=-1.3637, max=6.8534 | UB min=0.0000, max=8.6622
  Layer 3: LB min=-7.9638, max=11.8261 | UB min=-3.7180, max=17.3656
  Layer 4: LB min=-6.1167, max=18.0535 | UB min=-2.2783, max=21.4570
  Layer 5: LB min=-1.6725, max=14.7001 | UB min=2.2960, max=18.3352
  Layer 6: LB min=4.5606, max=11.8261 | UB min=9.3174, max=17.3656
  Layer 7: LB min=-0.6185, max=-0.6185 | UB min=3.4069, max=3.4069
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.009072542190551758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.00607609748840332
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010950565338134766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013127326965332031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014350414276123047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012440681457519531
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03892374038696289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04248189926147461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011649131774902344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001226663589477539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002103090286254883
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001458883285522461
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.014595985412597656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.013239860534667969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001026153564453125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012745857238769531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001077890396118164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012552738189697266
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029723405838012695
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.025185346603393555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010793209075927734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011167526245117188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002995729446411133
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015223026275634766
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04018545150756836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.038042306900024414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001552581787109375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011868476867675781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0029828548431396484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013217926025390625
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04883456230163574
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028606176376342773
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001264333724975586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0017364025115966797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0029659271240234375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001676321029663086
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03368949890136719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04215693473815918
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001354217529296875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011749267578125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011899471282958984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015761852264404297
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.009357929229736328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.008841276168823242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010585784912109375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0017592906951904297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010976791381835938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001257181167602539
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03673672676086426
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04594063758850098
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013580322265625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011608600616455078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013535022735595703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011892318725585938
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01244044303894043
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.004358530044555664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010294914245605469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012302398681640625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011763572692871094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.007314443588256836
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.009375333786010742
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.009116888046264648
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0032541751861572266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0032291412353515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004516124725341797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003164529800415039
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.040509939193725586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02904653549194336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001050710678100586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011734962463378906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0021469593048095703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0022606849670410156
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03167605400085449
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015938520431518555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009884834289550781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0039179325103759766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013780593872070312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014028549194335938
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.06236839294433594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020992040634155273
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00789952278137207
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.005232334136962891
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0017921924591064453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004376888275146484
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03300666809082031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02571868896484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015876293182373047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0045626163482666016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012423992156982422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013039112091064453
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05875802040100098
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030167818069458008
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016613006591796875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002919912338256836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013175010681152344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013437271118164062

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-38.0983, max=0.0000 | UB min=0.0000, max=52.9117
  Layer 2: LB min=-59.6748, max=0.0000 | UB min=0.0000, max=92.2435
  Layer 3: LB min=-186.2810, max=227.4786 | UB min=106.2327, max=697.4130
  Layer 4: LB min=-267.9215, max=293.6506 | UB min=207.0329, max=676.6032
  Layer 5: LB min=-325.9630, max=371.0374 | UB min=272.5373, max=859.1422
  Layer 6: LB min=-139.0855, max=198.9515 | UB min=581.9624, max=676.6032
  Layer 7: LB min=-521.8190, max=-521.8190 | UB min=151.0652, max=151.0652
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.011226177215576172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.009926795959472656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001322031021118164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0038039684295654297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0017080307006835938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0027129650115966797

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-19.3465, max=0.0000 | UB min=0.0000, max=27.4344
  Layer 2: LB min=-32.0870, max=0.0000 | UB min=0.0000, max=48.9136
  Layer 3: LB min=-97.7954, max=132.1280 | UB min=52.6496, max=373.8161
  Layer 4: LB min=-139.6527, max=165.0974 | UB min=105.2529, max=358.6536
  Layer 5: LB min=-168.8077, max=206.9507 | UB min=139.1947, max=453.9920
  Layer 6: LB min=-72.3013, max=116.4097 | UB min=299.1173, max=358.6536
  Layer 7: LB min=-263.1086, max=-263.1086 | UB min=78.2828, max=78.2828
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.00115966796875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009613037109375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010883808135986328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011386871337890625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001325368881225586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016803741455078125

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-9.8753, max=0.0000 | UB min=0.0000, max=16.6907
  Layer 2: LB min=-17.8505, max=0.0000 | UB min=0.0000, max=27.5421
  Layer 3: LB min=-51.4087, max=85.6266 | UB min=22.4200, max=206.8531
  Layer 4: LB min=-70.9525, max=100.8249 | UB min=50.0966, max=199.2300
  Layer 5: LB min=-84.7447, max=124.3523 | UB min=67.0788, max=245.6622
  Layer 6: LB min=-36.7034, max=76.5197 | UB min=148.2298, max=199.2300
  Layer 7: LB min=-128.4474, max=-128.4474 | UB min=43.6629, max=43.6629
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0010128021240234375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0018033981323242188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002079010009765625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001272439956665039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0023241043090820312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018925666809082031

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.0981, max=3.4879 | UB min=0.0000, max=12.2473
  Layer 2: LB min=-10.8305, max=3.6148 | UB min=0.0000, max=18.7669
  Layer 3: LB min=-28.4946, max=53.4529 | UB min=4.7347, max=109.5700
  Layer 4: LB min=-34.1617, max=61.7417 | UB min=20.4657, max=106.0397
  Layer 5: LB min=-39.6058, max=72.0508 | UB min=30.1377, max=127.4858
  Layer 6: LB min=-15.2412, max=50.0823 | UB min=68.8695, max=106.0397
  Layer 7: LB min=-53.3221, max=-53.3221 | UB min=25.0180, max=25.0180
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.001065969467163086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0008797645568847656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010352134704589844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011751651763916016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001371145248413086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014946460723876953

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.6938, max=5.5286 | UB min=0.0000, max=10.0067
  Layer 2: LB min=-7.1740, max=7.8499 | UB min=-0.0612, max=14.9617
  Layer 3: LB min=-17.0475, max=33.5961 | UB min=-3.5391, max=57.8445
  Layer 4: LB min=-16.8714, max=38.6793 | UB min=6.9718, max=57.8445
  Layer 5: LB min=-16.6385, max=40.7671 | UB min=12.0658, max=64.2057
  Layer 6: LB min=-3.4504, max=33.5961 | UB min=30.2908, max=57.8445
  Layer 7: LB min=-15.9432, max=-15.9432 | UB min=15.5667, max=15.5667
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04694795608520508
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027393817901611328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001308441162109375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013623237609863281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0030944347381591797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015499591827392578

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.4917, max=6.5522 | UB min=0.0000, max=8.8862
  Layer 2: LB min=-5.4962, max=9.6257 | UB min=-1.9770, max=13.1979
  Layer 3: LB min=-13.1497, max=19.7978 | UB min=-6.6865, max=31.7008
  Layer 4: LB min=-10.4291, max=23.7284 | UB min=2.0337, max=32.1523
  Layer 5: LB min=-6.8589, max=22.2579 | UB min=4.3393, max=32.0649
  Layer 6: LB min=0.9747, max=19.7978 | UB min=14.5739, max=31.7008
  Layer 7: LB min=-1.0337, max=-1.0337 | UB min=10.7710, max=10.7710
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.007725715637207031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0065538883209228516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013813972473144531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0015072822570800781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001800537109375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019621849060058594

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.0928, max=6.0399 | UB min=0.0000, max=9.4464
  Layer 2: LB min=-6.3024, max=8.8310 | UB min=-1.0569, max=14.0809
  Layer 3: LB min=-15.0362, max=27.4708 | UB min=-5.3487, max=45.0647
  Layer 4: LB min=-13.4127, max=32.0388 | UB min=4.5236, max=45.0647
  Layer 5: LB min=-11.5524, max=31.8079 | UB min=8.2176, max=48.3909
  Layer 6: LB min=-1.1349, max=27.4708 | UB min=22.1362, max=45.0647
  Layer 7: LB min=-7.9199, max=-7.9199 | UB min=13.3688, max=13.3688
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.032778024673461914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023301362991333008
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.006922483444213867
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011949539184570312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003868579864501953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002254486083984375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.7922, max=6.2959 | UB min=0.0000, max=9.1663
  Layer 2: LB min=-5.8975, max=9.2299 | UB min=-1.5172, max=13.6395
  Layer 3: LB min=-14.0925, max=23.6558 | UB min=-6.0166, max=38.3989
  Layer 4: LB min=-11.9162, max=27.8928 | UB min=3.3192, max=38.3989
  Layer 5: LB min=-9.4490, max=26.7856 | UB min=6.5851, max=40.4594
  Layer 6: LB min=-0.2298, max=23.6558 | UB min=18.6569, max=38.3989
  Layer 7: LB min=-4.5792, max=-4.5792 | UB min=12.4011, max=12.4011
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03862500190734863
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04037761688232422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011603832244873047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001199483871459961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012187957763671875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011882781982421875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.9425, max=6.1678 | UB min=0.0000, max=9.3064
  Layer 2: LB min=-6.0982, max=9.0320 | UB min=-1.2871, max=13.8603
  Layer 3: LB min=-14.5644, max=25.5847 | UB min=-5.6851, max=41.7481
  Layer 4: LB min=-12.6593, max=29.9840 | UB min=3.9211, max=41.7481
  Layer 5: LB min=-10.5020, max=29.3085 | UB min=7.4077, max=44.4384
  Layer 6: LB min=-0.6785, max=25.5847 | UB min=20.3959, max=41.7481
  Layer 7: LB min=-6.2453, max=-6.2453 | UB min=12.8982, max=12.8982
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04397869110107422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030316829681396484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002569437026977539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0019152164459228516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001581430435180664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011677742004394531

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8674, max=6.2319 | UB min=0.0000, max=9.2363
  Layer 2: LB min=-5.9978, max=9.1310 | UB min=-1.4022, max=13.7499
  Layer 3: LB min=-14.3284, max=24.6203 | UB min=-5.8506, max=40.0735
  Layer 4: LB min=-12.2878, max=28.9379 | UB min=3.6201, max=40.0735
  Layer 5: LB min=-9.9766, max=28.0439 | UB min=6.9984, max=42.4489
  Layer 6: LB min=-0.4542, max=24.6203 | UB min=19.5271, max=40.0735
  Layer 7: LB min=-5.4133, max=-5.4133 | UB min=12.6548, max=12.6548
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.030538082122802734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020351648330688477
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011372566223144531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0018405914306640625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012888908386230469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.006181240081787109

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8298, max=6.2639 | UB min=0.0000, max=9.2013
  Layer 2: LB min=-5.9477, max=9.1804 | UB min=-1.4597, max=13.6947
  Layer 3: LB min=-14.2104, max=24.1380 | UB min=-5.9335, max=39.2362
  Layer 4: LB min=-12.1020, max=28.4152 | UB min=3.4697, max=39.2362
  Layer 5: LB min=-9.7131, max=27.4139 | UB min=6.7923, max=41.4542
  Layer 6: LB min=-0.3420, max=24.1380 | UB min=19.0922, max=39.2362
  Layer 7: LB min=-4.9966, max=-4.9966 | UB min=12.5294, max=12.5294
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.033669471740722656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03563714027404785
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011026859283447266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011582374572753906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002975940704345703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001445770263671875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8110, max=6.2799 | UB min=0.0000, max=9.1838
  Layer 2: LB min=-5.9226, max=9.2052 | UB min=-1.4885, max=13.6671
  Layer 3: LB min=-14.1515, max=23.8969 | UB min=-5.9750, max=38.8175
  Layer 4: LB min=-12.0091, max=28.1540 | UB min=3.3944, max=38.8175
  Layer 5: LB min=-9.5811, max=27.0995 | UB min=6.6889, max=40.9568
  Layer 6: LB min=-0.2859, max=23.8969 | UB min=18.8746, max=38.8175
  Layer 7: LB min=-4.7880, max=-4.7880 | UB min=12.4656, max=12.4656
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04005932807922363
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023693323135375977
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001214742660522461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011882781982421875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0019178390502929688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017185211181640625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8204, max=6.2719 | UB min=0.0000, max=9.1926
  Layer 2: LB min=-5.9351, max=9.1928 | UB min=-1.4741, max=13.6809
  Layer 3: LB min=-14.1809, max=24.0174 | UB min=-5.9543, max=39.0269
  Layer 4: LB min=-12.0555, max=28.2846 | UB min=3.4320, max=39.0269
  Layer 5: LB min=-9.6471, max=27.2567 | UB min=6.7406, max=41.2055
  Layer 6: LB min=-0.3139, max=24.0174 | UB min=18.9834, max=39.0269
  Layer 7: LB min=-4.8923, max=-4.8923 | UB min=12.4976, max=12.4976
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028812170028686523
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04348897933959961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002187967300415039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012922286987304688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011699199676513672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013551712036132812

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8251, max=6.2679 | UB min=0.0000, max=9.1970
  Layer 2: LB min=-5.9414, max=9.1866 | UB min=-1.4669, max=13.6878
  Layer 3: LB min=-14.1957, max=24.0777 | UB min=-5.9439, max=39.1315
  Layer 4: LB min=-12.0788, max=28.3499 | UB min=3.4508, max=39.1315
  Layer 5: LB min=-9.6801, max=27.3353 | UB min=6.7665, max=41.3298
  Layer 6: LB min=-0.3280, max=24.0777 | UB min=19.0378, max=39.1315
  Layer 7: LB min=-4.9444, max=-4.9444 | UB min=12.5135, max=12.5135
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03336739540100098
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03794598579406738
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004976987838745117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011401176452636719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.006100893020629883
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014777183532714844

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8204, max=6.2719 | UB min=0.0000, max=9.1926
  Layer 2: LB min=-5.9351, max=9.1928 | UB min=-1.4741, max=13.6809
  Layer 3: LB min=-14.1809, max=24.0174 | UB min=-5.9543, max=39.0269
  Layer 4: LB min=-12.0555, max=28.2846 | UB min=3.4320, max=39.0269
  Layer 5: LB min=-9.6471, max=27.2567 | UB min=6.7406, max=41.2055
  Layer 6: LB min=-0.3139, max=24.0174 | UB min=18.9834, max=39.0269
  Layer 7: LB min=-4.8923, max=-4.8923 | UB min=12.4976, max=12.4976
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0331878662109375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04945945739746094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001424551010131836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001069784164428711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001255035400390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013530254364013672
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.00917959213256836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.008237123489379883
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010194778442382812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010614395141601562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0021643638610839844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014255046844482422
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009629726409912109
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009725093841552734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009706020355224609
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007631778717041016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010187625885009766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009891986846923828
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.039925336837768555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.031325340270996094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001024007797241211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010967254638671875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011909008026123047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012252330780029297
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01952505111694336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027252197265625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011191368103027344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0019104480743408203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013055801391601562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017757415771484375
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03138613700866699
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03111100196838379
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0020515918731689453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014607906341552734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002319812774658203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014660358428955078
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03550457954406738
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.013519525527954102
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014367103576660156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0015180110931396484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015456676483154297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015840530395507812
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05063152313232422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017235994338989258
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013513565063476562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0015406608581542969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015518665313720703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016009807586669922
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02825474739074707
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030600786209106445
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001125335693359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001069784164428711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0030982494354248047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001963376998901367
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03895711898803711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02364039421081543
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.009050130844116211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014524459838867188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015158653259277344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016443729400634766
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.040723562240600586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02464151382446289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0028896331787109375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012025833129882812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016214847564697266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013926029205322266
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.042298316955566406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04464077949523926
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012707710266113281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001110076904296875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002887248992919922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014204978942871094
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03205561637878418
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.012132644653320312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004122734069824219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012202262878417969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010895729064941406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019161701202392578
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.039003849029541016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03316807746887207
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004943132400512695
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013012886047363281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011551380157470703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0034706592559814453
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0274507999420166
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03549766540527344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002451658248901367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0017333030700683594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012013912200927734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001245260238647461
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.045755624771118164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02657294273376465
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013899803161621094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011508464813232422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001508474349975586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015065670013427734

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-38.2096, max=0.0000 | UB min=0.0000, max=44.8499
  Layer 2: LB min=0.0000, max=0.0000 | UB min=61.7371, max=92.5392
  Layer 3: LB min=-186.1945, max=227.2946 | UB min=106.6472, max=697.4863
  Layer 4: LB min=-266.3423, max=292.2263 | UB min=207.4361, max=678.8033
  Layer 5: LB min=-324.9018, max=370.5624 | UB min=273.5218, max=859.3911
  Layer 6: LB min=-138.1610, max=197.4598 | UB min=582.2991, max=678.8033
  Layer 7: LB min=-522.9834, max=-522.9834 | UB min=150.0557, max=150.0557
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.030493736267089844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0361785888671875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012462139129638672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010938644409179688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012357234954833984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001184701919555664

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-19.6099, max=0.0000 | UB min=0.0000, max=24.9984
  Layer 2: LB min=0.0000, max=0.0000 | UB min=32.2867, max=49.6898
  Layer 3: LB min=-97.4495, max=131.3149 | UB min=53.6151, max=374.0377
  Layer 4: LB min=-137.1606, max=162.6529 | UB min=106.4939, max=365.6069
  Layer 5: LB min=-167.6487, max=205.7851 | UB min=141.0930, max=457.5130
  Layer 6: LB min=-70.8529, max=113.2422 | UB min=301.4005, max=365.6069
  Layer 7: LB min=-268.6306, max=-268.6306 | UB min=76.4376, max=76.4376
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.030423641204833984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.021448135375976562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012562274932861328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00112152099609375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010938644409179688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011997222900390625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-10.1276, max=0.0000 | UB min=0.0000, max=15.1823
  Layer 2: LB min=0.0000, max=0.0000 | UB min=16.5882, max=27.7903
  Layer 3: LB min=-50.8628, max=84.1739 | UB min=25.2029, max=206.9346
  Layer 4: LB min=-68.2119, max=98.5023 | UB min=53.2420, max=202.0359
  Layer 5: LB min=-84.1193, max=123.0645 | UB min=70.6643, max=248.1544
  Layer 6: LB min=-34.6999, max=71.6417 | UB min=154.1052, max=202.0359
  Layer 7: LB min=-132.5004, max=-132.5004 | UB min=38.6904, max=38.6904
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03756260871887207
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03289198875427246
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001255035400390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011372566223144531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011522769927978516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016055107116699219

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.3006, max=3.0324 | UB min=0.0000, max=11.0251
  Layer 2: LB min=0.0000, max=0.7790 | UB min=8.5871, max=17.0942
  Layer 3: LB min=-26.3068, max=60.6725 | UB min=8.1058, max=115.6215
  Layer 4: LB min=-29.9440, max=65.7844 | UB min=23.8316, max=110.0008
  Layer 5: LB min=-36.4324, max=78.0866 | UB min=30.6964, max=132.0578
  Layer 6: LB min=-6.7802, max=48.6722 | UB min=73.1593, max=110.0008
  Layer 7: LB min=-51.5981, max=-51.5981 | UB min=22.4923, max=22.4923
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.009296178817749023
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015341043472290039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0023665428161621094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0015711784362792969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010833740234375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011670589447021484

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.8727, max=4.8278 | UB min=0.0000, max=8.9179
  Layer 2: LB min=0.0000, max=4.5556 | UB min=4.9589, max=12.6781
  Layer 3: LB min=-15.9728, max=39.5159 | UB min=-0.1671, max=63.9121
  Layer 4: LB min=-13.5184, max=44.7542 | UB min=9.3357, max=62.1404
  Layer 5: LB min=-14.6192, max=50.0510 | UB min=12.2317, max=72.6588
  Layer 6: LB min=3.2761, max=33.3798 | UB min=36.3653, max=62.1404
  Layer 7: LB min=-15.7369, max=-15.7369 | UB min=12.4376, max=12.4376
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03106999397277832
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03885030746459961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004712343215942383
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0016021728515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0020761489868164062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019271373748779297

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.6577, max=5.7294 | UB min=0.0000, max=7.8624
  Layer 2: LB min=0.0000, max=6.5222 | UB min=2.8677, max=10.6171
  Layer 3: LB min=-11.0288, max=23.8330 | UB min=-3.9388, max=34.9866
  Layer 4: LB min=-5.6437, max=29.8097 | UB min=2.4983, max=37.6987
  Layer 5: LB min=-4.9291, max=32.6734 | UB min=5.1143, max=41.0185
  Layer 6: LB min=6.7286, max=20.6105 | UB min=20.5887, max=34.6851
  Layer 7: LB min=-2.3157, max=-2.3157 | UB min=8.7724, max=8.7724
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0386500358581543
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04061746597290039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012409687042236328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010197162628173828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012423992156982422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011897087097167969

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.2652, max=5.2783 | UB min=0.0000, max=8.3902
  Layer 2: LB min=0.0000, max=5.5307 | UB min=4.0043, max=11.6462
  Layer 3: LB min=-13.5325, max=32.8663 | UB min=-2.0840, max=50.4302
  Layer 4: LB min=-9.9399, max=38.8136 | UB min=6.2989, max=51.1958
  Layer 5: LB min=-9.7357, max=42.2892 | UB min=8.5362, max=57.8131
  Layer 6: LB min=5.4664, max=28.6445 | UB min=28.3395, max=49.9788
  Layer 7: LB min=-8.8054, max=-8.8054 | UB min=10.6344, max=10.6344
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.011343240737915039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.009180307388305664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0032591819763183594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011310577392578125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012629032135009766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0034983158111572266

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.9615, max=5.5038 | UB min=0.0000, max=8.1263
  Layer 2: LB min=0.0000, max=6.0160 | UB min=3.4353, max=11.1312
  Layer 3: LB min=-12.1979, max=28.4053 | UB min=-3.0276, max=42.7786
  Layer 4: LB min=-7.2637, max=34.4136 | UB min=4.2928, max=44.5040
  Layer 5: LB min=-7.2306, max=37.4828 | UB min=6.7919, max=49.1751
  Layer 6: LB min=6.6432, max=24.7240 | UB min=24.3057, max=42.5308
  Layer 7: LB min=-5.3545, max=-5.3545 | UB min=9.6932, max=9.6932
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03324294090270996
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022919416427612305
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012133121490478516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0021169185638427734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013346672058105469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015444755554199219

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8096, max=5.6166 | UB min=0.0000, max=7.9944
  Layer 2: LB min=0.0000, max=6.2613 | UB min=3.1512, max=10.8740
  Layer 3: LB min=-11.5821, max=26.1609 | UB min=-3.4947, max=38.9014
  Layer 4: LB min=-6.4375, max=32.1834 | UB min=3.3136, max=41.1664
  Layer 5: LB min=-6.0168, max=35.1056 | UB min=5.9497, max=45.0435
  Layer 6: LB min=7.1966, max=22.7564 | UB min=22.3931, max=38.6779
  Layer 7: LB min=-3.7866, max=-3.7866 | UB min=9.2376, max=9.2376
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029060840606689453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022271394729614258
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011861324310302734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011415481567382812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011544227600097656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004746437072753906

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.7337, max=5.6730 | UB min=0.0000, max=7.9284
  Layer 2: LB min=0.0000, max=6.3892 | UB min=3.0094, max=10.7454
  Layer 3: LB min=-11.2974, max=25.0088 | UB min=-3.7283, max=36.9434
  Layer 4: LB min=-6.0311, max=31.0108 | UB min=2.8610, max=39.4427
  Layer 5: LB min=-5.4206, max=33.9057 | UB min=5.5303, max=42.9895
  Layer 6: LB min=6.4312, max=21.7009 | UB min=21.4550, max=36.6873
  Layer 7: LB min=-3.0184, max=-3.0184 | UB min=8.9981, max=8.9981
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.034525394439697266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04638218879699707
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0033593177795410156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011570453643798828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010914802551269531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010464191436767578

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.6957, max=5.7012 | UB min=0.0000, max=7.8954
  Layer 2: LB min=0.0000, max=6.4557 | UB min=2.9385, max=10.6812
  Layer 3: LB min=-11.1630, max=24.4237 | UB min=-3.8373, max=35.9648
  Layer 4: LB min=-5.8340, max=30.4102 | UB min=2.6549, max=38.5697
  Layer 5: LB min=-5.1441, max=33.3048 | UB min=5.3217, max=41.9805
  Layer 6: LB min=6.5818, max=21.1557 | UB min=21.0009, max=35.6832
  Layer 7: LB min=-2.6492, max=-2.6492 | UB min=8.8797, max=8.8797
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.030159950256347656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03885602951049805
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00164031982421875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013511180877685547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.006931781768798828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004486083984375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.7147, max=5.6871 | UB min=0.0000, max=7.9119
  Layer 2: LB min=0.0000, max=6.4225 | UB min=2.9739, max=10.7133
  Layer 3: LB min=-11.2302, max=24.7191 | UB min=-3.7865, max=36.4536
  Layer 4: LB min=-5.9299, max=30.7105 | UB min=2.7531, max=39.0051
  Layer 5: LB min=-5.2754, max=33.6092 | UB min=5.4257, max=42.4789
  Layer 6: LB min=6.5084, max=21.4283 | UB min=21.2233, max=36.1823
  Layer 7: LB min=-2.8287, max=-2.8287 | UB min=8.9370, max=8.9370
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04343533515930176
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.047304391860961914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015523433685302734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010938644409179688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002205371856689453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001438140869140625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.7242, max=5.6801 | UB min=0.0000, max=7.9202
  Layer 2: LB min=0.0000, max=6.4058 | UB min=2.9917, max=10.7294
  Layer 3: LB min=-11.2638, max=24.8640 | UB min=-3.7574, max=36.6985
  Layer 4: LB min=-5.9805, max=30.8607 | UB min=2.8070, max=39.2239
  Layer 5: LB min=-5.3478, max=33.7573 | UB min=5.4780, max=42.7341
  Layer 6: LB min=6.4698, max=21.5646 | UB min=21.3391, max=36.4348
  Layer 7: LB min=-2.9235, max=-2.9235 | UB min=8.9677, max=8.9677
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04689145088195801
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030910491943359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001135110855102539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013260841369628906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011162757873535156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011451244354248047

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.7194, max=5.6836 | UB min=0.0000, max=7.9160
  Layer 2: LB min=0.0000, max=6.4141 | UB min=2.9828, max=10.7213
  Layer 3: LB min=-11.2470, max=24.7915 | UB min=-3.7720, max=36.5760
  Layer 4: LB min=-5.9552, max=30.7856 | UB min=2.7801, max=39.1145
  Layer 5: LB min=-5.3116, max=33.6832 | UB min=5.4518, max=42.6065
  Layer 6: LB min=6.4891, max=21.4965 | UB min=21.2812, max=36.3086
  Layer 7: LB min=-2.8761, max=-2.8761 | UB min=8.9524, max=8.9524
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0254366397857666
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02324509620666504
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010745525360107422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.006482839584350586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0017275810241699219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0050923824310302734

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.7147, max=5.6871 | UB min=0.0000, max=7.9119
  Layer 2: LB min=0.0000, max=6.4225 | UB min=2.9739, max=10.7133
  Layer 3: LB min=-11.2302, max=24.7191 | UB min=-3.7865, max=36.4536
  Layer 4: LB min=-5.9299, max=30.7105 | UB min=2.7531, max=39.0051
  Layer 5: LB min=-5.2754, max=33.6092 | UB min=5.4257, max=42.4789
  Layer 6: LB min=6.5084, max=21.4283 | UB min=21.2233, max=36.1823
  Layer 7: LB min=-2.8287, max=-2.8287 | UB min=8.9370, max=8.9370
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.030554771423339844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03138327598571777
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013959407806396484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011990070343017578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011513233184814453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011947154998779297
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.002228975296020508
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0011005401611328125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001081228256225586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00131988525390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.011822700500488281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018787384033203125
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.017066001892089844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02090907096862793
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011250972747802734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012340545654296875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010395050048828125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011343955993652344
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03132033348083496
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019625425338745117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001154184341430664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012781620025634766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010371208190917969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011403560638427734
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.049559593200683594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02875995635986328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001310110092163086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004450321197509766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0022771358489990234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0042002201080322266
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.031880855560302734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02703094482421875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011281967163085938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010917186737060547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012311935424804688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.007875204086303711
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.033466339111328125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020943403244018555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011048316955566406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010976791381835938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0038237571716308594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014333724975585938
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0504300594329834
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0375826358795166
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011799335479736328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00354766845703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012636184692382812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0028543472290039062
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.045243263244628906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019490957260131836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001104116439819336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.007219791412353516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015575885772705078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0047740936279296875
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03421807289123535
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02051568031311035
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001177072525024414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014257431030273438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012063980102539062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002445220947265625
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03733372688293457
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03656268119812012
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012028217315673828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010979175567626953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.006563901901245117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014569759368896484
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03954744338989258
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04690670967102051
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012385845184326172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0033316612243652344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0017113685607910156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016162395477294922
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029676198959350586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04527091979980469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0020804405212402344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014545917510986328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011353492736816406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014805793762207031
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03269457817077637
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02654409408569336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014486312866210938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009167194366455078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0037882328033447266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001535177230834961
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03587031364440918
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03839731216430664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011937618255615234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010075569152832031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011641979217529297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011146068572998047
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.045763254165649414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03945589065551758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001073598861694336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011627674102783203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010669231414794922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012516975402832031

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-21.1373, max=0.0000 | UB min=0.0000, max=45.3236
  Layer 2: LB min=0.0000, max=0.0000 | UB min=60.8619, max=93.2607
  Layer 3: LB min=-188.4960, max=230.9631 | UB min=107.6139, max=706.1479
  Layer 4: LB min=-270.3340, max=296.5221 | UB min=209.4373, max=686.1248
  Layer 5: LB min=-328.7570, max=375.7255 | UB min=275.8401, max=869.4008
  Layer 6: LB min=-140.3326, max=201.2217 | UB min=588.2056, max=686.1248
  Layer 7: LB min=-528.1277, max=-528.1277 | UB min=152.6265, max=152.6265
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.012241601943969727
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015948772430419922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011005401611328125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010919570922851562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00107574462890625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011951923370361328

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-11.1171, max=0.0000 | UB min=0.0000, max=25.5707
  Layer 2: LB min=0.0000, max=0.0000 | UB min=32.2409, max=49.7860
  Layer 3: LB min=-99.9857, max=135.4708 | UB min=54.2974, max=383.0384
  Layer 4: LB min=-141.7392, max=167.2578 | UB min=108.2056, max=372.4677
  Layer 5: LB min=-171.5483, max=211.1920 | UB min=142.9950, max=467.5290
  Layer 6: LB min=-73.4457, max=118.0448 | UB min=306.2310, max=372.4677
  Layer 7: LB min=-273.3978, max=-273.3978 | UB min=79.5747, max=79.5747
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03785395622253418
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.046561479568481445
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0017306804656982422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013990402221679688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001316070556640625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012247562408447266

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.9114, max=0.0000 | UB min=0.0000, max=15.5698
  Layer 2: LB min=0.0000, max=0.0000 | UB min=17.1279, max=27.7218
  Layer 3: LB min=-53.1214, max=89.2098 | UB min=25.4627, max=215.4265
  Layer 4: LB min=-72.3578, max=102.7232 | UB min=54.0490, max=208.1569
  Layer 5: LB min=-87.2291, max=128.4651 | UB min=71.0721, max=256.8636
  Layer 6: LB min=-37.0756, max=77.4190 | UB min=156.2900, max=208.1569
  Layer 7: LB min=-135.2487, max=-135.2487 | UB min=45.2354, max=45.2354
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.014088630676269531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.011116504669189453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011930465698242188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011186599731445312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010843276977539062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011835098266601562

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.2212, max=2.2489 | UB min=0.0000, max=10.7594
  Layer 2: LB min=0.0000, max=1.0803 | UB min=9.0953, max=17.2695
  Layer 3: LB min=-28.5952, max=61.9985 | UB min=7.6517, max=121.1525
  Layer 4: LB min=-34.1219, max=68.1572 | UB min=23.4976, max=116.0194
  Layer 5: LB min=-39.6547, max=80.0353 | UB min=31.4447, max=138.1295
  Layer 6: LB min=-9.1744, max=54.8210 | UB min=73.4810, max=116.0194
  Layer 7: LB min=-54.9042, max=-54.9042 | UB min=23.9801, max=23.9801
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.036788225173950195
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02012348175048828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009944438934326172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007748603820800781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009613037109375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009608268737792969

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8562, max=4.1443 | UB min=0.0000, max=8.4847
  Layer 2: LB min=0.0000, max=5.1194 | UB min=4.8167, max=12.8924
  Layer 3: LB min=-17.0879, max=39.6640 | UB min=-0.5917, max=67.3051
  Layer 4: LB min=-17.2031, max=45.5175 | UB min=9.1265, max=66.0193
  Layer 5: LB min=-17.7224, max=50.1771 | UB min=12.2090, max=75.8306
  Layer 6: LB min=0.6666, max=37.6524 | UB min=34.9313, max=66.0193
  Layer 7: LB min=-17.6173, max=-17.6173 | UB min=13.5406, max=13.5406
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.013194561004638672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.013450860977172852
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016634464263916016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012602806091308594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012505054473876953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011749267578125

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.1724, max=5.0931 | UB min=0.0000, max=7.3425
  Layer 2: LB min=0.0000, max=7.0719 | UB min=2.4149, max=10.9458
  Layer 3: LB min=-12.2340, max=25.1014 | UB min=-4.6412, max=39.2571
  Layer 4: LB min=-10.1523, max=31.1208 | UB min=2.2812, max=39.6792
  Layer 5: LB min=-7.5324, max=32.7565 | UB min=3.9146, max=42.9403
  Layer 6: LB min=4.9777, max=25.1014 | UB min=17.9381, max=39.2571
  Layer 7: LB min=-2.9679, max=-2.9679 | UB min=9.0124, max=9.0124
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03554844856262207
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03407168388366699
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012090206146240234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0017614364624023438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00133514404296875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010802745819091797

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-0.8305, max=5.5690 | UB min=0.0000, max=6.7709
  Layer 2: LB min=0.0000, max=8.0084 | UB min=1.2226, max=9.9493
  Layer 3: LB min=-10.1493, max=14.5799 | UB min=-6.4090, max=22.0212
  Layer 4: LB min=-7.2280, max=19.9842 | UB min=-1.5780, max=24.3372
  Layer 5: LB min=-4.1151, max=21.0506 | UB min=0.4401, max=25.4956
  Layer 6: LB min=6.7749, max=14.5799 | UB min=11.1462, max=22.0212
  Layer 7: LB min=2.4704, max=2.4704 | UB min=7.0616, max=7.0616
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028867483139038086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027830839157104492
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014519691467285156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0035665035247802734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012404918670654297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013318061828613281

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.0015, max=5.3308 | UB min=0.0000, max=7.0567
  Layer 2: LB min=0.0000, max=7.5406 | UB min=1.8169, max=10.4556
  Layer 3: LB min=-11.1745, max=20.0942 | UB min=-5.4908, max=31.0133
  Layer 4: LB min=-8.5508, max=25.6354 | UB min=0.3474, max=32.1058
  Layer 5: LB min=-5.3821, max=26.9733 | UB min=2.1494, max=33.8734
  Layer 6: LB min=5.8515, max=20.0942 | UB min=13.9410, max=31.0133
  Layer 7: LB min=0.2208, max=0.2208 | UB min=8.0362, max=8.0362
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.005401134490966797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.004496097564697266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013051033020019531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001321554183959961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0029354095458984375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002198934555053711

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.0870, max=5.2119 | UB min=0.0000, max=7.1996
  Layer 2: LB min=0.0000, max=7.3063 | UB min=2.1153, max=10.7099
  Layer 3: LB min=-11.7359, max=22.6955 | UB min=-5.0611, max=35.2097
  Layer 4: LB min=-9.4319, max=28.4766 | UB min=1.3168, max=35.9946
  Layer 5: LB min=-6.4581, max=29.9299 | UB min=3.0386, max=38.4546
  Layer 6: LB min=5.3903, max=22.6955 | UB min=15.9837, max=35.2097
  Layer 7: LB min=-1.3792, max=-1.3792 | UB min=8.5256, max=8.5256
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.032183170318603516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.014900445938110352
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00484776496887207
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001956462860107422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016682147979736328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.006694793701171875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.1297, max=5.1524 | UB min=0.0000, max=7.2710
  Layer 2: LB min=0.0000, max=7.1890 | UB min=2.2650, max=10.8280
  Layer 3: LB min=-11.9853, max=23.9995 | UB min=-4.8499, max=37.3347
  Layer 4: LB min=-9.7928, max=29.8967 | UB min=1.7992, max=37.9356
  Layer 5: LB min=-6.9878, max=31.4094 | UB min=3.4761, max=40.7629
  Layer 6: LB min=5.1839, max=23.9995 | UB min=16.9589, max=37.3347
  Layer 7: LB min=-2.1719, max=-2.1719 | UB min=8.7690, max=8.7690
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.035835981369018555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023891925811767578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001268625259399414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013647079467773438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0023484230041503906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017409324645996094

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.1511, max=5.1228 | UB min=0.0000, max=7.3067
  Layer 2: LB min=0.0000, max=7.1305 | UB min=2.3400, max=10.8869
  Layer 3: LB min=-12.1097, max=24.6298 | UB min=-4.7453, max=38.3753
  Layer 4: LB min=-9.9727, max=30.5859 | UB min=2.0402, max=38.8847
  Layer 5: LB min=-7.2598, max=32.1347 | UB min=3.6952, max=41.9032
  Layer 6: LB min=5.0808, max=24.6298 | UB min=17.4479, max=38.3753
  Layer 7: LB min=-2.5697, max=-2.5697 | UB min=8.8907, max=8.8907
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.026849031448364258
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020359039306640625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015494823455810547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0016384124755859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001707315444946289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018062591552734375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.1404, max=5.1376 | UB min=0.0000, max=7.2889
  Layer 2: LB min=0.0000, max=7.1598 | UB min=2.3025, max=10.8574
  Layer 3: LB min=-12.0475, max=24.3252 | UB min=-4.7975, max=37.8656
  Layer 4: LB min=-9.8829, max=30.2516 | UB min=1.9197, max=38.4205
  Layer 5: LB min=-7.1233, max=31.7790 | UB min=3.5856, max=41.3399
  Layer 6: LB min=5.1324, max=24.3252 | UB min=17.2021, max=37.8656
  Layer 7: LB min=-2.3707, max=-2.3707 | UB min=8.8299, max=8.8299
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.043976545333862305
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04117989540100098
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004301786422729492
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012135505676269531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012698173522949219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011687278747558594

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.1457, max=5.1302 | UB min=0.0000, max=7.2978
  Layer 2: LB min=0.0000, max=7.1451 | UB min=2.3212, max=10.8722
  Layer 3: LB min=-12.0786, max=24.4881 | UB min=-4.7714, max=38.1310
  Layer 4: LB min=-9.9279, max=30.4290 | UB min=1.9800, max=38.6629
  Layer 5: LB min=-7.1916, max=31.9637 | UB min=3.6404, max=41.6284
  Layer 6: LB min=5.1066, max=24.4881 | UB min=17.3251, max=38.1310
  Layer 7: LB min=-2.4702, max=-2.4702 | UB min=8.8603, max=8.8603
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.033052921295166016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03063201904296875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011510848999023438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010819435119628906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012803077697753906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012049674987792969

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.1484, max=5.1265 | UB min=0.0000, max=7.3023
  Layer 2: LB min=0.0000, max=7.1378 | UB min=2.3306, max=10.8795
  Layer 3: LB min=-12.0942, max=24.5695 | UB min=-4.7583, max=38.2637
  Layer 4: LB min=-9.9503, max=30.5178 | UB min=2.0101, max=38.7841
  Layer 5: LB min=-7.2257, max=32.0561 | UB min=3.6678, max=41.7727
  Layer 6: LB min=5.0937, max=24.5695 | UB min=17.3865, max=38.2637
  Layer 7: LB min=-2.5199, max=-2.5199 | UB min=8.8755, max=8.8755
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03303265571594238
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015361309051513672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001260519027709961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0024101734161376953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0019268989562988281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001680612564086914

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.1457, max=5.1302 | UB min=0.0000, max=7.2978
  Layer 2: LB min=0.0000, max=7.1451 | UB min=2.3212, max=10.8722
  Layer 3: LB min=-12.0786, max=24.4881 | UB min=-4.7714, max=38.1310
  Layer 4: LB min=-9.9279, max=30.4290 | UB min=1.9800, max=38.6629
  Layer 5: LB min=-7.1916, max=31.9637 | UB min=3.6404, max=41.6284
  Layer 6: LB min=5.1066, max=24.4881 | UB min=17.3251, max=38.1310
  Layer 7: LB min=-2.4702, max=-2.4702 | UB min=8.8603, max=8.8603
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.036673784255981445
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.016784191131591797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011615753173828125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010309219360351562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003086090087890625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004447221755981445
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027733325958251953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03454732894897461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0019099712371826172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010280609130859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003609180450439453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018062591552734375
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01257014274597168
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.009177207946777344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009713172912597656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0017158985137939453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012972354888916016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011317729949951172
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0013780593872070312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.002291440963745117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015020370483398438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0020647048950195312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018353462219238281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019001960754394531
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04863286018371582
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.032423973083496094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011434555053710938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001055002212524414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001260519027709961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011608600616455078
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04234671592712402
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027953624725341797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015735626220703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0037665367126464844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001434326171875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014171600341796875
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05926156044006348
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023137807846069336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001321554183959961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011692047119140625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0023560523986816406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014750957489013672
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.011980533599853516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01087808609008789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010838508605957031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009684562683105469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012402534484863281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010821819305419922
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.042647361755371094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.021442651748657227
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012900829315185547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010738372802734375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011048316955566406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011126995086669922
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.033186912536621094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03816723823547363
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011510848999023438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010714530944824219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011327266693115234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001275777816772461
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02865147590637207
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.031002283096313477
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011444091796875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009500980377197266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0017445087432861328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0026328563690185547
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.033498287200927734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.038222551345825195
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0021219253540039062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0021669864654541016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011904239654541016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0023910999298095703
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.037386417388916016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03142499923706055
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0018045902252197266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013179779052734375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012929439544677734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012731552124023438
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04106402397155762
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.05807900428771973
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014491081237792969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010962486267089844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011801719665527344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012745857238769531
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02950453758239746
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.013815164566040039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014607906341552734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013914108276367188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002981424331665039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013537406921386719
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027895450592041016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017946243286132812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002130270004272461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0015859603881835938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015192031860351562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015380382537841797

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-40.6862, max=0.0000 | UB min=0.0000, max=55.9807
  Layer 2: LB min=-59.3281, max=0.0000 | UB min=0.0000, max=93.3212
  Layer 3: LB min=-186.7726, max=231.1129 | UB min=105.4779, max=700.1001
  Layer 4: LB min=-266.7504, max=298.9606 | UB min=208.6122, max=678.3906
  Layer 5: LB min=-325.8034, max=373.9977 | UB min=274.0912, max=862.1071
  Layer 6: LB min=-136.5103, max=201.3875 | UB min=585.9352, max=678.3906
  Layer 7: LB min=-520.8062, max=-520.8062 | UB min=148.6481, max=148.6481
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.030756473541259766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03318142890930176
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0036144256591796875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014948844909667969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0022208690643310547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.007920980453491211

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-22.8782, max=0.0000 | UB min=0.0000, max=31.7560
  Layer 2: LB min=-30.9669, max=0.0000 | UB min=0.0000, max=49.9524
  Layer 3: LB min=-96.0087, max=136.8949 | UB min=50.5807, max=372.9179
  Layer 4: LB min=-134.3696, max=171.4042 | UB min=105.6748, max=350.9061
  Layer 5: LB min=-165.0349, max=209.0378 | UB min=138.5418, max=450.8304
  Layer 6: LB min=-65.5102, max=118.1195 | UB min=299.9653, max=348.5884
  Layer 7: LB min=-254.6461, max=-254.6461 | UB min=73.0661, max=73.0661
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03250312805175781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015865087509155273
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001073598861694336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001148223876953125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004373073577880859
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.005644321441650391

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-13.7331, max=1.2072 | UB min=0.0000, max=19.4905
  Layer 2: LB min=-15.6274, max=1.1222 | UB min=0.0000, max=28.3392
  Layer 3: LB min=-47.6938, max=88.9475 | UB min=19.0695, max=201.6276
  Layer 4: LB min=-60.4306, max=108.1525 | UB min=47.7373, max=185.3406
  Layer 5: LB min=-76.2993, max=124.5985 | UB min=63.6130, max=233.6251
  Layer 6: LB min=-23.2576, max=76.7815 | UB min=144.9084, max=178.7601
  Layer 7: LB min=-108.9860, max=-108.9860 | UB min=34.3821, max=34.3821
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.007698774337768555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.008455991744995117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010993480682373047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013523101806640625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0025289058685302734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0029098987579345703

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-9.0935, max=5.3262 | UB min=0.0000, max=14.6406
  Layer 2: LB min=-8.1790, max=7.2711 | UB min=0.0000, max=19.3232
  Layer 3: LB min=-24.8862, max=51.4485 | UB min=2.3284, max=101.6270
  Layer 4: LB min=-22.9850, max=70.5811 | UB min=17.7145, max=99.0599
  Layer 5: LB min=-30.6329, max=67.5294 | UB min=28.1400, max=113.1571
  Layer 6: LB min=1.2583, max=46.9785 | UB min=70.6555, max=89.3505
  Layer 7: LB min=-37.2848, max=-37.2848 | UB min=15.4690, max=15.4690
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0010221004486083984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009210109710693359
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010404586791992188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0020704269409179688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016622543334960938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018596649169921875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.7545, max=7.3967 | UB min=-2.0540, max=12.1802
  Layer 2: LB min=-4.6576, max=9.9699 | UB min=0.0000, max=15.9021
  Layer 3: LB min=-15.8518, max=31.8718 | UB min=-4.1870, max=55.1533
  Layer 4: LB min=-10.2362, max=50.1234 | UB min=7.3260, max=63.3426
  Layer 5: LB min=-11.8029, max=39.8773 | UB min=14.4599, max=59.2023
  Layer 6: LB min=14.5084, max=30.1937 | UB min=42.4290, max=50.1144
  Layer 7: LB min=-12.9439, max=-12.9439 | UB min=9.0020, max=9.0020
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0465550422668457
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03620767593383789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013680458068847656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0015583038330078125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0020635128021240234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015101432800292969

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.5746, max=8.4372 | UB min=-3.1302, max=10.9285
  Layer 2: LB min=-3.0319, max=11.1354 | UB min=0.0000, max=14.1882
  Layer 3: LB min=-12.2647, max=19.0721 | UB min=-6.9466, max=29.8253
  Layer 4: LB min=-5.5277, max=36.8043 | UB min=3.2201, max=43.1820
  Layer 5: LB min=-3.6410, max=23.4273 | UB min=8.3263, max=31.7925
  Layer 6: LB min=18.1208, max=19.0721 | UB min=28.6066, max=30.1826
  Layer 7: LB min=-3.1973, max=-3.1973 | UB min=5.8681, max=5.8681
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03644609451293945
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02179408073425293
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010154247283935547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0036079883575439453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.006613731384277344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001294851303100586

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-4.9831, max=8.9582 | UB min=-3.6690, max=10.3006
  Layer 2: LB min=-2.3091, max=11.6845 | UB min=-0.4813, max=13.3269
  Layer 3: LB min=-10.8872, max=16.2984 | UB min=-8.1652, max=20.7818
  Layer 4: LB min=-3.2440, max=28.4087 | UB min=1.3362, max=31.8102
  Layer 5: LB min=-0.2676, max=16.8742 | UB min=5.5319, max=20.8629
  Layer 6: LB min=10.4224, max=19.6294 | UB min=15.4331, max=24.8861
  Layer 7: LB min=0.5223, max=0.5223 | UB min=4.4855, max=4.4855
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01060795783996582
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.014432907104492188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0024225711822509766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011935234069824219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012731552124023438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012404918670654297

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.2789, max=8.6977 | UB min=-3.3996, max=10.6148
  Layer 2: LB min=-2.6710, max=11.4100 | UB min=-0.0564, max=13.7580
  Layer 3: LB min=-11.5002, max=15.5160 | UB min=-7.6160, max=22.8376
  Layer 4: LB min=-4.3850, max=32.6407 | UB min=2.2615, max=37.4981
  Layer 5: LB min=-1.9122, max=20.2224 | UB min=6.8694, max=26.3200
  Layer 6: LB min=14.8349, max=18.8758 | UB min=22.0227, max=27.4678
  Layer 7: LB min=-1.2530, max=-1.2530 | UB min=5.1488, max=5.1488
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.017230749130249023
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.021477699279785156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012471675872802734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001056671142578125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011658668518066406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011646747589111328

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.4268, max=8.5674 | UB min=-3.2649, max=10.7717
  Layer 2: LB min=-2.8515, max=11.2727 | UB min=0.0000, max=13.9731
  Layer 3: LB min=-11.8703, max=16.9636 | UB min=-7.2848, max=26.3492
  Layer 4: LB min=-4.9563, max=34.7280 | UB min=2.7429, max=40.3401
  Layer 5: LB min=-2.7753, max=21.8358 | UB min=7.5895, max=29.0544
  Layer 6: LB min=16.9636, max=18.4984 | UB min=25.3146, max=28.8236
  Layer 7: LB min=-2.2144, max=-2.2144 | UB min=5.5031, max=5.5031
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0020084381103515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0020036697387695312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002407550811767578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0043299198150634766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003235340118408203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013885498046875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.3528, max=8.6326 | UB min=-3.3323, max=10.6932
  Layer 2: LB min=-2.7613, max=11.3414 | UB min=0.0000, max=13.8655
  Layer 3: LB min=-11.6736, max=15.9107 | UB min=-7.4597, max=24.5903
  Layer 4: LB min=-4.6706, max=33.6900 | UB min=2.5010, max=38.9191
  Layer 5: LB min=-2.3348, max=21.0399 | UB min=7.2208, max=27.6854
  Layer 6: LB min=15.9107, max=18.6872 | UB min=23.6686, max=28.1360
  Layer 7: LB min=-1.7267, max=-1.7267 | UB min=5.3210, max=5.3210
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0486297607421875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03577780723571777
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00122833251953125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001051187515258789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012722015380859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012249946594238281

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.3159, max=8.6651 | UB min=-3.3659, max=10.6540
  Layer 2: LB min=-2.7161, max=11.3757 | UB min=-0.0033, max=13.8118
  Layer 3: LB min=-11.5767, max=15.4185 | UB min=-7.5477, max=23.6983
  Layer 4: LB min=-4.5278, max=33.1703 | UB min=2.3771, max=38.2086
  Layer 5: LB min=-2.1136, max=20.6404 | UB min=7.0367, max=27.0014
  Layer 6: LB min=15.3861, max=18.7815 | UB min=22.8457, max=27.7905
  Layer 7: LB min=-1.4835, max=-1.4835 | UB min=5.2306, max=5.2306
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03110671043395996
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.039211273193359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012557506561279297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011677742004394531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011713504791259766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011959075927734375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.3344, max=8.6488 | UB min=-3.3491, max=10.6736
  Layer 2: LB min=-2.7387, max=11.3585 | UB min=0.0000, max=13.8386
  Layer 3: LB min=-11.6245, max=15.6493 | UB min=-7.5042, max=24.1436
  Layer 4: LB min=-4.5992, max=33.4305 | UB min=2.4388, max=38.5639
  Layer 5: LB min=-2.2237, max=20.8408 | UB min=7.1282, max=27.3433
  Layer 6: LB min=15.6493, max=18.7343 | UB min=23.2571, max=27.9626
  Layer 7: LB min=-1.6046, max=-1.6046 | UB min=5.2755, max=5.2755
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03947901725769043
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02498340606689453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001064300537109375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001230478286743164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002379179000854492
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014781951904296875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.3251, max=8.6570 | UB min=-3.3575, max=10.6638
  Layer 2: LB min=-2.7274, max=11.3671 | UB min=0.0000, max=13.8252
  Layer 3: LB min=-11.5999, max=15.5186 | UB min=-7.5266, max=23.9200
  Layer 4: LB min=-4.5635, max=33.3007 | UB min=2.4077, max=38.3862
  Layer 5: LB min=-2.1680, max=20.7413 | UB min=7.0819, max=27.1723
  Layer 6: LB min=15.5186, max=18.7579 | UB min=23.0514, max=27.8758
  Layer 7: LB min=-1.5437, max=-1.5437 | UB min=5.2528, max=5.2528
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03739213943481445
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03637099266052246
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013070106506347656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010182857513427734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014154911041259766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011980533599853516

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.3205, max=8.6610 | UB min=-3.3617, max=10.6589
  Layer 2: LB min=-2.7218, max=11.3714 | UB min=0.0000, max=13.8185
  Layer 3: LB min=-11.5876, max=15.4533 | UB min=-7.5378, max=23.8081
  Layer 4: LB min=-4.5457, max=33.2359 | UB min=2.3921, max=38.2974
  Layer 5: LB min=-2.1401, max=20.6915 | UB min=7.0587, max=27.0868
  Layer 6: LB min=15.4533, max=18.7697 | UB min=22.9485, max=27.8323
  Layer 7: LB min=-1.5132, max=-1.5132 | UB min=5.2414, max=5.2414
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.000982522964477539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006532669067382812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0007333755493164062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007801055908203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008804798126220703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009882450103759766

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.3159, max=8.6651 | UB min=-3.3659, max=10.6540
  Layer 2: LB min=-2.7161, max=11.3757 | UB min=-0.0033, max=13.8118
  Layer 3: LB min=-11.5767, max=15.4185 | UB min=-7.5477, max=23.6983
  Layer 4: LB min=-4.5278, max=33.1703 | UB min=2.3771, max=38.2086
  Layer 5: LB min=-2.1136, max=20.6404 | UB min=7.0367, max=27.0014
  Layer 6: LB min=15.3861, max=18.7815 | UB min=22.8457, max=27.7905
  Layer 7: LB min=-1.4835, max=-1.4835 | UB min=5.2306, max=5.2306
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04279494285583496
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026586294174194336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011484622955322266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011110305786132812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012710094451904297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0024161338806152344
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.014331579208374023
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022027015686035156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011487007141113281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010144710540771484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001222848892211914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017101764678955078
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03644752502441406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04807925224304199
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015401840209960938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013592243194580078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011522769927978516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012784004211425781
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.050116777420043945
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020273208618164062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001546621322631836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001287698745727539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002872943878173828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0027348995208740234
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04579877853393555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0160675048828125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012333393096923828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0019268989562988281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.006506204605102539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019330978393554688
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04645538330078125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.018396615982055664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011491775512695312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004090547561645508
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008652210235595703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010764598846435547
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03342771530151367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04006600379943848
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001990795135498047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012285709381103516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0017428398132324219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014019012451171875
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0111083984375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.006834506988525391
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001953601837158203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012848377227783203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011425018310546875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010712146759033203
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04237985610961914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022984743118286133
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0026612281799316406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.005112409591674805
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015385150909423828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015358924865722656
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05253767967224121
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03614974021911621
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.005914449691772461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013518333435058594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003449678421020508
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014412403106689453
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04973196983337402
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02291727066040039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011227130889892578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011372566223144531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005784034729003906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011663436889648438
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.024869441986083984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0073053836822509766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002405405044555664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0036127567291259766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0044269561767578125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013747215270996094
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02936410903930664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026617050170898438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001169443130493164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0015177726745605469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001087188720703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003818988800048828
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04148530960083008
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.040936946868896484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011315345764160156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012924671173095703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005464315414428711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013308525085449219
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04267621040344238
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01491236686706543
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001203775405883789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010950565338134766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016481876373291016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001310586929321289
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03472590446472168
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028329133987426758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001481771469116211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014107227325439453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013060569763183594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012989044189453125

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-38.2362, max=0.0000 | UB min=0.0000, max=52.8419
  Layer 2: LB min=-59.5002, max=0.0000 | UB min=0.0000, max=91.4805
  Layer 3: LB min=-186.0435, max=223.1641 | UB min=105.7873, max=690.9216
  Layer 4: LB min=-266.8692, max=289.3281 | UB min=206.8498, max=670.1929
  Layer 5: LB min=-324.7184, max=365.5592 | UB min=271.9561, max=852.1200
  Layer 6: LB min=-138.3249, max=195.1645 | UB min=580.1642, max=670.1929
  Layer 7: LB min=-520.1788, max=-520.1788 | UB min=151.1506, max=151.1506
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03812122344970703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019338369369506836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001171112060546875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001142263412475586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011489391326904297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014536380767822266

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-19.5565, max=0.0000 | UB min=0.0000, max=27.4051
  Layer 2: LB min=-31.7733, max=0.0000 | UB min=0.0000, max=47.8216
  Layer 3: LB min=-97.5031, max=125.5395 | UB min=52.1266, max=364.8928
  Layer 4: LB min=-138.4214, max=158.6047 | UB min=105.5113, max=349.9709
  Layer 5: LB min=-167.4238, max=198.7491 | UB min=138.7497, max=445.1636
  Layer 6: LB min=-71.2098, max=110.5359 | UB min=297.7053, max=349.9709
  Layer 7: LB min=-262.0695, max=-262.0695 | UB min=78.6709, max=78.6709
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03275036811828613
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04887032508850098
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001329183578491211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001026153564453125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010247230529785156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011334419250488281

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-10.1049, max=0.0000 | UB min=0.0000, max=15.5188
  Layer 2: LB min=-17.5514, max=0.0000 | UB min=0.0000, max=26.8131
  Layer 3: LB min=-51.2439, max=77.2770 | UB min=23.2149, max=196.9352
  Layer 4: LB min=-70.6348, max=92.8108 | UB min=51.7305, max=183.6109
  Layer 5: LB min=-84.3496, max=114.3190 | UB min=67.6252, max=234.6817
  Layer 6: LB min=-35.7631, max=68.7279 | UB min=148.6807, max=183.6109
  Layer 7: LB min=-125.3907, max=-125.3907 | UB min=42.0874, max=42.0874
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.056853532791137695
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03020167350769043
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012009143829345703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012753009796142578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012350082397460938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.010588645935058594

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.3236, max=2.0979 | UB min=0.0000, max=10.9294
  Layer 2: LB min=-10.4816, max=2.3773 | UB min=0.0000, max=17.9242
  Layer 3: LB min=-28.3385, max=47.5328 | UB min=5.3023, max=104.2397
  Layer 4: LB min=-34.9077, max=55.2184 | UB min=22.9022, max=96.5682
  Layer 5: LB min=-39.7335, max=64.8101 | UB min=30.7520, max=120.9777
  Layer 6: LB min=-14.4118, max=43.4254 | UB min=70.5135, max=96.5682
  Layer 7: LB min=-53.5099, max=-53.5099 | UB min=22.8623, max=22.8623
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.032128095626831055
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.05111408233642578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002173900604248047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0032625198364257812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012679100036621094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013120174407958984

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.9221, max=4.1178 | UB min=0.0000, max=8.6110
  Layer 2: LB min=-7.0259, max=6.6340 | UB min=0.0000, max=14.1582
  Layer 3: LB min=-17.3590, max=28.0871 | UB min=-3.9158, max=50.7000
  Layer 4: LB min=-17.7512, max=32.7759 | UB min=10.7286, max=50.7000
  Layer 5: LB min=-17.0872, max=33.6136 | UB min=13.3412, max=58.8346
  Layer 6: LB min=-2.9972, max=26.8883 | UB min=33.3902, max=50.7000
  Layer 7: LB min=-18.9490, max=-18.9490 | UB min=13.4776, max=13.4776
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02722001075744629
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0320734977722168
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002825021743774414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0023963451385498047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001232147216796875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012769699096679688

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.7213, max=5.1283 | UB min=0.0000, max=7.4511
  Layer 2: LB min=-5.4863, max=8.5982 | UB min=-1.8413, max=12.3947
  Layer 3: LB min=-13.4066, max=15.7227 | UB min=-7.6292, max=27.1024
  Layer 4: LB min=-9.3459, max=19.1126 | UB min=5.0572, max=27.1024
  Layer 5: LB min=-6.3075, max=16.4786 | UB min=5.3836, max=27.5716
  Layer 6: LB min=1.5904, max=15.7227 | UB min=16.8003, max=27.1024
  Layer 7: LB min=-4.3857, max=-4.3857 | UB min=8.8639, max=8.8639
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02514338493347168
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04501819610595703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013020038604736328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011501312255859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010886192321777344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011966228485107422

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.1209, max=5.6336 | UB min=0.0000, max=6.8712
  Layer 2: LB min=-4.7195, max=9.5791 | UB min=-2.8417, max=11.5294
  Layer 3: LB min=-11.7065, max=10.0810 | UB min=-8.9938, max=15.9665
  Layer 4: LB min=-5.4461, max=12.2829 | UB min=1.3011, max=16.2048
  Layer 5: LB min=-1.8745, max=10.0810 | UB min=2.1966, max=15.9665
  Layer 6: LB min=3.1966, max=10.0810 | UB min=9.9065, max=15.9665
  Layer 7: LB min=0.6862, max=0.6862 | UB min=6.2798, max=6.2798
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.007475137710571289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.010040521621704102
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013794898986816406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004608154296875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0024492740631103516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018353462219238281

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.4211, max=5.3809 | UB min=0.0000, max=7.1611
  Layer 2: LB min=-5.1020, max=9.0888 | UB min=-2.3383, max=11.9617
  Layer 3: LB min=-12.5169, max=13.3290 | UB min=-8.3361, max=21.9355
  Layer 4: LB min=-7.3633, max=16.1010 | UB min=3.1397, max=21.9355
  Layer 5: LB min=-3.9146, max=13.4118 | UB min=3.7179, max=21.9355
  Layer 6: LB min=2.5654, max=13.3290 | UB min=13.1973, max=21.9355
  Layer 7: LB min=-1.6740, max=-1.6740 | UB min=7.7586, max=7.7586
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04914069175720215
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030109405517578125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015087127685546875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010437965393066406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011246204376220703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0036766529083251953

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.5712, max=5.2546 | UB min=0.0000, max=7.3061
  Layer 2: LB min=-5.2940, max=8.8436 | UB min=-2.0867, max=12.1781
  Layer 3: LB min=-12.9335, max=14.5259 | UB min=-8.0059, max=24.4967
  Layer 4: LB min=-8.3381, max=17.6099 | UB min=4.0240, max=24.4967
  Layer 5: LB min=-5.0532, max=14.9913 | UB min=4.5038, max=24.4967
  Layer 6: LB min=2.0994, max=14.5259 | UB min=14.8939, max=24.4967
  Layer 7: LB min=-2.9187, max=-2.9187 | UB min=8.2694, max=8.2694
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027827739715576172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02752685546875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012466907501220703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010645389556884766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0017786026000976562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011227130889892578

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.6462, max=5.1915 | UB min=0.0000, max=7.3786
  Layer 2: LB min=-5.3902, max=8.7209 | UB min=-1.9632, max=12.2864
  Layer 3: LB min=-13.1696, max=15.1244 | UB min=-7.8256, max=25.7944
  Layer 4: LB min=-8.8395, max=18.3613 | UB min=4.5222, max=25.7944
  Layer 5: LB min=-5.6691, max=15.7477 | UB min=4.9273, max=25.9642
  Layer 6: LB min=1.8451, max=15.1244 | UB min=15.8136, max=25.7944
  Layer 7: LB min=-3.6143, max=-3.6143 | UB min=8.5523, max=8.5523
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03612256050109863
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04478120803833008
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012195110321044922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013427734375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0019757747650146484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012722015380859375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.6087, max=5.2230 | UB min=0.0000, max=7.3424
  Layer 2: LB min=-5.3421, max=8.7822 | UB min=-2.0242, max=12.2322
  Layer 3: LB min=-13.0513, max=14.8252 | UB min=-7.9233, max=25.1408
  Layer 4: LB min=-8.5858, max=17.9856 | UB min=4.2561, max=25.1408
  Layer 5: LB min=-5.3526, max=15.3879 | UB min=4.7132, max=25.1639
  Layer 6: LB min=1.9723, max=14.8252 | UB min=15.3311, max=25.1408
  Layer 7: LB min=-3.2417, max=-3.2417 | UB min=8.3956, max=8.3956
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03159046173095703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.014756202697753906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001407623291015625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012745857238769531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001092672348022461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004144906997680664

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.5900, max=5.2388 | UB min=0.0000, max=7.3242
  Layer 2: LB min=-5.3181, max=8.8129 | UB min=-2.0552, max=12.2052
  Layer 3: LB min=-12.9924, max=14.6756 | UB min=-7.9646, max=24.8188
  Layer 4: LB min=-8.4620, max=17.7978 | UB min=4.1402, max=24.8188
  Layer 5: LB min=-5.2028, max=15.1893 | UB min=4.6084, max=24.8188
  Layer 6: LB min=2.0359, max=14.6756 | UB min=15.1124, max=24.8188
  Layer 7: LB min=-3.0801, max=-3.0801 | UB min=8.3328, max=8.3328
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0505220890045166
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02131795883178711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011599063873291016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004102468490600586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001390695571899414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004323720932006836

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.5806, max=5.2467 | UB min=0.0000, max=7.3152
  Layer 2: LB min=-5.3060, max=8.8282 | UB min=-2.0709, max=12.1916
  Layer 3: LB min=-12.9629, max=14.6008 | UB min=-7.9852, max=24.6577
  Layer 4: LB min=-8.4001, max=17.7038 | UB min=4.0821, max=24.6577
  Layer 5: LB min=-5.1280, max=15.0902 | UB min=4.5561, max=24.6577
  Layer 6: LB min=2.0677, max=14.6008 | UB min=15.0032, max=24.6577
  Layer 7: LB min=-2.9994, max=-2.9994 | UB min=8.3012, max=8.3012
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03273940086364746
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04300832748413086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004128932952880859
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0016846656799316406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012564659118652344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0021343231201171875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.5853, max=5.2428 | UB min=0.0000, max=7.3197
  Layer 2: LB min=-5.3121, max=8.8206 | UB min=-2.0631, max=12.1984
  Layer 3: LB min=-12.9777, max=14.6382 | UB min=-7.9749, max=24.7383
  Layer 4: LB min=-8.4310, max=17.7508 | UB min=4.1111, max=24.7383
  Layer 5: LB min=-5.1654, max=15.1397 | UB min=4.5823, max=24.7383
  Layer 6: LB min=2.0518, max=14.6382 | UB min=15.0578, max=24.7383
  Layer 7: LB min=-3.0398, max=-3.0398 | UB min=8.3170, max=8.3170
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.031078815460205078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.034139156341552734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013000965118408203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0021979808807373047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014030933380126953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014903545379638672

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.5806, max=5.2467 | UB min=0.0000, max=7.3152
  Layer 2: LB min=-5.3060, max=8.8282 | UB min=-2.0709, max=12.1916
  Layer 3: LB min=-12.9629, max=14.6008 | UB min=-7.9852, max=24.6577
  Layer 4: LB min=-8.4001, max=17.7038 | UB min=4.0821, max=24.6577
  Layer 5: LB min=-5.1280, max=15.0902 | UB min=4.5561, max=24.6577
  Layer 6: LB min=2.0677, max=14.6008 | UB min=15.0032, max=24.6577
  Layer 7: LB min=-2.9994, max=-2.9994 | UB min=8.3012, max=8.3012
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03615856170654297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027129173278808594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012209415435791016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0017096996307373047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005086183547973633
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014164447784423828
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04558539390563965
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027695655822753906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001230478286743164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010485649108886719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0038826465606689453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001466512680053711
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.010744333267211914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.007276058197021484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013189315795898438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001356363296508789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001424551010131836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016589164733886719
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.010344505310058594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.012593984603881836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011615753173828125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011453628540039062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011491775512695312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0030405521392822266
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.042998552322387695
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028739213943481445
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0055730342864990234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011954307556152344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0025980472564697266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013556480407714844
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.057773590087890625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026763200759887695
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001340627670288086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011997222900390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00547480583190918
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001561880111694336
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.037973642349243164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02431035041809082
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015723705291748047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001482248306274414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014882087707519531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00495147705078125
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.015742063522338867
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.008334636688232422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013301372528076172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0017538070678710938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00424647331237793
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016627311706542969
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04855537414550781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.031157970428466797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010712146759033203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002092123031616211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018672943115234375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002012968063354492
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.033247947692871094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02817559242248535
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0020627975463867188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011665821075439453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011973381042480469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0043811798095703125
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027157306671142578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04392385482788086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012409687042236328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010368824005126953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012271404266357422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012869834899902344
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05526137351989746
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.033336639404296875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001096963882446289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0022957324981689453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001344919204711914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014455318450927734
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03402447700500488
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0478518009185791
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012640953063964844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011055469512939453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0028591156005859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015213489532470703
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03456830978393555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04209589958190918
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0017740726470947266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0026311874389648438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014090538024902344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014219284057617188
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03122568130493164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04258322715759277
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012657642364501953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012042522430419922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0019145011901855469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014510154724121094
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03149771690368652
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03786158561706543
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011861324310302734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001110076904296875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011165142059326172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001203298568725586

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-38.2387, max=0.0000 | UB min=0.0000, max=45.1526
  Layer 2: LB min=0.0000, max=0.0000 | UB min=61.2134, max=92.3761
  Layer 3: LB min=-186.2481, max=228.0685 | UB min=107.0476, max=698.5107
  Layer 4: LB min=-267.6531, max=293.4589 | UB min=207.7931, max=679.7352
  Layer 5: LB min=-325.0362, max=372.0949 | UB min=273.3951, max=860.9996
  Layer 6: LB min=-139.2585, max=197.9632 | UB min=582.4729, max=679.7352
  Layer 7: LB min=-523.5504, max=-523.5504 | UB min=150.3689, max=150.3689
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.009137630462646484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.004937887191772461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009713172912597656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009369850158691406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001172780990600586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011360645294189453

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-19.5231, max=0.0000 | UB min=0.0000, max=25.3913
  Layer 2: LB min=0.0000, max=0.0000 | UB min=33.2566, max=49.3190
  Layer 3: LB min=-97.1941, max=132.2740 | UB min=54.0456, max=374.7090
  Layer 4: LB min=-138.6544, max=164.2298 | UB min=106.5611, max=366.1567
  Layer 5: LB min=-167.4532, max=207.5312 | UB min=140.4648, max=458.9201
  Layer 6: LB min=-72.1265, max=113.9412 | UB min=300.5836, max=366.1567
  Layer 7: LB min=-268.7283, max=-268.7283 | UB min=76.6524, max=76.6524
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03666806221008301
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.024998188018798828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011849403381347656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011761188507080078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014183521270751953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001226663589477539

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-10.0214, max=0.0000 | UB min=0.0000, max=15.3672
  Layer 2: LB min=0.0000, max=0.0000 | UB min=17.6651, max=27.2873
  Layer 3: LB min=-50.0764, max=88.4602 | UB min=25.8358, max=207.8035
  Layer 4: LB min=-69.7476, max=100.6047 | UB min=52.8793, max=202.7159
  Layer 5: LB min=-82.7301, max=125.1713 | UB min=67.9130, max=249.0799
  Layer 6: LB min=-36.1683, max=73.3425 | UB min=150.6237, max=202.7159
  Layer 7: LB min=-130.5931, max=-130.5931 | UB min=44.3090, max=44.3090
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.018235206604003906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.013694047927856445
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001009225845336914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0031392574310302734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013086795806884766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016856193542480469

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.2116, max=3.1171 | UB min=0.0000, max=11.0915
  Layer 2: LB min=0.0000, max=0.9993 | UB min=9.7920, max=16.8578
  Layer 3: LB min=-25.1875, max=62.4298 | UB min=8.4448, max=116.4990
  Layer 4: LB min=-30.9656, max=68.5856 | UB min=22.7613, max=110.7168
  Layer 5: LB min=-37.0381, max=80.3938 | UB min=29.1407, max=134.4460
  Layer 6: LB min=-13.1783, max=52.1005 | UB min=70.4229, max=110.7168
  Layer 7: LB min=-52.7739, max=-52.7739 | UB min=23.7301, max=23.7301
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028835058212280273
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04444527626037598
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014264583587646484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010192394256591797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011949539184570312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00135040283203125

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.8028, max=4.9016 | UB min=0.0000, max=9.0016
  Layer 2: LB min=0.0000, max=4.5652 | UB min=5.1801, max=12.4961
  Layer 3: LB min=-14.1483, max=39.1075 | UB min=0.8013, max=62.3024
  Layer 4: LB min=-14.5536, max=45.7820 | UB min=7.6907, max=61.9830
  Layer 5: LB min=-14.4343, max=50.1398 | UB min=10.9794, max=72.5845
  Layer 6: LB min=1.5532, max=34.2096 | UB min=32.7252, max=61.6649
  Layer 7: LB min=-14.4142, max=-14.4142 | UB min=12.9092, max=12.9092
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.008732795715332031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.008167743682861328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016481876373291016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0017058849334716797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016083717346191406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011196136474609375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8372, max=5.7939 | UB min=0.0000, max=7.9553
  Layer 2: LB min=0.0000, max=6.4039 | UB min=2.9146, max=10.4753
  Layer 3: LB min=-9.4955, max=23.8925 | UB min=-2.3855, max=36.2290
  Layer 4: LB min=-7.2641, max=32.5413 | UB min=1.8077, max=40.1883
  Layer 5: LB min=-5.1589, max=33.6028 | UB min=3.9971, max=43.0024
  Layer 6: LB min=5.4168, max=22.3218 | UB min=17.4094, max=36.2290
  Layer 7: LB min=-1.7417, max=-1.7417 | UB min=9.3092, max=9.3092
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.036839962005615234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03897905349731445
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012786388397216797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002294301986694336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013058185577392578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013728141784667969

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.2492, max=5.3478 | UB min=0.0000, max=8.4791
  Layer 2: LB min=0.0000, max=5.4597 | UB min=4.0478, max=11.4849
  Layer 3: LB min=-11.8058, max=31.8220 | UB min=-0.8373, max=49.7293
  Layer 4: LB min=-11.3351, max=39.5502 | UB min=4.6054, max=51.4911
  Layer 5: LB min=-9.6867, max=42.1000 | UB min=7.3394, max=57.8424
  Layer 6: LB min=3.5052, max=29.1621 | UB min=24.8426, max=49.7293
  Layer 7: LB min=-7.7735, max=-7.7735 | UB min=11.1225, max=11.1225
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.010424613952636719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.007640838623046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011954307556152344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001287221908569336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010721683502197266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012364387512207031

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.0434, max=5.5709 | UB min=0.0000, max=8.2175
  Layer 2: LB min=0.0000, max=5.9313 | UB min=3.4812, max=10.9799
  Layer 3: LB min=-10.5617, max=28.1027 | UB min=-1.6479, max=43.8182
  Layer 4: LB min=-8.8742, max=36.3817 | UB min=3.1181, max=46.0956
  Layer 5: LB min=-7.0531, max=38.1858 | UB min=5.6106, max=50.2551
  Layer 6: LB min=4.5168, max=26.4660 | UB min=20.8082, max=43.8182
  Layer 7: LB min=-4.4150, max=-4.4150 | UB min=10.1394, max=10.1394
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0010814666748046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006520748138427734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001188516616821289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007505416870117188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008401870727539062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009105205535888672

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.9403, max=5.6824 | UB min=0.0000, max=8.0865
  Layer 2: LB min=0.0000, max=6.1670 | UB min=3.1979, max=10.7275
  Layer 3: LB min=-10.0276, max=26.0557 | UB min=-2.0181, max=40.1139
  Layer 4: LB min=-8.0648, max=34.5432 | UB min=2.4344, max=43.2217
  Layer 5: LB min=-6.0226, max=35.9826 | UB min=4.8005, max=46.6215
  Layer 6: LB min=4.9681, max=24.4871 | UB min=19.0476, max=40.1139
  Layer 7: LB min=-3.0272, max=-3.0272 | UB min=9.7218, max=9.7218
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03276777267456055
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030961036682128906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014925003051757812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0017175674438476562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015168190002441406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00397181510925293

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8888, max=5.7382 | UB min=0.0000, max=8.0209
  Layer 2: LB min=0.0000, max=6.2853 | UB min=3.0562, max=10.6013
  Layer 3: LB min=-9.7612, max=25.0239 | UB min=-2.2018, max=38.2478
  Layer 4: LB min=-7.6637, max=33.6169 | UB min=2.1219, max=41.7794
  Layer 5: LB min=-5.5892, max=34.8446 | UB min=4.3983, max=44.8539
  Layer 6: LB min=5.1925, max=23.4809 | UB min=18.2279, max=38.2478
  Layer 7: LB min=-2.3830, max=-2.3830 | UB min=9.5197, max=9.5197
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04970669746398926
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03185606002807617
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011854171752929688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001207113265991211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013592243194580078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0046689510345458984

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8630, max=5.7660 | UB min=0.0000, max=7.9881
  Layer 2: LB min=0.0000, max=6.3446 | UB min=2.9854, max=10.5383
  Layer 3: LB min=-9.6283, max=24.5080 | UB min=-2.2937, max=37.3147
  Layer 4: LB min=-7.4637, max=33.1535 | UB min=1.9660, max=41.0582
  Layer 5: LB min=-5.3737, max=34.2745 | UB min=4.1974, max=43.9752
  Layer 6: LB min=5.3047, max=22.9777 | UB min=17.8185, max=37.3147
  Layer 7: LB min=-2.0620, max=-2.0620 | UB min=9.4157, max=9.4157
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03171682357788086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029227256774902344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0026056766510009766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011508464813232422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011653900146484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011639595031738281

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8501, max=5.7800 | UB min=0.0000, max=7.9717
  Layer 2: LB min=0.0000, max=6.3742 | UB min=2.9500, max=10.5068
  Layer 3: LB min=-9.5619, max=24.2076 | UB min=-2.3396, max=36.7832
  Layer 4: LB min=-7.3638, max=32.8584 | UB min=1.8880, max=40.6343
  Layer 5: LB min=-5.2662, max=33.9457 | UB min=4.0971, max=43.4961
  Layer 6: LB min=5.3608, max=22.6611 | UB min=17.6139, max=36.7832
  Layer 7: LB min=-1.9018, max=-1.9018 | UB min=9.3628, max=9.3628
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03009200096130371
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.021125316619873047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010902881622314453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010280609130859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005687236785888672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019829273223876953

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8565, max=5.7730 | UB min=0.0000, max=7.9799
  Layer 2: LB min=0.0000, max=6.3594 | UB min=2.9677, max=10.5225
  Layer 3: LB min=-9.5951, max=24.3652 | UB min=-2.3166, max=37.0603
  Layer 4: LB min=-7.4137, max=33.0170 | UB min=1.9270, max=40.8573
  Layer 5: LB min=-5.3199, max=34.1174 | UB min=4.1472, max=43.7430
  Layer 6: LB min=5.3327, max=22.8307 | UB min=17.7162, max=37.0603
  Layer 7: LB min=-1.9818, max=-1.9818 | UB min=9.3893, max=9.3893
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03578066825866699
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022800207138061523
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010712146759033203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.006445407867431641
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016665458679199219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001772165298461914

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8533, max=5.7765 | UB min=0.0000, max=7.9758
  Layer 2: LB min=0.0000, max=6.3668 | UB min=2.9588, max=10.5147
  Layer 3: LB min=-9.5785, max=24.2864 | UB min=-2.3281, max=36.9217
  Layer 4: LB min=-7.3888, max=32.9377 | UB min=1.9075, max=40.7458
  Layer 5: LB min=-5.2931, max=34.0315 | UB min=4.1222, max=43.6195
  Layer 6: LB min=5.3467, max=22.7459 | UB min=17.6651, max=36.9217
  Layer 7: LB min=-1.9418, max=-1.9418 | UB min=9.3761, max=9.3761
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.030449628829956055
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026912212371826172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001222848892211914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010404586791992188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0031828880310058594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019063949584960938

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8533, max=5.7765 | UB min=0.0000, max=7.9758
  Layer 2: LB min=0.0000, max=6.3668 | UB min=2.9588, max=10.5147
  Layer 3: LB min=-9.5785, max=24.2864 | UB min=-2.3281, max=36.9217
  Layer 4: LB min=-7.3888, max=32.9377 | UB min=1.9075, max=40.7458
  Layer 5: LB min=-5.2931, max=34.0315 | UB min=4.1222, max=43.6195
  Layer 6: LB min=5.3467, max=22.7459 | UB min=17.6651, max=36.9217
  Layer 7: LB min=-1.9418, max=-1.9418 | UB min=9.3761, max=9.3761
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.034899234771728516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.014303207397460938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013709068298339844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.006142616271972656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013048648834228516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0024912357330322266
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04293417930603027
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.038008689880371094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012848377227783203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002317190170288086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015764236450195312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.006081581115722656
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.008634328842163086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.006209850311279297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012063980102539062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012955665588378906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0025968551635742188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001779317855834961
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01706218719482422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.010272026062011719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011906623840332031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011587142944335938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0025167465209960938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014870166778564453
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04013943672180176
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023267745971679688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001373291015625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011250972747802734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001965045928955078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014786720275878906
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03877902030944824
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03762221336364746
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012564659118652344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014917850494384766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014348030090332031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016334056854248047
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04238724708557129
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03233146667480469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014603137969970703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012097358703613281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012488365173339844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004044771194458008
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03617548942565918
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0329289436340332
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013844966888427734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013129711151123047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011317729949951172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012569427490234375
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03517508506774902
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02976369857788086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012171268463134766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014786720275878906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013246536254882812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014224052429199219
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029361248016357422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04155755043029785
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0028526782989501953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.009752750396728516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.006101846694946289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0033562183380126953
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03155112266540527
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.021570444107055664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013394355773925781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013818740844726562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013852119445800781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017673969268798828
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03278517723083496
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01891469955444336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011868476867675781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010480880737304688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011615753173828125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012674331665039062
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04356980323791504
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04278922080993652
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012402534484863281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001194000244140625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001325368881225586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011441707611083984
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029663562774658203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03239846229553223
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0028870105743408203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011484622955322266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012464523315429688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0020003318786621094
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03167104721069336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.036365509033203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012259483337402344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011124610900878906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001169443130493164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012087821960449219
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04031968116760254
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.038799285888671875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010519027709960938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013935565948486328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001102447509765625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011913776397705078

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-21.6388, max=0.0000 | UB min=0.0000, max=44.7603
  Layer 2: LB min=0.0000, max=0.0000 | UB min=61.0292, max=91.6786
  Layer 3: LB min=-188.7446, max=231.4972 | UB min=106.7021, max=706.0533
  Layer 4: LB min=-269.9435, max=295.2955 | UB min=208.7821, max=684.3127
  Layer 5: LB min=-327.0095, max=376.2468 | UB min=274.9684, max=867.9398
  Layer 6: LB min=-139.7852, max=202.2856 | UB min=584.9633, max=684.3127
  Layer 7: LB min=-526.1682, max=-526.1682 | UB min=152.6850, max=152.6850
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02671957015991211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04020547866821289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001222372055053711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0025110244750976562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012869834899902344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0028569698333740234

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-12.2693, max=0.0000 | UB min=0.0000, max=24.6806
  Layer 2: LB min=0.0000, max=0.0000 | UB min=31.5830, max=48.0130
  Layer 3: LB min=-101.0133, max=137.5750 | UB min=53.1843, max=385.0081
  Layer 4: LB min=-142.1482, max=166.5955 | UB min=107.8256, max=372.6306
  Layer 5: LB min=-169.9257, max=213.6380 | UB min=142.1801, max=468.1605
  Layer 6: LB min=-73.1557, max=120.4396 | UB min=303.5675, max=372.6306
  Layer 7: LB min=-271.9804, max=-271.9804 | UB min=82.7545, max=82.7545
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04238724708557129
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020291566848754883
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001249551773071289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.008469581604003906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0030717849731445312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002434968948364258

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-7.4144, max=0.0000 | UB min=0.0000, max=14.8899
  Layer 2: LB min=0.0000, max=0.0000 | UB min=15.8351, max=27.4932
  Layer 3: LB min=-54.1233, max=96.1301 | UB min=23.3503, max=218.1016
  Layer 4: LB min=-72.7511, max=104.2010 | UB min=53.2546, max=210.2450
  Layer 5: LB min=-83.7494, max=133.0407 | UB min=68.9627, max=257.9167
  Layer 6: LB min=-37.0625, max=81.3281 | UB min=151.9147, max=210.2450
  Layer 7: LB min=-132.6270, max=-132.6270 | UB min=44.0124, max=44.0124
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.006201744079589844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.004136800765991211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009655952453613281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009009838104248047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011682510375976562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0020236968994140625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-4.9023, max=1.8107 | UB min=0.0000, max=10.6996
  Layer 2: LB min=0.0000, max=2.6236 | UB min=8.2759, max=17.5558
  Layer 3: LB min=-29.3097, max=71.3868 | UB min=4.2629, max=124.0168
  Layer 4: LB min=-34.3204, max=70.8110 | UB min=21.9427, max=118.9171
  Layer 5: LB min=-35.3825, max=88.5819 | UB min=26.8798, max=142.0749
  Layer 6: LB min=-11.2214, max=60.0996 | UB min=67.6250, max=118.9171
  Layer 7: LB min=-51.7212, max=-51.7212 | UB min=22.5174, max=22.5174
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0010886192321777344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009176731109619141
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001058816909790039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011610984802246094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013246536254882812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016567707061767578

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.6366, max=3.9399 | UB min=0.0000, max=8.5959
  Layer 2: LB min=0.0000, max=6.4781 | UB min=4.5019, max=13.5931
  Layer 3: LB min=-19.1444, max=43.1910 | UB min=-3.9652, max=67.8442
  Layer 4: LB min=-19.4138, max=43.8185 | UB min=7.3379, max=65.4079
  Layer 5: LB min=-15.4159, max=54.7570 | UB min=9.7949, max=78.5522
  Layer 6: LB min=1.1911, max=38.1470 | UB min=34.0624, max=65.4079
  Layer 7: LB min=-16.7856, max=-16.7856 | UB min=11.8718, max=11.8718
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0478363037109375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028229713439941406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011794567108154297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0044307708740234375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015461444854736328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013852119445800781

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.0034, max=5.1151 | UB min=-0.4854, max=7.5428
  Layer 2: LB min=0.0000, max=8.1349 | UB min=2.3686, max=11.6034
  Layer 3: LB min=-14.6883, max=26.3462 | UB min=-7.4000, max=38.8310
  Layer 4: LB min=-13.0987, max=27.1429 | UB min=-0.5840, max=36.3982
  Layer 5: LB min=-7.0463, max=36.6033 | UB min=2.3311, max=46.4883
  Layer 6: LB min=6.8099, max=22.9623 | UB min=19.4778, max=36.3478
  Layer 7: LB min=-3.9745, max=-3.9745 | UB min=7.1056, max=7.1056
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03728342056274414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.018292665481567383
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016398429870605469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001560211181640625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0025391578674316406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017342567443847656

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.6828, max=5.7032 | UB min=-1.3254, max=7.0112
  Layer 2: LB min=0.0000, max=8.7817 | UB min=1.5012, max=10.6058
  Layer 3: LB min=-12.6247, max=15.3548 | UB min=-9.0007, max=21.7726
  Layer 4: LB min=-10.3100, max=16.5214 | UB min=-4.3076, max=20.8579
  Layer 5: LB min=-4.7455, max=24.7464 | UB min=-0.8696, max=29.6088
  Layer 6: LB min=9.3930, max=13.5526 | UB min=15.0074, max=20.5910
  Layer 7: LB min=0.1967, max=0.1967 | UB min=5.0591, max=5.0591
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01531362533569336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.011030912399291992
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001468658447265625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0015115737915039062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015406608581542969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017426013946533203

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.8451, max=5.4090 | UB min=-0.9049, max=7.2796
  Layer 2: LB min=0.0000, max=8.4568 | UB min=1.9351, max=11.1076
  Layer 3: LB min=-13.6174, max=21.1987 | UB min=-8.2284, max=30.6268
  Layer 4: LB min=-11.6233, max=22.0396 | UB min=-2.5302, max=28.8043
  Layer 5: LB min=-5.6838, max=31.0273 | UB min=0.6289, max=38.2567
  Layer 6: LB min=8.1461, max=18.3386 | UB min=16.8440, max=28.5142
  Layer 7: LB min=-1.4878, max=-1.4878 | UB min=6.0411, max=6.0411
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04849505424499512
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.025413036346435547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0017404556274414062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0033235549926757812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012462139129638672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013344287872314453

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7646, max=5.5560 | UB min=-1.1149, max=7.1462
  Layer 2: LB min=0.0000, max=8.6187 | UB min=1.7182, max=10.8576
  Layer 3: LB min=-13.1063, max=18.2946 | UB min=-8.6136, max=26.2157
  Layer 4: LB min=-10.9459, max=19.2911 | UB min=-3.4532, max=24.8313
  Layer 5: LB min=-5.1373, max=27.9136 | UB min=-0.1547, max=33.9156
  Layer 6: LB min=8.7815, max=15.9537 | UB min=15.7133, max=24.5593
  Layer 7: LB min=-0.4668, max=-0.4668 | UB min=5.5353, max=5.5353
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.013485908508300781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.006660938262939453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014269351959228516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013070106506347656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0054967403411865234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001962423324584961

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7237, max=5.6296 | UB min=-1.2202, max=7.0787
  Layer 2: LB min=0.0000, max=8.7002 | UB min=1.6096, max=10.7315
  Layer 3: LB min=-12.8647, max=16.8251 | UB min=-8.8072, max=23.9939
  Layer 4: LB min=-10.6280, max=17.9063 | UB min=-3.8778, max=22.8418
  Layer 5: LB min=-4.9414, max=26.3300 | UB min=-0.5167, max=31.7622
  Layer 6: LB min=9.0872, max=14.7532 | UB min=15.3604, max=22.5751
  Layer 7: LB min=-0.1351, max=-0.1351 | UB min=5.2972, max=5.2972
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0010592937469482422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009057521820068359
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011110305786132812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012218952178955078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013420581817626953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015339851379394531

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7033, max=5.6664 | UB min=-1.2728, max=7.0449
  Layer 2: LB min=0.0000, max=8.7410 | UB min=1.5554, max=10.6686
  Layer 3: LB min=-12.7445, max=16.0900 | UB min=-8.9040, max=22.8830
  Layer 4: LB min=-10.4690, max=17.2138 | UB min=-4.0928, max=21.8494
  Layer 5: LB min=-4.8434, max=25.5382 | UB min=-0.6943, max=30.6855
  Layer 6: LB min=9.2401, max=14.1529 | UB min=15.1839, max=21.5831
  Layer 7: LB min=0.0308, max=0.0308 | UB min=5.1781, max=5.1781
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04467892646789551
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028322458267211914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001020193099975586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010530948638916016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013210773468017578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003589630126953125

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7135, max=5.6480 | UB min=-1.2465, max=7.0618
  Layer 2: LB min=0.0000, max=8.7206 | UB min=1.5825, max=10.7000
  Layer 3: LB min=-12.8046, max=16.4576 | UB min=-8.8556, max=23.4384
  Layer 4: LB min=-10.5485, max=17.5601 | UB min=-3.9854, max=22.3454
  Layer 5: LB min=-4.8924, max=25.9341 | UB min=-0.6058, max=31.2239
  Layer 6: LB min=9.1637, max=14.4531 | UB min=15.2722, max=22.0791
  Layer 7: LB min=-0.0521, max=-0.0521 | UB min=5.2376, max=5.2376
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.014136552810668945
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0170748233795166
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012714862823486328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001405954360961914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0032300949096679688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002052783966064453

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7084, max=5.6572 | UB min=-1.2596, max=7.0534
  Layer 2: LB min=0.0000, max=8.7308 | UB min=1.5689, max=10.6843
  Layer 3: LB min=-12.7745, max=16.2738 | UB min=-8.8798, max=23.1607
  Layer 4: LB min=-10.5087, max=17.3869 | UB min=-4.0391, max=22.0973
  Layer 5: LB min=-4.8679, max=25.7362 | UB min=-0.6502, max=30.9547
  Layer 6: LB min=9.2019, max=14.3030 | UB min=15.2280, max=21.8311
  Layer 7: LB min=-0.0106, max=-0.0106 | UB min=5.2079, max=5.2079
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.041934967041015625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03331279754638672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015840530395507812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011734962463378906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0024573802947998047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001451253890991211

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7058, max=5.6618 | UB min=-1.2662, max=7.0491
  Layer 2: LB min=0.0000, max=8.7359 | UB min=1.5621, max=10.6764
  Layer 3: LB min=-12.7595, max=16.1819 | UB min=-8.8919, max=23.0219
  Layer 4: LB min=-10.4889, max=17.3004 | UB min=-4.0660, max=21.9733
  Layer 5: LB min=-4.8557, max=25.6372 | UB min=-0.6723, max=30.8201
  Layer 6: LB min=9.2210, max=14.2280 | UB min=15.2060, max=21.7071
  Layer 7: LB min=0.0101, max=0.0101 | UB min=5.1930, max=5.1930
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.009623050689697266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.004984617233276367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010356903076171875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00110626220703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011630058288574219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012140274047851562

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7058, max=5.6618 | UB min=-1.2662, max=7.0491
  Layer 2: LB min=0.0000, max=8.7359 | UB min=1.5621, max=10.6764
  Layer 3: LB min=-12.7595, max=16.1819 | UB min=-8.8919, max=23.0219
  Layer 4: LB min=-10.4889, max=17.3004 | UB min=-4.0660, max=21.9733
  Layer 5: LB min=-4.8557, max=25.6372 | UB min=-0.6723, max=30.8201
  Layer 6: LB min=9.2210, max=14.2280 | UB min=15.2060, max=21.7071
  Layer 7: LB min=0.0101, max=0.0101 | UB min=5.1930, max=5.1930
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.001951456069946289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0010085105895996094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0007092952728271484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008127689361572266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008454322814941406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016188621520996094
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03380632400512695
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029213666915893555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001016855239868164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001096963882446289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012621879577636719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011355876922607422
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.018496036529541016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01414942741394043
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010480880737304688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011103153228759766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010590553283691406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001306295394897461
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05232572555541992
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.021533966064453125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003268003463745117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004991054534912109
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014383792877197266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013110637664794922
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0590510368347168
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02537989616394043
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001130819320678711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011162757873535156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0020728111267089844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015571117401123047
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02802300453186035
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.021287202835083008
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011563301086425781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011322498321533203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002832174301147461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015408992767333984
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.059343814849853516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02615952491760254
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011794567108154297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010695457458496094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011737346649169922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012309551239013672
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.019628047943115234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.014999866485595703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009944438934326172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012600421905517578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010764598846435547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0047872066497802734
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03152346611022949
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03375077247619629
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012946128845214844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001077890396118164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002689361572265625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002039194107055664
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.015375852584838867
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019244909286499023
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0029027462005615234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0035560131072998047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0034439563751220703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0050048828125
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.039609670639038086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03393983840942383
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013051033020019531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010454654693603516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002805471420288086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013744831085205078
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01263737678527832
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.009268522262573242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010662078857421875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010936260223388672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011301040649414062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0020825862884521484
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029323339462280273
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027453899383544922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010120868682861328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011827945709228516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001039743423461914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004609107971191406
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0027174949645996094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.010229110717773438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012614727020263672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0017235279083251953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001630544662475586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017437934875488281
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0019176006317138672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009722709655761719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011279582977294922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001359701156616211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014319419860839844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002744436264038086
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.003246784210205078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0027184486389160156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010488033294677734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008220672607421875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010867118835449219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00106048583984375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-21.2880, max=0.0000 | UB min=0.0000, max=43.6567
  Layer 2: LB min=0.0000, max=0.0000 | UB min=60.3533, max=91.2456
  Layer 3: LB min=-187.6057, max=224.2516 | UB min=106.7346, max=697.4436
  Layer 4: LB min=-268.4496, max=289.2856 | UB min=208.1535, max=675.7191
  Layer 5: LB min=-325.9924, max=369.2351 | UB min=274.2256, max=859.3190
  Layer 6: LB min=-139.5047, max=195.9855 | UB min=583.1793, max=675.7191
  Layer 7: LB min=-524.6232, max=-524.6232 | UB min=152.3364, max=152.3364
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01955699920654297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01653909683227539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010707378387451172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0022759437561035156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002378225326538086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014755725860595703

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-11.6020, max=0.0000 | UB min=0.0000, max=23.0714
  Layer 2: LB min=0.0000, max=0.0000 | UB min=31.8110, max=47.3819
  Layer 3: LB min=-99.4660, max=126.1671 | UB min=53.7108, max=372.9214
  Layer 4: LB min=-140.6071, max=157.3378 | UB min=107.3482, max=360.7582
  Layer 5: LB min=-169.3361, max=202.8182 | UB min=142.2179, max=456.6273
  Layer 6: LB min=-73.0270, max=110.6370 | UB min=302.1333, max=360.7582
  Layer 7: LB min=-271.6071, max=-271.6071 | UB min=79.6374, max=79.6374
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0010099411010742188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006604194641113281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0007460117340087891
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007991790771484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009431838989257812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009562969207763672

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.5964, max=0.0000 | UB min=0.0000, max=13.5588
  Layer 2: LB min=0.0000, max=0.0000 | UB min=15.9923, max=25.4852
  Layer 3: LB min=-53.6484, max=77.6009 | UB min=25.8685, max=205.7611
  Layer 4: LB min=-73.8477, max=91.2198 | UB min=54.8732, max=198.3605
  Layer 5: LB min=-87.2088, max=118.9648 | UB min=72.6879, max=248.7869
  Layer 6: LB min=-38.0106, max=68.1648 | UB min=155.9239, max=198.3605
  Layer 7: LB min=-138.4580, max=-138.4580 | UB min=44.0113, max=44.0113
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02397775650024414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022390127182006836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011098384857177734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001207113265991211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012600421905517578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011320114135742188

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.9884, max=0.1788 | UB min=0.0000, max=9.2902
  Layer 2: LB min=0.0000, max=0.0000 | UB min=7.9644, max=15.2410
  Layer 3: LB min=-28.6286, max=57.0303 | UB min=8.3548, max=116.6488
  Layer 4: LB min=-36.4152, max=59.7284 | UB min=24.5383, max=112.4879
  Layer 5: LB min=-40.1239, max=77.5097 | UB min=32.6027, max=137.2070
  Layer 6: LB min=-16.6943, max=48.4515 | UB min=73.5779, max=112.4879
  Layer 7: LB min=-62.0170, max=-62.0170 | UB min=23.6067, max=23.6067
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.035399436950683594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02898716926574707
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003701925277709961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0015554428100585938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.006707191467285156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016901493072509766

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.6618, max=2.4747 | UB min=0.0000, max=7.1192
  Layer 2: LB min=0.0000, max=3.2347 | UB min=4.3277, max=11.0112
  Layer 3: LB min=-16.9955, max=37.2041 | UB min=-0.4981, max=64.2030
  Layer 4: LB min=-17.0872, max=37.4888 | UB min=9.4980, max=61.4999
  Layer 5: LB min=-16.8803, max=49.5954 | UB min=11.4484, max=75.2542
  Layer 6: LB min=-3.5340, max=31.3751 | UB min=33.1928, max=61.4999
  Layer 7: LB min=-21.2717, max=-21.2717 | UB min=12.1360, max=12.1360
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01788020133972168
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.012340307235717773
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0029289722442626953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0029833316802978516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003919839859008789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00530552864074707

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.9966, max=3.6229 | UB min=0.0000, max=6.0276
  Layer 2: LB min=0.0000, max=5.3134 | UB min=2.7167, max=9.2989
  Layer 3: LB min=-12.1520, max=21.8531 | UB min=-4.4556, max=34.8410
  Layer 4: LB min=-10.0882, max=22.3647 | UB min=0.8086, max=32.6360
  Layer 5: LB min=-7.4252, max=32.8259 | UB min=3.1234, max=43.0646
  Layer 6: LB min=2.8781, max=18.4236 | UB min=16.4517, max=32.6360
  Layer 7: LB min=-4.8544, max=-4.8544 | UB min=7.0556, max=7.0556
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03622722625732422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03990817070007324
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001300811767578125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011110305786132812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012412071228027344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004822492599487305

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.6640, max=4.1970 | UB min=-0.3173, max=5.4817
  Layer 2: LB min=0.0000, max=6.3192 | UB min=1.7302, max=8.3655
  Layer 3: LB min=-10.1105, max=14.0155 | UB min=-6.3464, max=20.5519
  Layer 4: LB min=-7.2819, max=14.8756 | UB min=-2.3953, max=19.3662
  Layer 5: LB min=-5.2463, max=24.1411 | UB min=-0.5392, max=29.0911
  Layer 6: LB min=5.5700, max=11.9087 | UB min=11.2032, max=18.9647
  Layer 7: LB min=-0.0407, max=-0.0407 | UB min=4.9093, max=4.9093
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.016238689422607422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02379584312438965
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003451108932495117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010075569152832031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010800361633300781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001112222671508789

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.4922, max=4.4845 | UB min=-0.7407, max=5.2014
  Layer 2: LB min=0.2379, max=6.7968 | UB min=1.2875, max=7.9176
  Layer 3: LB min=-9.1588, max=8.4363 | UB min=-7.1653, max=11.9684
  Layer 4: LB min=-5.9765, max=10.5813 | UB min=-3.2874, max=13.2527
  Layer 5: LB min=-4.3982, max=18.1426 | UB min=-1.8927, max=20.8139
  Layer 6: LB min=6.8127, max=7.5407 | UB min=9.8749, max=11.4226
  Layer 7: LB min=1.2709, max=1.2709 | UB min=3.9423, max=3.9423
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0010528564453125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.002324819564819336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002192974090576172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0031609535217285156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004925966262817383
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003332853317260742

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.5790, max=4.3407 | UB min=-0.5284, max=5.3428
  Layer 2: LB min=0.0357, max=6.5578 | UB min=1.5093, max=8.1434
  Layer 3: LB min=-9.6264, max=11.4374 | UB min=-6.7732, max=16.4458
  Layer 4: LB min=-6.6132, max=12.7915 | UB min=-2.8406, max=16.5832
  Layer 5: LB min=-4.7918, max=21.3260 | UB min=-1.2685, max=25.1177
  Layer 6: LB min=6.1971, max=10.0522 | UB min=10.5155, max=15.4926
  Layer 7: LB min=0.6363, max=0.6363 | UB min=4.4280, max=4.4280
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03638195991516113
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02341914176940918
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010797977447509766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001069784164428711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.007926225662231445
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014700889587402344

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.6224, max=4.2688 | UB min=-0.4223, max=5.4134
  Layer 2: LB min=0.0000, max=6.4382 | UB min=1.6203, max=8.2563
  Layer 3: LB min=-9.8640, max=12.7521 | UB min=-6.5624, max=18.5153
  Layer 4: LB min=-6.9441, max=13.7762 | UB min=-2.6173, max=17.9764
  Layer 5: LB min=-4.9895, max=22.7471 | UB min=-0.9474, max=27.1122
  Layer 6: LB min=5.8835, max=11.0054 | UB min=10.8434, max=17.2450
  Layer 7: LB min=0.3058, max=0.3058 | UB min=4.6709, max=4.6709
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.015521764755249023
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.010270357131958008
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001741647720336914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011365413665771484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002088785171508789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017902851104736328

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.6432, max=4.2329 | UB min=-0.3698, max=5.4476
  Layer 2: LB min=0.0000, max=6.3787 | UB min=1.6753, max=8.3109
  Layer 3: LB min=-9.9871, max=13.3841 | UB min=-6.4544, max=19.5338
  Layer 4: LB min=-7.1129, max=14.3260 | UB min=-2.5063, max=18.6714
  Layer 5: LB min=-5.1190, max=23.4443 | UB min=-0.7460, max=28.1019
  Layer 6: LB min=5.7267, max=11.4573 | UB min=11.0232, max=18.1050
  Layer 7: LB min=0.1326, max=0.1326 | UB min=4.7901, max=4.7901
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.008270263671875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0063364505767822266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0029134750366210938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003259897232055664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0041387081146240234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004793882369995117

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.6536, max=4.2149 | UB min=-0.3436, max=5.4646
  Layer 2: LB min=0.0000, max=6.3490 | UB min=1.7027, max=8.3382
  Layer 3: LB min=-10.0488, max=13.6998 | UB min=-6.4004, max=20.0429
  Layer 4: LB min=-7.1974, max=14.6008 | UB min=-2.4508, max=19.0188
  Layer 5: LB min=-5.1834, max=23.7927 | UB min=-0.6426, max=28.5965
  Layer 6: LB min=5.6483, max=11.6830 | UB min=11.1131, max=18.5348
  Layer 7: LB min=0.0460, max=0.0460 | UB min=4.8497, max=4.8497
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.001018524169921875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0014715194702148438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0040760040283203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0020825862884521484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0027625560760498047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003312349319458008

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.6588, max=4.2060 | UB min=-0.3305, max=5.4732
  Layer 2: LB min=0.0000, max=6.3341 | UB min=1.7165, max=8.3518
  Layer 3: LB min=-10.0796, max=13.8577 | UB min=-6.3734, max=20.2974
  Layer 4: LB min=-7.2396, max=14.7382 | UB min=-2.4231, max=19.1925
  Layer 5: LB min=-5.2150, max=23.9669 | UB min=-0.5909, max=28.8438
  Layer 6: LB min=5.6091, max=11.7959 | UB min=11.1581, max=18.7497
  Layer 7: LB min=0.0026, max=0.0026 | UB min=4.8795, max=4.8795
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03801417350769043
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03122401237487793
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001291513442993164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0016798973083496094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012333393096923828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012547969818115234

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.6614, max=4.2015 | UB min=-0.3239, max=5.4774
  Layer 2: LB min=0.0000, max=6.3267 | UB min=1.7233, max=8.3586
  Layer 3: LB min=-10.0951, max=13.9366 | UB min=-6.3599, max=20.4246
  Layer 4: LB min=-7.2607, max=14.8069 | UB min=-2.4092, max=19.2793
  Layer 5: LB min=-5.2307, max=24.0540 | UB min=-0.5651, max=28.9674
  Layer 6: LB min=5.5896, max=11.8523 | UB min=11.1807, max=18.8572
  Layer 7: LB min=-0.0190, max=-0.0190 | UB min=4.8944, max=4.8944
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01370692253112793
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.009711265563964844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011835098266601562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0016047954559326172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013687610626220703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013988018035888672

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.6588, max=4.2060 | UB min=-0.3305, max=5.4732
  Layer 2: LB min=0.0000, max=6.3341 | UB min=1.7165, max=8.3518
  Layer 3: LB min=-10.0796, max=13.8577 | UB min=-6.3734, max=20.2974
  Layer 4: LB min=-7.2396, max=14.7382 | UB min=-2.4231, max=19.1925
  Layer 5: LB min=-5.2150, max=23.9669 | UB min=-0.5909, max=28.8438
  Layer 6: LB min=5.6091, max=11.7959 | UB min=11.1581, max=18.7497
  Layer 7: LB min=0.0026, max=0.0026 | UB min=4.8795, max=4.8795
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0026731491088867188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0011124610900878906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008914470672607422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010066032409667969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001310586929321289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011494159698486328
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03142833709716797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02313828468322754
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0033926963806152344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014312267303466797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003635406494140625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00145721435546875
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.030902862548828125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023171186447143555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001077413558959961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011241436004638672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.006755352020263672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014798641204833984
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03477621078491211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029201507568359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003650665283203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001163482666015625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0027618408203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0020585060119628906
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02833843231201172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027718782424926758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0020666122436523438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013358592987060547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0068209171295166016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002051115036010742
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03030109405517578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03165245056152344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0019960403442382812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002208709716796875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018019676208496094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019829273223876953
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03356146812438965
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0204315185546875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002651214599609375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010952949523925781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0043659210205078125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001756906509399414
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.040155649185180664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04664802551269531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011801719665527344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0017125606536865234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0019893646240234375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011408329010009766
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01116323471069336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.007808685302734375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004041433334350586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0028383731842041016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018911361694335938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002028226852416992
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.00508570671081543
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0025331974029541016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0025510787963867188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0023431777954101562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011358261108398438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013289451599121094
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.001550436019897461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0018639564514160156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.007581949234008789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0036118030548095703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004206180572509766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018572807312011719
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05366373062133789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029258251190185547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008883476257324219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014026165008544922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004602909088134766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013642311096191406
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01578974723815918
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.016365528106689453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011355876922607422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001020669937133789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010862350463867188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018932819366455078
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0010306835174560547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0013060569763183594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010623931884765625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010311603546142578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011038780212402344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015130043029785156
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03175044059753418
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026859045028686523
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.008655786514282227
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0015859603881835938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012164115905761719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013928413391113281
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02740168571472168
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01969432830810547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001129150390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010983943939208984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011990070343017578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012629032135009766

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-38.3102, max=0.0000 | UB min=0.0000, max=53.2436
  Layer 2: LB min=-59.2852, max=0.0000 | UB min=0.0000, max=91.6209
  Layer 3: LB min=-184.0658, max=222.8754 | UB min=105.3830, max=687.9152
  Layer 4: LB min=-264.6808, max=289.3677 | UB min=205.5924, max=667.9590
  Layer 5: LB min=-323.0827, max=364.3948 | UB min=270.2493, max=848.3746
  Layer 6: LB min=-137.4564, max=194.6707 | UB min=577.4047, max=667.9590
  Layer 7: LB min=-517.3615, max=-517.3615 | UB min=149.1763, max=149.1763
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.033025503158569336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017042875289916992
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010344982147216797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0023441314697265625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010766983032226562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004071235656738281

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-19.8493, max=0.0000 | UB min=0.0000, max=28.0832
  Layer 2: LB min=-31.1102, max=0.0000 | UB min=0.0000, max=48.0161
  Layer 3: LB min=-94.8291, max=125.2130 | UB min=51.8727, max=360.4131
  Layer 4: LB min=-134.8715, max=158.2773 | UB min=103.7255, max=345.0502
  Layer 5: LB min=-165.2251, max=196.7739 | UB min=136.3773, max=438.2760
  Layer 6: LB min=-69.9412, max=109.6088 | UB min=293.4336, max=345.0502
  Layer 7: LB min=-256.9283, max=-256.9283 | UB min=75.7801, max=75.7801
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03132176399230957
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03256988525390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004054546356201172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001108407974243164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011754035949707031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0073697566986083984

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-10.5294, max=0.0000 | UB min=0.0000, max=15.4036
  Layer 2: LB min=-16.7666, max=0.0000 | UB min=0.0000, max=26.1284
  Layer 3: LB min=-48.1183, max=77.5617 | UB min=20.2301, max=193.3393
  Layer 4: LB min=-66.2424, max=94.9783 | UB min=48.7121, max=179.2903
  Layer 5: LB min=-82.2016, max=113.1621 | UB min=64.9401, max=228.6252
  Layer 6: LB min=-34.0418, max=68.4195 | UB min=144.2118, max=179.2903
  Layer 7: LB min=-119.5159, max=-119.5159 | UB min=37.7045, max=37.7045
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03774738311767578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02767014503479004
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014493465423583984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001285552978515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011391639709472656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001405477523803711

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.8314, max=2.6306 | UB min=0.0000, max=10.8932
  Layer 2: LB min=-9.9412, max=1.8594 | UB min=0.0000, max=16.4522
  Layer 3: LB min=-25.1084, max=46.3234 | UB min=4.1374, max=99.1430
  Layer 4: LB min=-30.4091, max=58.3065 | UB min=19.8480, max=93.7294
  Layer 5: LB min=-36.5649, max=63.1060 | UB min=28.7400, max=114.1632
  Layer 6: LB min=-10.5986, max=43.4696 | UB min=66.1513, max=93.5790
  Layer 7: LB min=-47.0942, max=-47.0942 | UB min=21.8111, max=21.8111
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03181815147399902
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030208826065063477
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013580322265625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0037384033203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011968612670898438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010890960693359375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.4788, max=4.4983 | UB min=0.0000, max=8.7418
  Layer 2: LB min=-6.6739, max=5.5619 | UB min=-0.0291, max=12.6387
  Layer 3: LB min=-14.3165, max=28.3483 | UB min=-3.3995, max=49.5689
  Layer 4: LB min=-13.3797, max=36.8094 | UB min=6.7932, max=50.4932
  Layer 5: LB min=-14.0534, max=34.1591 | UB min=11.6396, max=54.7408
  Layer 6: LB min=-2.0145, max=28.3483 | UB min=29.2022, max=49.5689
  Layer 7: LB min=-13.6636, max=-13.6636 | UB min=12.2498, max=12.2498
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03429388999938965
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03070974349975586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015642642974853516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010707378387451172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011897087097167969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013113021850585938

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.2989, max=5.4338 | UB min=-0.0993, max=7.6542
  Layer 2: LB min=-5.1688, max=7.4849 | UB min=-2.0197, max=10.9541
  Layer 3: LB min=-10.9301, max=17.2856 | UB min=-6.6606, max=27.2662
  Layer 4: LB min=-6.4419, max=23.3835 | UB min=2.3653, max=29.3965
  Layer 5: LB min=-4.5615, max=17.6050 | UB min=5.3207, max=27.2662
  Layer 6: LB min=3.0004, max=17.2856 | UB min=14.5933, max=27.2662
  Layer 7: LB min=-1.4447, max=-1.4447 | UB min=7.4946, max=7.4946
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.023778676986694336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.034746408462524414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012030601501464844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001271963119506836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011181831359863281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0033295154571533203

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.8906, max=4.9656 | UB min=0.0000, max=8.2039
  Layer 2: LB min=-5.9100, max=6.5281 | UB min=-1.0415, max=11.7780
  Layer 3: LB min=-12.4369, max=23.1369 | UB min=-5.1656, max=38.5598
  Layer 4: LB min=-9.7991, max=30.3561 | UB min=4.4996, max=40.1094
  Layer 5: LB min=-9.2595, max=25.9474 | UB min=8.3699, max=39.8222
  Layer 6: LB min=-0.0485, max=23.1369 | UB min=21.7002, max=38.5598
  Layer 7: LB min=-7.0111, max=-7.0111 | UB min=10.0169, max=10.0169
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.045679569244384766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02478313446044922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015931129455566406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012013912200927734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013399124145507812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004614114761352539

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.5965, max=5.1992 | UB min=0.0000, max=7.9329
  Layer 2: LB min=-5.5344, max=7.0108 | UB min=-1.5347, max=11.3568
  Layer 3: LB min=-11.6375, max=20.2180 | UB min=-5.9251, max=32.8954
  Layer 4: LB min=-8.0951, max=26.8578 | UB min=3.3957, max=34.7139
  Layer 5: LB min=-6.8784, max=21.6631 | UB min=6.7949, max=32.8954
  Layer 6: LB min=0.8295, max=20.2180 | UB min=18.0756, max=32.8954
  Layer 7: LB min=-4.1311, max=-4.1311 | UB min=9.0773, max=9.0773
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.033466339111328125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019231796264648438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.008722066879272461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014934539794921875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0040013790130615234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016942024230957031

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7436, max=5.0824 | UB min=0.0000, max=8.0687
  Layer 2: LB min=-5.7223, max=6.7695 | UB min=-1.2881, max=11.5678
  Layer 3: LB min=-12.0365, max=21.7451 | UB min=-5.5453, max=35.7953
  Layer 4: LB min=-8.9553, max=28.6586 | UB min=3.9478, max=37.4634
  Layer 5: LB min=-8.0829, max=23.8065 | UB min=7.5794, max=36.1148
  Layer 6: LB min=0.3907, max=21.7451 | UB min=19.8903, max=35.7953
  Layer 7: LB min=-5.5641, max=-5.5641 | UB min=9.5547, max=9.5547
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04374980926513672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.018702983856201172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001186370849609375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012698173522949219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010874271392822266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012145042419433594

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.6701, max=5.1408 | UB min=0.0000, max=8.0008
  Layer 2: LB min=-5.6283, max=6.8902 | UB min=-1.4114, max=11.4623
  Layer 3: LB min=-11.8363, max=20.9816 | UB min=-5.7352, max=34.3452
  Layer 4: LB min=-8.5271, max=27.7582 | UB min=3.6715, max=36.0885
  Layer 5: LB min=-7.4805, max=22.7349 | UB min=7.1862, max=34.3452
  Layer 6: LB min=0.6102, max=20.9816 | UB min=18.9821, max=34.3452
  Layer 7: LB min=-4.8465, max=-4.8465 | UB min=9.3202, max=9.3202
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03687238693237305
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.032689809799194336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001195669174194336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010249614715576172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011131763458251953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011489391326904297

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7068, max=5.1116 | UB min=0.0000, max=8.0348
  Layer 2: LB min=-5.6753, max=6.8298 | UB min=-1.3498, max=11.5151
  Layer 3: LB min=-11.9363, max=21.3634 | UB min=-5.6402, max=35.0702
  Layer 4: LB min=-8.7416, max=28.2084 | UB min=3.8097, max=36.7759
  Layer 5: LB min=-7.7817, max=23.2707 | UB min=7.3827, max=35.1878
  Layer 6: LB min=0.5005, max=21.3634 | UB min=19.4361, max=35.0702
  Layer 7: LB min=-5.2051, max=-5.2051 | UB min=9.4384, max=9.4384
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04499697685241699
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027261734008789062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001664876937866211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.005110025405883789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001184701919555664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012655258178710938

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7252, max=5.0970 | UB min=0.0000, max=8.0517
  Layer 2: LB min=-5.6988, max=6.7996 | UB min=-1.3189, max=11.5415
  Layer 3: LB min=-11.9864, max=21.5542 | UB min=-5.5928, max=35.4327
  Layer 4: LB min=-8.8486, max=28.4335 | UB min=3.8787, max=37.1196
  Layer 5: LB min=-7.9323, max=23.5386 | UB min=7.4809, max=35.6512
  Layer 6: LB min=0.4456, max=21.5542 | UB min=19.6631, max=35.4327
  Layer 7: LB min=-5.3845, max=-5.3845 | UB min=9.4968, max=9.4968
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0474238395690918
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030443906784057617
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012669563293457031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011148452758789062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011963844299316406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.006066560745239258

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7344, max=5.0897 | UB min=0.0000, max=8.0602
  Layer 2: LB min=-5.7105, max=6.7846 | UB min=-1.3035, max=11.5547
  Layer 3: LB min=-12.0114, max=21.6496 | UB min=-5.5690, max=35.6140
  Layer 4: LB min=-8.9020, max=28.5461 | UB min=3.9133, max=37.2915
  Layer 5: LB min=-8.0076, max=23.6726 | UB min=7.5301, max=35.8830
  Layer 6: LB min=0.4181, max=21.6496 | UB min=19.7767, max=35.6140
  Layer 7: LB min=-5.4743, max=-5.4743 | UB min=9.5258, max=9.5258
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05216383934020996
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03146219253540039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001068115234375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002048015594482422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001928567886352539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.005190372467041016

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7390, max=5.0861 | UB min=0.0000, max=8.0645
  Layer 2: LB min=-5.7164, max=6.7770 | UB min=-1.2958, max=11.5612
  Layer 3: LB min=-12.0240, max=21.6974 | UB min=-5.5572, max=35.7047
  Layer 4: LB min=-8.9286, max=28.6024 | UB min=3.9306, max=37.3775
  Layer 5: LB min=-8.0453, max=23.7396 | UB min=7.5547, max=35.9989
  Layer 6: LB min=0.4044, max=21.6974 | UB min=19.8335, max=35.7047
  Layer 7: LB min=-5.5192, max=-5.5192 | UB min=9.5402, max=9.5402
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.014418363571166992
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.012387990951538086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001425027847290039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013475418090820312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014767646789550781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003943443298339844

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7344, max=5.0897 | UB min=0.0000, max=8.0602
  Layer 2: LB min=-5.7105, max=6.7846 | UB min=-1.3035, max=11.5547
  Layer 3: LB min=-12.0114, max=21.6496 | UB min=-5.5690, max=35.6140
  Layer 4: LB min=-8.9020, max=28.5461 | UB min=3.9133, max=37.2915
  Layer 5: LB min=-8.0076, max=23.6726 | UB min=7.5301, max=35.8830
  Layer 6: LB min=0.4181, max=21.6496 | UB min=19.7767, max=35.6140
  Layer 7: LB min=-5.4743, max=-5.4743 | UB min=9.5258, max=9.5258
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04691505432128906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027087688446044922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0017161369323730469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.005652904510498047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.006530046463012695
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015904903411865234
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.014722585678100586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.012421607971191406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012924671173095703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001428365707397461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001416921615600586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017514228820800781
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01036381721496582
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.00619959831237793
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010633468627929688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011112689971923828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001264333724975586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011951923370361328
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04762148857116699
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028132915496826172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0020351409912109375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0016117095947265625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012996196746826172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001399993896484375
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03624439239501953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026709794998168945
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001107931137084961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0020983219146728516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004193782806396484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0024089813232421875
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.056982994079589844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03409886360168457
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.006122112274169922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013060569763183594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012240409851074219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014085769653320312
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03134751319885254
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020905017852783203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.005111217498779297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001352071762084961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013430118560791016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019693374633789062
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.055625200271606445
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015210390090942383
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011250972747802734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010232925415039062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013222694396972656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011823177337646484
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.030016660690307617
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02151799201965332
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012001991271972656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001088857650756836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011398792266845703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.006371021270751953
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03003525733947754
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02556467056274414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0018932819366455078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011260509490966797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0042743682861328125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002313375473022461
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.026630640029907227
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017390012741088867
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011310577392578125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012676715850830078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011744499206542969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001201629638671875
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.033011674880981445
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03256368637084961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013086795806884766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0025391578674316406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013463497161865234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001485586166381836
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027010679244995117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.025719881057739258
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012271404266357422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001031637191772461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003009796142578125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002986431121826172
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.022620201110839844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028183460235595703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012676715850830078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0015285015106201172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0034554004669189453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002447843551635742
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04302191734313965
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.018610000610351562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010938644409179688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012090206146240234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011906623840332031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011417865753173828
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.015741586685180664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030613422393798828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0021109580993652344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001201629638671875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011210441589355469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001371145248413086

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-40.2063, max=0.0000 | UB min=0.0000, max=53.5448
  Layer 2: LB min=-59.5554, max=0.0000 | UB min=0.0000, max=89.8729
  Layer 3: LB min=-185.0657, max=220.4690 | UB min=104.4848, max=685.4364
  Layer 4: LB min=-264.7758, max=286.2012 | UB min=205.3116, max=662.1421
  Layer 5: LB min=-322.4523, max=362.1617 | UB min=270.5692, max=845.2559
  Layer 6: LB min=-137.2062, max=193.5975 | UB min=575.4315, max=662.1421
  Layer 7: LB min=-517.2190, max=-517.2190 | UB min=148.4927, max=148.4927
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.011667013168334961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.00730586051940918
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00115966796875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001026153564453125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012450218200683594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010640621185302734

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-22.7506, max=0.0000 | UB min=0.0000, max=28.6282
  Layer 2: LB min=-31.8592, max=0.0000 | UB min=0.0000, max=45.7347
  Layer 3: LB min=-95.4339, max=121.0818 | UB min=50.2443, max=356.6429
  Layer 4: LB min=-135.0135, max=153.9916 | UB min=103.3162, max=337.9113
  Layer 5: LB min=-164.2679, max=193.4771 | UB min=136.5278, max=433.9257
  Layer 6: LB min=-69.7048, max=107.8237 | UB min=290.9479, max=337.9113
  Layer 7: LB min=-256.8698, max=-256.8698 | UB min=74.5912, max=74.5912
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0011463165283203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0008983612060546875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008547306060791016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007619857788085938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012080669403076172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.000990152359008789

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-13.8697, max=0.0000 | UB min=0.0000, max=16.0104
  Layer 2: LB min=-17.5946, max=0.0000 | UB min=0.0000, max=24.8380
  Layer 3: LB min=-49.2527, max=72.2935 | UB min=21.7184, max=188.2845
  Layer 4: LB min=-65.8624, max=87.7463 | UB min=49.3013, max=171.0525
  Layer 5: LB min=-81.3536, max=108.5773 | UB min=65.2470, max=222.7577
  Layer 6: LB min=-34.1295, max=65.2554 | UB min=142.0735, max=170.7445
  Layer 7: LB min=-119.9898, max=-119.9898 | UB min=36.7899, max=36.7899
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05800271034240723
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020134687423706055
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0031347274780273438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011873245239257812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013475418090820312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012402534484863281

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-9.4070, max=3.0929 | UB min=-0.5615, max=11.5034
  Layer 2: LB min=-10.3721, max=1.2966 | UB min=0.0000, max=15.5687
  Layer 3: LB min=-24.6693, max=44.1561 | UB min=4.6014, max=96.2277
  Layer 4: LB min=-27.1147, max=51.0454 | UB min=19.5125, max=85.4921
  Layer 5: LB min=-35.5148, max=61.2139 | UB min=27.1731, max=108.7256
  Layer 6: LB min=-13.5142, max=40.8253 | UB min=62.3183, max=85.1551
  Layer 7: LB min=-46.5211, max=-46.5211 | UB min=18.4848, max=18.4848
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02245163917541504
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.010699272155761719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011577606201171875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004288911819458008
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013763904571533203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014007091522216797

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-7.1648, max=4.9886 | UB min=-2.6482, max=9.2938
  Layer 2: LB min=-7.2872, max=4.4590 | UB min=-0.4531, max=11.7033
  Layer 3: LB min=-15.5328, max=24.6601 | UB min=-2.6373, max=47.6157
  Layer 4: LB min=-12.4593, max=29.8288 | UB min=7.3286, max=45.0821
  Layer 5: LB min=-16.4672, max=32.4727 | UB min=11.7786, max=53.0877
  Layer 6: LB min=-3.7812, max=24.6601 | UB min=30.1282, max=44.9126
  Layer 7: LB min=-15.5524, max=-15.5524 | UB min=11.8216, max=11.8216
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0010607242584228516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0015120506286621094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016243457794189453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001435995101928711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001638174057006836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016045570373535156

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.0438, max=5.9364 | UB min=-3.6916, max=8.1885
  Layer 2: LB min=-5.7700, max=6.1418 | UB min=-2.3032, max=9.9106
  Layer 3: LB min=-12.2653, max=14.5207 | UB min=-5.7422, max=24.8689
  Layer 4: LB min=-6.8883, max=17.7525 | UB min=2.7661, max=24.9386
  Layer 5: LB min=-8.2012, max=16.5053 | UB min=5.1009, max=25.9084
  Layer 6: LB min=0.3284, max=14.5207 | UB min=16.4650, max=24.8689
  Layer 7: LB min=-2.4593, max=-2.4593 | UB min=8.9572, max=8.9572
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03492426872253418
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02049541473388672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013837814331054688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0015254020690917969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016224384307861328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004264354705810547

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6043, max=5.4625 | UB min=-3.1699, max=8.7412
  Layer 2: LB min=-6.5390, max=5.3123 | UB min=-1.3633, max=10.8069
  Layer 3: LB min=-13.9304, max=19.5998 | UB min=-4.1975, max=35.1620
  Layer 4: LB min=-9.8215, max=23.7231 | UB min=5.0601, max=34.9920
  Layer 5: LB min=-12.3755, max=24.0013 | UB min=8.5558, max=39.0429
  Layer 6: LB min=-1.7557, max=19.5998 | UB min=23.3143, max=34.9033
  Layer 7: LB min=-8.9766, max=-8.9766 | UB min=10.5194, max=10.5194
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03181266784667969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.014118671417236328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011358261108398438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011968612670898438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005727052688598633
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019283294677734375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.8846, max=5.2255 | UB min=-2.9091, max=9.0175
  Layer 2: LB min=-6.9147, max=4.8857 | UB min=-0.9070, max=11.2551
  Layer 3: LB min=-14.7329, max=22.1342 | UB min=-3.4177, max=41.3792
  Layer 4: LB min=-11.1703, max=26.7722 | UB min=6.2000, max=40.0318
  Layer 5: LB min=-14.4256, max=28.2287 | UB min=10.1890, max=46.0519
  Layer 6: LB min=-2.7722, max=22.1342 | UB min=26.7239, max=39.8972
  Layer 7: LB min=-12.2670, max=-12.2670 | UB min=11.1928, max=11.1928
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.037355661392211914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01896047592163086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011279582977294922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010526180267333984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0020647048950195312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0031371116638183594

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.7445, max=5.3440 | UB min=-3.0395, max=8.8793
  Layer 2: LB min=-6.7273, max=5.0990 | UB min=-1.1348, max=11.0310
  Layer 3: LB min=-14.3325, max=20.8651 | UB min=-3.8073, max=38.2703
  Layer 4: LB min=-10.5182, max=25.2452 | UB min=5.6320, max=37.5139
  Layer 5: LB min=-13.4030, max=26.1107 | UB min=9.3836, max=42.5466
  Layer 6: LB min=-2.2658, max=20.8651 | UB min=25.0243, max=37.4001
  Layer 7: LB min=-10.6272, max=-10.6272 | UB min=10.8638, max=10.8638
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03370213508605957
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.025914907455444336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003206968307495117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011467933654785156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012395381927490234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012347698211669922

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6744, max=5.4033 | UB min=-3.1047, max=8.8103
  Layer 2: LB min=-6.6333, max=5.2057 | UB min=-1.2490, max=10.9190
  Layer 3: LB min=-14.1317, max=20.2319 | UB min=-4.0023, max=36.7160
  Layer 4: LB min=-10.1700, max=24.4832 | UB min=5.3466, max=36.2529
  Layer 5: LB min=-12.8902, max=25.0549 | UB min=8.9711, max=40.7948
  Layer 6: LB min=-2.0117, max=20.2319 | UB min=24.1700, max=36.1517
  Layer 7: LB min=-9.8026, max=-9.8026 | UB min=10.6941, max=10.6941
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.039496660232543945
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.018298625946044922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015463829040527344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012936592102050781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016639232635498047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017230510711669922

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03539705276489258
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.021928071975708008
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0019507408142089844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014982223510742188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003688812255859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001743316650390625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6569, max=5.4181 | UB min=-3.1210, max=8.7930
  Layer 2: LB min=-6.6097, max=5.2324 | UB min=-1.2775, max=10.8909
  Layer 3: LB min=-14.0814, max=20.0738 | UB min=-4.0511, max=36.3275
  Layer 4: LB min=-10.0830, max=24.2930 | UB min=5.2751, max=35.9377
  Layer 5: LB min=-12.7617, max=24.7913 | UB min=8.8676, max=40.3567
  Layer 6: LB min=-1.9479, max=20.0738 | UB min=23.9562, max=35.8396
  Layer 7: LB min=-9.5962, max=-9.5962 | UB min=10.6508, max=10.6508
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0274202823638916
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017679214477539062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0026259422302246094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001177072525024414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004591941833496094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001226663589477539

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6481, max=5.4255 | UB min=-3.1292, max=8.7843
  Layer 2: LB min=-6.5980, max=5.2457 | UB min=-1.2918, max=10.8769
  Layer 3: LB min=-14.0563, max=19.9948 | UB min=-4.0755, max=36.1332
  Layer 4: LB min=-10.0394, max=24.1979 | UB min=5.2393, max=35.7801
  Layer 5: LB min=-12.6974, max=24.6595 | UB min=8.8158, max=40.1377
  Layer 6: LB min=-1.9159, max=19.9948 | UB min=23.8493, max=35.6836
  Layer 7: LB min=-9.4930, max=-9.4930 | UB min=10.6291, max=10.6291
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.046334266662597656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.032691001892089844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011951923370361328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0019402503967285156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013208389282226562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013928413391113281

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6437, max=5.4292 | UB min=-3.1332, max=8.7800
  Layer 2: LB min=-6.5921, max=5.2524 | UB min=-1.2990, max=10.8699
  Layer 3: LB min=-14.0437, max=19.9552 | UB min=-4.0877, max=36.0361
  Layer 4: LB min=-10.0176, max=24.1504 | UB min=5.2214, max=35.7013
  Layer 5: LB min=-12.6652, max=24.5937 | UB min=8.7898, max=40.0282
  Layer 6: LB min=-1.8999, max=19.9552 | UB min=23.7958, max=35.6055
  Layer 7: LB min=-9.4414, max=-9.4414 | UB min=10.6182, max=10.6182
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.031844377517700195
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01794910430908203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010972023010253906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009822845458984375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.008455753326416016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004197597503662109

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027408838272094727
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02606678009033203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011858940124511719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.005011081695556641
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018138885498046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001455545425415039
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.026341676712036133
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03434300422668457
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001096963882446289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009951591491699219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010120868682861328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.007701396942138672
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01071476936340332
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02397012710571289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014951229095458984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001222372055053711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013506412506103516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012600421905517578
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.024770021438598633
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.014640092849731445
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0026102066040039062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012936592102050781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0051386356353759766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017237663269042969
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.046526432037353516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015598297119140625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011034011840820312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0055084228515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014350414276123047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004769086837768555
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.038561344146728516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020923852920532227
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0029761791229248047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001116037368774414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001344919204711914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011739730834960938
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04698038101196289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017764568328857422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010962486267089844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001184225082397461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0035407543182373047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.010489702224731445
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027643203735351562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0135498046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011126995086669922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013308525085449219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005452394485473633
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016758441925048828
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02733016014099121
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01888871192932129
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001130819320678711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001142740249633789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011212825775146484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.007394075393676758
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04004716873168945
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015758752822875977
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016968250274658203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011563301086425781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018322467803955078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016002655029296875
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.025110244750976562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030207395553588867
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001459360122680664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0050640106201171875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0034041404724121094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014259815216064453
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03978300094604492
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.021137714385986328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012288093566894531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010313987731933594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011599063873291016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013537406921386719
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04354405403137207
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020851612091064453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0017025470733642578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012562274932861328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001237630844116211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004016399383544922
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03369474411010742
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03300786018371582
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010385513305664062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011906623840332031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004051685333251953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019192695617675781
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03245949745178223
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01860642433166504
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015187263488769531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0015218257904052734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016338825225830078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0074651241302490234
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
 Found input where NAP improves robustness! at index 15 epsilons are  0.024901855468749998 and  0.0189263916015625
[INFO] Found NAP-exclusive robust input for label 1 at epsilon=0.0249
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0346376895904541
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02557086944580078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010440349578857422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001111745834350586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0027942657470703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0028340816497802734

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[Info] NAP non robuste au départ.
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02718353271484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03184318542480469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0024776458740234375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012454986572265625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001268148422241211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013201236724853516

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.033576011657714844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02517223358154297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0007691383361816406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008454322814941406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009241104125976562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0042743682861328125

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Coarsened NAP at iteration 0 was verified as robust.
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.030590057373046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017220735549926758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015537738800048828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002106189727783203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0019147396087646484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001668691635131836

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.050995826721191406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019535303115844727
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012660026550292969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011508464813232422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005287885665893555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014362335205078125

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.044942617416381836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02864837646484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002506732940673828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012731552124023438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012140274047851562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004902839660644531

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03331470489501953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026677370071411133
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010950565338134766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012001991271972656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011322498321533203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003881216049194336

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.055850982666015625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026326417922973633
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012063980102539062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0031976699829101562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.006487846374511719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014412403106689453

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.030472517013549805
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022307395935058594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011835098266601562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010533332824707031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011751651763916016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.006684780120849609

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.018399477005004883
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.025882959365844727
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012173652648925781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011217594146728516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012869834899902344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015723705291748047

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.016989469528198242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01662445068359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016644001007080078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011875629425048828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012917518615722656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012302398681640625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04532146453857422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.024206876754760742
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010793209075927734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.005890607833862305
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0017218589782714844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0035920143127441406

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.038214683532714844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0268251895904541
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011410713195800781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001268148422241211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003671407699584961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018045902252197266

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.039080142974853516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017225027084350586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004326581954956055
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010304450988769531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016515254974365234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001554250717163086

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04959535598754883
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023671865463256836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012650489807128906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0018105506896972656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.006970643997192383
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0041429996490478516

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.030031204223632812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019308805465698242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012087821960449219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012860298156738281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010955333709716797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012273788452148438

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02415180206298828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02486896514892578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0018086433410644531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0021758079528808594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001344442367553711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011911392211914062

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0263063907623291
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.021815776824951172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001346588134765625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0017287731170654297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012440681457519531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012357234954833984

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028482437133789062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022553682327270508
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0028192996978759766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0015959739685058594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004564762115478516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013265609741210938

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03653144836425781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04253721237182617
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0019621849060058594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010216236114501953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0023725032806396484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011854171752929688

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0568690299987793
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027311086654663086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013360977172851562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.006139039993286133
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013818740844726562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.011866092681884766

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.049310922622680664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02824091911315918
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0028095245361328125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013628005981445312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012733936309814453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001873016357421875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04593801498413086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0368199348449707
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011966228485107422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013020038604736328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012128353118896484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011925697326660156

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0463709831237793
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03625059127807617
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012598037719726562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001592397689819336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0022530555725097656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002275228500366211

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05430245399475098
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027129173278808594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011219978332519531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010056495666503906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001115560531616211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001186370849609375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04802703857421875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.025417804718017578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001245260238647461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011458396911621094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012657642364501953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012662410736083984

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05282163619995117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023102283477783203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013108253479003906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001613616943359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0034389495849609375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014088153839111328

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.048819541931152344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027196168899536133
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.005321502685546875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012292861938476562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.007461071014404297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014255046844482422

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04496026039123535
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026380300521850586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010819435119628906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004665851593017578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013315677642822266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.014280319213867188

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01724100112915039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022777557373046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010845661163330078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011789798736572266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001359701156616211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015873908996582031

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03760218620300293
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.025221824645996094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011098384857177734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013308525085449219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010864734649658203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011799335479736328

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05385303497314453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03046250343322754
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011432170867919922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0032389163970947266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014595985412597656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014047622680664062

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0354008674621582
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027106761932373047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014412403106689453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010857582092285156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011725425720214844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013556480407714844

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02773737907409668
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01721954345703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013566017150878906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012841224670410156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005499362945556641
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017132759094238281

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.036978960037231445
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03579068183898926
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011737346649169922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011229515075683594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018146038055419922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014176368713378906

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04773235321044922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02469801902770996
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010881423950195312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001210927963256836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004772663116455078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013353824615478516

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.023458003997802734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020652294158935547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001131296157836914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010075569152832031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001203298568725586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001916646957397461

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03442645072937012
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02382040023803711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008771419525146484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008838176727294922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009315013885498047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004125833511352539

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.037378787994384766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.021335124969482422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010981559753417969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011773109436035156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012121200561523438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001123666763305664

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.034491539001464844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0427241325378418
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002298593521118164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010726451873779297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013375282287597656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010802745819091797

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03413653373718262
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02417588233947754
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001026153564453125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001104116439819336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00508427619934082
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001005411148071289

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03153395652770996
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026932716369628906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0042095184326171875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014281272888183594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008611679077148438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.006510496139526367

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.026648521423339844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.018293142318725586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012128353118896484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011286735534667969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0033347606658935547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015859603881835938

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.035642147064208984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.024989604949951172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012242794036865234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014019012451171875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002042055130004883
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014786720275878906

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03341364860534668
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015714168548583984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011353492736816406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011687278747558594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001172780990600586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011317729949951172

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.036403656005859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.024890422821044922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001129150390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004540443420410156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012936592102050781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013370513916015625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04497957229614258
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0291898250579834
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003205537796020508
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001352548599243164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002811431884765625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001692056655883789

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02756214141845703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.025798797607421875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013709068298339844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001985311508178711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015835762023925781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011358261108398438

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03635978698730469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028149843215942383
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011837482452392578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011568069458007812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0027532577514648438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018188953399658203

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05038642883300781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.013634443283081055
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0060694217681884766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0024302005767822266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00131988525390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014791488647460938

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.030159473419189453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023136138916015625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011332035064697266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0045282840728759766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014035701751708984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0062541961669921875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.052437543869018555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03094339370727539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012056827545166016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010619163513183594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001150369644165039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012819766998291016

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.044867515563964844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019440412521362305
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.005659818649291992
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012557506561279297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001032114028930664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00595545768737793

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05549335479736328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02960658073425293
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001409769058227539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001199960708618164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013270378112792969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012731552124023438

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03212618827819824
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03564906120300293
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009837150573730469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004996299743652344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002114534378051758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.008071422576904297

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03439021110534668
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.008884429931640625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0007233619689941406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012462139129638672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011932849884033203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009899139404296875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05474853515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026897430419921875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011477470397949219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001081228256225586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.007877588272094727
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015497207641601562

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.057586669921875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02713322639465332
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001664876937866211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003714323043823242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014653205871582031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001310586929321289

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03247523307800293
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02953481674194336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011491775512695312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0047380924224853516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012691020965576172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013151168823242188

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02988409996032715
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03374767303466797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014662742614746094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009832382202148438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008544921875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010573863983154297

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05059242248535156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02392888069152832
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00402522087097168
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011339187622070312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00601959228515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015892982482910156

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03531670570373535
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026714086532592773
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011875629425048828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0037000179290771484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012726783752441406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012407302856445312

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0310976505279541
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.031034231185913086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011835098266601562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00116729736328125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012083053588867188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012090206146240234

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04443693161010742
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03684496879577637
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001180887222290039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.006624698638916016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016062259674072266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013325214385986328

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04363679885864258
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026401281356811523
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.006525754928588867
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012879371643066406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011124610900878906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012178421020507812

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0463109016418457
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028767824172973633
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011169910430908203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002482175827026367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013508796691894531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004033088684082031

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03687930107116699
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028907299041748047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011758804321289062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0032978057861328125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011773109436035156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013966560363769531

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028219223022460938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023151397705078125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00103759765625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012786388397216797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011839866638183594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004095554351806641

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03654170036315918
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03282761573791504
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0019681453704833984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0022058486938476562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.008801460266113281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018773078918457031

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04046893119812012
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03379631042480469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011439323425292969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010497570037841797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012564659118652344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011866092681884766

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.031571149826049805
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.05180859565734863
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001726388931274414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.006272077560424805
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018758773803710938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004759550094604492

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028691530227661133
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02156662940979004
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014045238494873047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0030868053436279297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002209901809692383
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0023229122161865234

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04560685157775879
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.018621444702148438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012428760528564453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.005296945571899414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.008972644805908203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017058849334716797

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.031061649322509766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02507185935974121
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0019674301147460938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00360870361328125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016222000122070312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.007882356643676758

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0484006404876709
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019572019577026367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015065670013427734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0015015602111816406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012869834899902344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0042552947998046875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04610085487365723
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.014820098876953125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001077413558959961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012383460998535156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013387203216552734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002899646759033203

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04446291923522949
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020070552825927734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001146554946899414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011343955993652344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011229515075683594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011522769927978516

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03910470008850098
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030928373336791992
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002836942672729492
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002033233642578125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0037841796875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001764059066772461

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.039742469787597656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02821946144104004
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015375614166259766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00258636474609375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00122833251953125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013985633850097656

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03517746925354004
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04984283447265625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011539459228515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011353492736816406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005297660827636719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013165473937988281

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04288792610168457
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026430130004882812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013225078582763672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010852813720703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005685567855834961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001392364501953125

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04717683792114258
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.038607120513916016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0017478466033935547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001791238784790039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011687278747558594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001356363296508789

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.045392751693725586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020830392837524414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004344463348388672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0016014575958251953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012218952178955078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0036551952362060547

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.030004262924194336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023383617401123047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012290477752685547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011687278747558594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0020978450775146484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001415252685546875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04943728446960449
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02625727653503418
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0024597644805908203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.006765127182006836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001322031021118164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012221336364746094

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.032318830490112305
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028275251388549805
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014548301696777344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012559890747070312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010924339294433594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012090206146240234

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029520034790039062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026796579360961914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011494159698486328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011029243469238281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004645586013793945
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013222694396972656

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03130173683166504
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03291797637939453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011870861053466797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0022802352905273438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003214597702026367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013225078582763672

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.06418132781982422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03223538398742676
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0025691986083984375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011856555938720703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002854585647583008
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018913745880126953

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.036346435546875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03581595420837402
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002117156982421875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0016536712646484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0017173290252685547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.006070852279663086

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.035455942153930664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026197433471679688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001096963882446289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.005700826644897461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014944076538085938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0020728111267089844

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.042902231216430664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.037415266036987305
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011365413665771484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010595321655273438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018210411071777344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016908645629882812

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05538535118103027
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.016746997833251953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011222362518310547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00141143798828125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013363361358642578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002115964889526367

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03267335891723633
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029798269271850586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004180908203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011837482452392578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012309551239013672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001363992691040039

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04553389549255371
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03283834457397461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015354156494140625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0030410289764404297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004097461700439453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015330314636230469

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04061579704284668
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026621580123901367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013501644134521484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003879070281982422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012640953063964844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001409292221069336

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.033760786056518555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03431987762451172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012216567993164062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013306140899658203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011792182922363281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011262893676757812

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03551173210144043
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0323796272277832
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004383563995361328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012924671173095703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00325775146484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016131401062011719

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04268145561218262
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029506683349609375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011601448059082031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012819766998291016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005102396011352539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015168190002441406

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04596304893493652
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.024163246154785156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010914802551269531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003184080123901367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001226186752319336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00435638427734375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03147387504577637
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028454303741455078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012359619140625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010657310485839844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0032830238342285156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013849735260009766

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02440619468688965
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0197296142578125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008270740509033203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011258125305175781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.000972747802734375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010919570922851562

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[Stochastic] Coarsened neurons: 3 | Remaining %: 85.00 | successful_iterations=1
[INFO] Coarsened NAP: [[1, 1, -1, 0, -1, 1, 1, 1, 1, 1], [-1, 1, 1, 1, 1, 0, 1, 1, 0, 1]]
[INFO] Original NAP:  [[1, 1, 1, 0, 0, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 0, 1, 1, 0, 1]]
[OK] Results saved to /home/goofy/stage/modified-oval-bab/clean/experiments/first_script+20250812_073628/results.json
