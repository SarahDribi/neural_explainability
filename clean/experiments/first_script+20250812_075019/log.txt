[INFO] Project root: /home/goofy/stage/modified-oval-bab/clean
[INFO] Experiments dir: /home/goofy/stage/modified-oval-bab/clean/experiments/first_script+20250812_075019
Loading ONNX model...
[INFO] Searching for NAP-exclusive robust inputs for label 1
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03296303749084473
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028280973434448242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011408329010009766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011532306671142578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010631084442138672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013222694396972656

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-38.2063, max=0.0000 | UB min=0.0000, max=44.5517
  Layer 2: LB min=0.0000, max=0.0000 | UB min=61.4856, max=92.1457
  Layer 3: LB min=-186.2676, max=226.6184 | UB min=106.2623, max=696.5044
  Layer 4: LB min=-266.4318, max=291.3767 | UB min=207.2865, max=677.8749
  Layer 5: LB min=-324.7933, max=369.6063 | UB min=273.1964, max=858.1282
  Layer 6: LB min=-138.0939, max=197.4918 | UB min=581.7582, max=677.8749
  Layer 7: LB min=-522.4902, max=-522.4902 | UB min=150.7498, max=150.7498
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
/home/goofy/stage/modified-oval-bab/plnn/anderson_linear_approximation.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(c_b, device=device).unsqueeze(0)
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03859281539916992
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029464244842529297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012285709381103516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0033326148986816406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016050338745117188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.007941484451293945

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-19.5789, max=0.0000 | UB min=0.0000, max=24.5340
  Layer 2: LB min=0.0000, max=0.0000 | UB min=31.7551, max=48.8659
  Layer 3: LB min=-98.0328, max=130.2761 | UB min=53.1063, max=373.3441
  Layer 4: LB min=-137.8324, max=161.3686 | UB min=106.5421, max=364.7351
  Layer 5: LB min=-167.8569, max=204.7671 | UB min=141.0503, max=456.5300
  Layer 6: LB min=-71.1136, max=113.3874 | UB min=301.0940, max=364.7351
  Layer 7: LB min=-268.6675, max=-268.6675 | UB min=77.7889, max=77.7889
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.007515430450439453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.004868030548095703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012559890747070312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013072490692138672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003023862838745117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018799304962158203

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-10.1752, max=0.0000 | UB min=0.0000, max=14.9748
  Layer 2: LB min=0.0000, max=0.0000 | UB min=16.0744, max=26.9094
  Layer 3: LB min=-51.7494, max=82.9030 | UB min=24.6743, max=206.4796
  Layer 4: LB min=-69.3198, max=96.4783 | UB min=53.6842, max=201.8145
  Layer 5: LB min=-84.5175, max=122.1129 | UB min=70.8192, max=247.6732
  Layer 6: LB min=-35.3846, max=71.6351 | UB min=154.2362, max=201.8145
  Layer 7: LB min=-133.2466, max=-133.2466 | UB min=40.1720, max=40.1720
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0013620853424072266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009162425994873047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010311603546142578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014650821685791016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015227794647216797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015034675598144531

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.3913, max=2.7620 | UB min=0.0000, max=10.8042
  Layer 2: LB min=0.0000, max=0.1918 | UB min=8.5169, max=16.1742
  Layer 3: LB min=-27.3138, max=58.5710 | UB min=7.0556, max=116.1566
  Layer 4: LB min=-31.4842, max=64.3349 | UB min=24.1535, max=111.2119
  Layer 5: LB min=-37.9468, max=78.6345 | UB min=31.7034, max=134.0001
  Layer 6: LB min=-13.9624, max=49.0524 | UB min=74.3105, max=111.2119
  Layer 7: LB min=-56.2513, max=-56.2513 | UB min=23.6666, max=23.6666
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028046369552612305
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023088693618774414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012264251708984375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010499954223632812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001135110855102539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011794567108154297

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.9753, max=4.5555 | UB min=0.0000, max=8.6876
  Layer 2: LB min=0.0000, max=3.6924 | UB min=4.7845, max=11.7993
  Layer 3: LB min=-16.9343, max=38.4209 | UB min=-1.2262, max=64.4316
  Layer 4: LB min=-13.8842, max=43.5778 | UB min=10.2120, max=63.2194
  Layer 5: LB min=-15.0651, max=50.4475 | UB min=13.2903, max=73.8129
  Layer 6: LB min=2.3355, max=33.6827 | UB min=36.7107, max=63.2194
  Layer 7: LB min=-17.1342, max=-17.1342 | UB min=12.7580, max=12.7580
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.007193565368652344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.008029699325561523
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012264251708984375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0021669864654541016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016598701477050781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017056465148925781

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.0873, max=5.4564 | UB min=0.0000, max=7.6248
  Layer 2: LB min=0.0000, max=5.8195 | UB min=2.9000, max=9.7929
  Layer 3: LB min=-12.1650, max=23.1944 | UB min=-5.0337, max=35.6010
  Layer 4: LB min=-6.5691, max=28.5729 | UB min=1.9727, max=37.4217
  Layer 5: LB min=-5.0981, max=32.7846 | UB min=5.6811, max=42.1726
  Layer 6: LB min=5.1065, max=20.7711 | UB min=20.4170, max=34.9953
  Layer 7: LB min=-3.0407, max=-3.0407 | UB min=9.2485, max=9.2485
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.044617652893066406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029757022857666016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003907680511474609
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014081001281738281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014824867248535156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.006496906280517578

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.4145, max=5.0058 | UB min=0.0000, max=8.1562
  Layer 2: LB min=0.0000, max=4.7616 | UB min=3.8929, max=10.7923
  Layer 3: LB min=-14.5459, max=31.8937 | UB min=-3.1567, max=50.9381
  Layer 4: LB min=-10.1272, max=37.6573 | UB min=5.9354, max=51.2101
  Layer 5: LB min=-9.8099, max=42.5966 | UB min=9.1807, max=58.6595
  Layer 6: LB min=4.6498, max=28.9415 | UB min=28.1499, max=50.6645
  Layer 7: LB min=-9.5092, max=-9.5092 | UB min=10.8886, max=10.8886
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028623342514038086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02715587615966797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011196136474609375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001096963882446289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010631084442138672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0023734569549560547

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.2509, max=5.2311 | UB min=0.0000, max=7.8905
  Layer 2: LB min=0.0000, max=5.2907 | UB min=3.4694, max=10.2912
  Layer 3: LB min=-13.3392, max=27.6511 | UB min=-4.0974, max=43.3854
  Layer 4: LB min=-8.3352, max=33.3368 | UB min=3.8918, max=44.4800
  Layer 5: LB min=-7.3571, max=37.7515 | UB min=7.3940, max=50.4287
  Layer 6: LB min=3.4405, max=25.1173 | UB min=24.1854, max=43.0745
  Layer 7: LB min=-6.1616, max=-6.1616 | UB min=10.0650, max=10.0650
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03481578826904297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027950525283813477
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00113677978515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010476112365722656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0020771026611328125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.011041879653930664

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.1691, max=5.3438 | UB min=0.0000, max=7.7576
  Layer 2: LB min=0.0000, max=5.5551 | UB min=3.1938, max=10.0418
  Layer 3: LB min=-12.7281, max=25.4384 | UB min=-4.5655, max=39.5008
  Layer 4: LB min=-7.4472, max=30.9574 | UB min=2.8872, max=40.9503
  Layer 5: LB min=-6.1876, max=35.2693 | UB min=6.5355, max=46.2741
  Layer 6: LB min=4.2688, max=22.9451 | UB min=22.2703, max=39.0274
  Layer 7: LB min=-4.5736, max=-4.5736 | UB min=9.6609, max=9.6609
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028661727905273438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.034021854400634766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010180473327636719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011081695556640625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009295940399169922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0048980712890625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.1282, max=5.4001 | UB min=0.0000, max=7.6912
  Layer 2: LB min=0.0000, max=5.6873 | UB min=3.0468, max=9.9172
  Layer 3: LB min=-12.4315, max=24.3213 | UB min=-4.7997, max=37.5508
  Layer 4: LB min=-7.0062, max=29.7668 | UB min=2.4054, max=39.1860
  Layer 5: LB min=-5.6236, max=34.0313 | UB min=6.1073, max=44.2083
  Layer 6: LB min=4.6920, max=21.8584 | UB min=21.3300, max=37.0068
  Layer 7: LB min=-3.7962, max=-3.7962 | UB min=9.4534, max=9.4534
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.025875091552734375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02260565757751465
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014684200286865234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0016021728515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001477956771850586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004386425018310547

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.1077, max=5.4282 | UB min=0.0000, max=7.6580
  Layer 2: LB min=0.0000, max=5.7534 | UB min=2.9734, max=9.8550
  Layer 3: LB min=-12.2981, max=23.7579 | UB min=-4.9167, max=36.5759
  Layer 4: LB min=-6.7875, max=29.1699 | UB min=2.1876, max=38.3039
  Layer 5: LB min=-5.3593, max=33.4122 | UB min=5.8941, max=43.1856
  Layer 6: LB min=4.8979, max=21.3149 | UB min=20.8719, max=36.0010
  Layer 7: LB min=-3.4170, max=-3.4170 | UB min=9.3516, max=9.3516
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0458683967590332
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027948617935180664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002130746841430664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.008482217788696289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013148784637451172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.008942365646362305

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.0975, max=5.4423 | UB min=0.0000, max=7.6414
  Layer 2: LB min=0.0000, max=5.7864 | UB min=2.9367, max=9.8239
  Layer 3: LB min=-12.2315, max=23.4761 | UB min=-4.9752, max=36.0884
  Layer 4: LB min=-6.6783, max=28.8714 | UB min=2.0801, max=37.8628
  Layer 5: LB min=-5.2285, max=33.0981 | UB min=5.7876, max=42.6787
  Layer 6: LB min=5.0018, max=21.0430 | UB min=20.6441, max=35.4982
  Layer 7: LB min=-3.2286, max=-3.2286 | UB min=9.3002, max=9.3002
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.014167547225952148
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.010821342468261719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013804435729980469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013663768768310547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014166831970214844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0024840831756591797

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.1026, max=5.4353 | UB min=0.0000, max=7.6497
  Layer 2: LB min=0.0000, max=5.7699 | UB min=2.9550, max=9.8395
  Layer 3: LB min=-12.2648, max=23.6170 | UB min=-4.9460, max=36.3322
  Layer 4: LB min=-6.7329, max=29.0206 | UB min=2.1338, max=38.0834
  Layer 5: LB min=-5.2938, max=33.2550 | UB min=5.8408, max=42.9321
  Layer 6: LB min=4.9497, max=21.1790 | UB min=20.7579, max=35.7496
  Layer 7: LB min=-3.3227, max=-3.3227 | UB min=9.3259, max=9.3259
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0066318511962890625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020689010620117188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.011350631713867188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002277374267578125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015878677368164062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019099712371826172

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.1001, max=5.4388 | UB min=0.0000, max=7.6455
  Layer 2: LB min=0.0000, max=5.7782 | UB min=2.9458, max=9.8317
  Layer 3: LB min=-12.2482, max=23.5466 | UB min=-4.9606, max=36.2103
  Layer 4: LB min=-6.7056, max=28.9460 | UB min=2.1070, max=37.9731
  Layer 5: LB min=-5.2611, max=33.1765 | UB min=5.8142, max=42.8054
  Layer 6: LB min=4.9757, max=21.1110 | UB min=20.7010, max=35.6239
  Layer 7: LB min=-3.2757, max=-3.2757 | UB min=9.3131, max=9.3131
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.011380195617675781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.004754304885864258
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010256767272949219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001005411148071289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009663105010986328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0028841495513916016

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.0975, max=5.4423 | UB min=0.0000, max=7.6414
  Layer 2: LB min=0.0000, max=5.7864 | UB min=2.9367, max=9.8239
  Layer 3: LB min=-12.2315, max=23.4761 | UB min=-4.9752, max=36.0884
  Layer 4: LB min=-6.6783, max=28.8714 | UB min=2.0801, max=37.8628
  Layer 5: LB min=-5.2285, max=33.0981 | UB min=5.7876, max=42.6787
  Layer 6: LB min=5.0018, max=21.0430 | UB min=20.6441, max=35.4982
  Layer 7: LB min=-3.2286, max=-3.2286 | UB min=9.3002, max=9.3002
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.010210037231445312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020442724227905273
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012979507446289062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0018610954284667969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014452934265136719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014150142669677734
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.004354953765869141
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0055158138275146484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003160715103149414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003674030303955078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012993812561035156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00113677978515625
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01843881607055664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.018805265426635742
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0047664642333984375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003523588180541992
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.006369590759277344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004418611526489258
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.013605833053588867
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.004750967025756836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0029115676879882812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0032079219818115234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004363298416137695
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003179311752319336
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0012814998626708984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.016642093658447266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011448860168457031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00087738037109375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010552406311035156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010597705841064453
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.014931678771972656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01798248291015625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002802610397338867
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0033063888549804688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0045909881591796875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004349470138549805
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.012404918670654297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.006024360656738281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010123252868652344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001062154769897461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010390281677246094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001210927963256836
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05985856056213379
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02051258087158203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012133121490478516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010945796966552734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.008656740188598633
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016722679138183594
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.035040855407714844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029339075088500977
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003634929656982422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0027272701263427734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.009481191635131836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.016385793685913086
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03140425682067871
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.024708032608032227
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003838777542114258
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002459287643432617
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012693405151367188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001443624496459961
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.030218839645385742
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030881166458129883
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0029337406158447266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0031304359436035156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003515005111694336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.012200117111206055
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04515266418457031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019840717315673828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.012756586074829102
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0031697750091552734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.009627342224121094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.006534576416015625
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03280067443847656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01723933219909668
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0029709339141845703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0029726028442382812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0064961910247802734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004320859909057617
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.059918880462646484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022653579711914062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013141632080078125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010323524475097656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003522634506225586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014503002166748047
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03763890266418457
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0288393497467041
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012290477752685547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0038695335388183594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012106895446777344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001218557357788086
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.038103342056274414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01621866226196289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001005411148071289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0066945552825927734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012271404266357422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013821125030517578

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-39.5999, max=0.0000 | UB min=0.0000, max=53.5932
  Layer 2: LB min=-60.0331, max=0.0000 | UB min=0.0000, max=91.8840
  Layer 3: LB min=-187.1825, max=227.6416 | UB min=104.5682, max=695.9067
  Layer 4: LB min=-267.9748, max=293.8542 | UB min=206.0851, max=673.6639
  Layer 5: LB min=-325.5292, max=370.8131 | UB min=272.5370, max=856.1168
  Layer 6: LB min=-138.4988, max=199.8865 | UB min=580.3879, max=673.6639
  Layer 7: LB min=-518.8408, max=-518.8408 | UB min=151.2998, max=151.2998
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0511012077331543
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028896570205688477
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004147052764892578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010628700256347656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010912418365478516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012080669403076172

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-21.5364, max=0.0000 | UB min=0.0000, max=28.4712
  Layer 2: LB min=-32.6776, max=0.0000 | UB min=0.0000, max=48.0408
  Layer 3: LB min=-97.8626, max=132.3947 | UB min=49.2602, max=369.5156
  Layer 4: LB min=-137.8967, max=164.8900 | UB min=102.7827, max=347.6699
  Layer 5: LB min=-166.1539, max=205.8547 | UB min=137.2880, max=445.8500
  Layer 6: LB min=-70.5253, max=117.6321 | UB min=293.8061, max=347.6699
  Layer 7: LB min=-254.7386, max=-254.7386 | UB min=77.9647, max=77.9647
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.023064374923706055
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028116226196289062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0031158924102783203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003184080123901367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004616260528564453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004235744476318359

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-12.3054, max=1.6462 | UB min=0.0000, max=18.0809
  Layer 2: LB min=-18.4452, max=0.0000 | UB min=0.0000, max=28.7518
  Layer 3: LB min=-51.6135, max=84.6528 | UB min=16.1546, max=198.6285
  Layer 4: LB min=-66.7159, max=99.3392 | UB min=45.6466, max=180.6946
  Layer 5: LB min=-79.5378, max=120.9372 | UB min=63.5761, max=231.4058
  Layer 6: LB min=-33.9386, max=76.9234 | UB min=139.2529, max=180.6946
  Layer 7: LB min=-113.0977, max=-113.0977 | UB min=40.3706, max=40.3706
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028997182846069336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02768540382385254
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0031082630157470703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0033028125762939453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.006632089614868164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004853487014770508

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-7.6281, max=5.5818 | UB min=0.0000, max=13.9241
  Layer 2: LB min=-11.8155, max=6.6333 | UB min=0.0000, max=20.9872
  Layer 3: LB min=-29.0072, max=53.7404 | UB min=-1.3845, max=97.8952
  Layer 4: LB min=-30.1224, max=57.8184 | UB min=17.2337, max=91.3434
  Layer 5: LB min=-32.4934, max=65.8484 | UB min=26.9547, max=111.1042
  Layer 6: LB min=-9.6564, max=47.4890 | UB min=60.2424, max=91.3434
  Layer 7: LB min=-39.5947, max=-39.5947 | UB min=21.1724, max=21.1724
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0375673770904541
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02851414680480957
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003194093704223633
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004601955413818359
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013718605041503906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00524449348449707

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.2715, max=7.5504 | UB min=-0.6968, max=11.8346
  Layer 2: LB min=-8.7571, max=10.5367 | UB min=-2.1411, max=17.6296
  Layer 3: LB min=-20.8528, max=27.5665 | UB min=-9.1031, max=47.0800
  Layer 4: LB min=-14.5198, max=33.2112 | UB min=7.0353, max=47.3061
  Layer 5: LB min=-13.1736, max=32.2244 | UB min=12.3637, max=50.5310
  Layer 6: LB min=-1.5349, max=27.5665 | UB min=28.8473, max=47.0800
  Layer 7: LB min=-10.3452, max=-10.3452 | UB min=13.7558, max=13.7558
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04442930221557617
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028439760208129883
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0019261837005615234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010874271392822266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011560916900634766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011322498321533203

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-4.0932, max=8.5347 | UB min=-1.7123, max=10.7892
  Layer 2: LB min=-7.2327, max=12.3263 | UB min=-3.9835, max=15.9522
  Layer 3: LB min=-17.6856, max=16.7380 | UB min=-12.2094, max=26.2396
  Layer 4: LB min=-7.3761, max=20.4852 | UB min=2.9845, max=27.1070
  Layer 5: LB min=-5.5037, max=17.8077 | UB min=5.8343, max=26.2396
  Layer 6: LB min=3.1463, max=16.7380 | UB min=16.0575, max=26.2396
  Layer 7: LB min=0.8326, max=0.8326 | UB min=10.8141, max=10.8141
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01828765869140625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.018222332000732422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001138925552368164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0050051212310791016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013527870178222656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014071464538574219

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-4.6823, max=8.0426 | UB min=-1.2046, max=11.3119
  Layer 2: LB min=-7.9942, max=11.4316 | UB min=-3.0536, max=16.7907
  Layer 3: LB min=-19.2645, max=22.1341 | UB min=-10.7364, max=36.5771
  Layer 4: LB min=-10.7305, max=26.8507 | UB min=4.8077, max=37.0308
  Layer 5: LB min=-9.1222, max=24.6227 | UB min=8.8659, max=37.2799
  Layer 6: LB min=0.2973, max=22.1341 | UB min=22.0774, max=36.5771
  Layer 7: LB min=-4.0331, max=-4.0331 | UB min=12.0406, max=12.0406
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04122447967529297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02817559242248535
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002907991409301758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.012769937515258789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0038344860076904297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00423121452331543

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-4.9769, max=7.7965 | UB min=-0.9507, max=11.5733
  Layer 2: LB min=-8.3756, max=10.9842 | UB min=-2.5967, max=17.2101
  Layer 3: LB min=-20.0580, max=24.8648 | UB min=-9.9522, max=41.8167
  Layer 4: LB min=-12.5456, max=30.0575 | UB min=5.8351, max=42.1496
  Layer 5: LB min=-11.0656, max=28.1787 | UB min=10.5495, max=43.4888
  Layer 6: LB min=-0.6106, max=24.8648 | UB min=25.3191, max=41.8167
  Layer 7: LB min=-6.9740, max=-6.9740 | UB min=12.8414, max=12.8414
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04309368133544922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015477418899536133
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012400150299072266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009918212890625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018765926361083984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012903213500976562

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.1242, max=7.6735 | UB min=-0.8238, max=11.7040
  Layer 2: LB min=-8.5664, max=10.7604 | UB min=-2.3688, max=17.4199
  Layer 3: LB min=-20.4551, max=26.2157 | UB min=-9.5277, max=44.4481
  Layer 4: LB min=-13.5436, max=31.6343 | UB min=6.4345, max=44.7253
  Layer 5: LB min=-12.1235, max=30.2016 | UB min=11.4553, max=47.0093
  Layer 6: LB min=-1.0727, max=26.2157 | UB min=27.0837, max=44.4481
  Layer 7: LB min=-8.6599, max=-8.6599 | UB min=13.3150, max=13.3150
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.051003456115722656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.018419981002807617
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011928081512451172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011374950408935547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011751651763916016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0060160160064697266

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.1978, max=7.6120 | UB min=-0.7603, max=11.7693
  Layer 2: LB min=-8.6617, max=10.6486 | UB min=-2.2549, max=17.5247
  Layer 3: LB min=-20.6539, max=26.8911 | UB min=-9.3154, max=45.7640
  Layer 4: LB min=-14.0343, max=32.4227 | UB min=6.7347, max=46.0153
  Layer 5: LB min=-12.6495, max=31.2130 | UB min=11.9091, max=48.7702
  Layer 6: LB min=-1.3038, max=26.8911 | UB min=27.9657, max=45.7640
  Layer 7: LB min=-9.5028, max=-9.5028 | UB min=13.5392, max=13.5392
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04372000694274902
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01878809928894043
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010669231414794922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011744499206542969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010592937469482422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.008508920669555664

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.1610, max=7.6427 | UB min=-0.7920, max=11.7366
  Layer 2: LB min=-8.6141, max=10.7045 | UB min=-2.3118, max=17.4723
  Layer 3: LB min=-20.5545, max=26.5534 | UB min=-9.4216, max=45.1060
  Layer 4: LB min=-13.7896, max=32.0286 | UB min=6.5846, max=45.3702
  Layer 5: LB min=-12.3866, max=30.7073 | UB min=11.6821, max=47.8898
  Layer 6: LB min=-1.1882, max=26.5534 | UB min=27.5245, max=45.1060
  Layer 7: LB min=-9.0813, max=-9.0813 | UB min=13.4280, max=13.4280
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027112483978271484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.021639585494995117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014176368713378906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001720428466796875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001504659652709961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015954971313476562

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.1426, max=7.6581 | UB min=-0.8079, max=11.7203
  Layer 2: LB min=-8.5902, max=10.7325 | UB min=-2.3403, max=17.4461
  Layer 3: LB min=-20.5048, max=26.3845 | UB min=-9.4747, max=44.7771
  Layer 4: LB min=-13.6667, max=31.8315 | UB min=6.5095, max=45.0477
  Layer 5: LB min=-12.2551, max=30.4545 | UB min=11.5686, max=47.4495
  Layer 6: LB min=-1.1305, max=26.3845 | UB min=27.3041, max=44.7771
  Layer 7: LB min=-8.8706, max=-8.8706 | UB min=13.3718, max=13.3718
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02766561508178711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027108192443847656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011017322540283203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012738704681396484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.011244535446166992
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001966714859008789

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.1334, max=7.6658 | UB min=-0.8158, max=11.7121
  Layer 2: LB min=-8.5783, max=10.7465 | UB min=-2.3545, max=17.4330
  Layer 3: LB min=-20.4800, max=26.3001 | UB min=-9.5012, max=44.6126
  Layer 4: LB min=-13.6051, max=31.7329 | UB min=6.4720, max=44.8865
  Layer 5: LB min=-12.1893, max=30.3280 | UB min=11.5120, max=47.2294
  Layer 6: LB min=-1.1015, max=26.3001 | UB min=27.1939, max=44.6126
  Layer 7: LB min=-8.7653, max=-8.7653 | UB min=13.3435, max=13.3435
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04809880256652832
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03287553787231445
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011501312255859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002878427505493164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013976097106933594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.010196447372436523

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.1288, max=7.6696 | UB min=-0.8198, max=11.7081
  Layer 2: LB min=-8.5723, max=10.7534 | UB min=-2.3616, max=17.4264
  Layer 3: LB min=-20.4675, max=26.2579 | UB min=-9.5145, max=44.5303
  Layer 4: LB min=-13.5744, max=31.6836 | UB min=6.4533, max=44.8059
  Layer 5: LB min=-12.1564, max=30.2648 | UB min=11.4836, max=47.1193
  Layer 6: LB min=-1.0871, max=26.2579 | UB min=27.1388, max=44.5303
  Layer 7: LB min=-8.7126, max=-8.7126 | UB min=13.3293, max=13.3293
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02715444564819336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02248239517211914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010292530059814453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010867118835449219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003113985061645508
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016789436340332031

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.1242, max=7.6735 | UB min=-0.8238, max=11.7040
  Layer 2: LB min=-8.5664, max=10.7604 | UB min=-2.3688, max=17.4199
  Layer 3: LB min=-20.4551, max=26.2157 | UB min=-9.5277, max=44.4481
  Layer 4: LB min=-13.5436, max=31.6343 | UB min=6.4345, max=44.7253
  Layer 5: LB min=-12.1235, max=30.2016 | UB min=11.4553, max=47.0093
  Layer 6: LB min=-1.0727, max=26.2157 | UB min=27.0837, max=44.4481
  Layer 7: LB min=-8.6599, max=-8.6599 | UB min=13.3150, max=13.3150
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027814626693725586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.031526803970336914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0017442703247070312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0025131702423095703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012323856353759766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.011168956756591797
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.048368215560913086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022307157516479492
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.009562253952026367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003919124603271484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012936592102050781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.005393028259277344
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.014551639556884766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.016092300415039062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012199878692626953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0016121864318847656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016243457794189453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0028867721557617188
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.004573345184326172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.004198312759399414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001241922378540039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0015332698822021484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001432657241821289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017311573028564453
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05478024482727051
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029761552810668945
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010461807250976562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001094818115234375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001176595687866211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011777877807617188
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.013172626495361328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.005611896514892578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011725425720214844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009739398956298828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001096963882446289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011970996856689453
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0014450550079345703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.00434422492980957
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009627342224121094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009748935699462891
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016751289367675781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013093948364257812
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03666424751281738
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.014630794525146484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010221004486083984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010786056518554688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.007077217102050781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013477802276611328
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.019843101501464844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02618694305419922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001081228256225586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002979755401611328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018415451049804688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013489723205566406
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.033054351806640625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029003620147705078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010628700256347656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011985301971435547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003062009811401367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013959407806396484
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.030997037887573242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.018901586532592773
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001300811767578125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012536048889160156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011754035949707031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011832714080810547
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05161452293395996
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.034034013748168945
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015113353729248047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013048648834228516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001336812973022461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.006955623626708984
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.033110618591308594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01845717430114746
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0017728805541992188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00115966796875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012140274047851562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001247406005859375
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04483532905578613
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03432321548461914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0017290115356445312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012443065643310547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001180887222290039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012896060943603516
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04552340507507324
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022442102432250977
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012278556823730469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001299142837524414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.007036685943603516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014088153839111328
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02926945686340332
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01285862922668457
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011641979217529297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010826587677001953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011610984802246094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011343955993652344

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-38.1396, max=0.0000 | UB min=0.0000, max=53.3740
  Layer 2: LB min=-59.7523, max=0.0000 | UB min=0.0000, max=91.3982
  Layer 3: LB min=-184.8863, max=222.4479 | UB min=105.5639, max=689.1536
  Layer 4: LB min=-265.7149, max=288.7630 | UB min=205.7368, max=667.5762
  Layer 5: LB min=-323.9898, max=364.6531 | UB min=270.9888, max=850.1638
  Layer 6: LB min=-138.0440, max=194.7981 | UB min=577.8207, max=667.5762
  Layer 7: LB min=-519.0209, max=-519.0209 | UB min=149.5644, max=149.5644
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0245819091796875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.013804912567138672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016434192657470703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0030837059020996094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0017693042755126953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013647079467773438

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-19.6893, max=0.0000 | UB min=0.0000, max=28.2907
  Layer 2: LB min=-32.2719, max=0.0000 | UB min=0.0000, max=47.7740
  Layer 3: LB min=-95.7442, max=124.3520 | UB min=51.8724, max=362.5962
  Layer 4: LB min=-136.6211, max=157.9652 | UB min=103.8759, max=346.6880
  Layer 5: LB min=-166.5703, max=197.7649 | UB min=137.5377, max=441.5319
  Layer 6: LB min=-70.9659, max=110.0787 | UB min=294.5009, max=346.6880
  Layer 7: LB min=-259.7729, max=-259.7729 | UB min=75.8993, max=75.8993
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.025156497955322266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.00912022590637207
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0037665367126464844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004456758499145508
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003801584243774414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002042531967163086

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-10.3484, max=0.0000 | UB min=0.0000, max=15.6002
  Layer 2: LB min=-18.0052, max=0.0000 | UB min=0.0000, max=25.6818
  Layer 3: LB min=-49.2462, max=76.2306 | UB min=20.3688, max=194.7134
  Layer 4: LB min=-67.8114, max=92.8052 | UB min=48.8037, max=180.3871
  Layer 5: LB min=-83.5692, max=113.7181 | UB min=66.2532, max=230.5850
  Layer 6: LB min=-35.7623, max=68.6030 | UB min=144.6362, max=180.3871
  Layer 7: LB min=-122.5621, max=-122.5621 | UB min=38.0827, max=38.0827
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03878903388977051
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030533790588378906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015099048614501953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001024484634399414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004161357879638672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016326904296875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.6399, max=2.5794 | UB min=0.0000, max=11.0923
  Layer 2: LB min=-11.2869, max=1.3771 | UB min=0.0000, max=16.5071
  Layer 3: LB min=-26.0283, max=46.3134 | UB min=4.0505, max=100.0628
  Layer 4: LB min=-30.4791, max=55.7333 | UB min=19.2900, max=93.5127
  Layer 5: LB min=-37.0832, max=65.3197 | UB min=29.4059, max=116.1132
  Layer 6: LB min=-13.7781, max=43.1867 | UB min=64.6026, max=93.5127
  Layer 7: LB min=-49.3697, max=-49.3697 | UB min=21.5233, max=21.5233
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.023703336715698242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.018356800079345703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012769699096679688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00418543815612793
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005117893218994141
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002526998519897461

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.2719, max=4.4554 | UB min=0.0000, max=8.8264
  Layer 2: LB min=-8.0867, max=5.2772 | UB min=-1.0966, max=12.6441
  Layer 3: LB min=-15.7581, max=26.3617 | UB min=-3.5061, max=48.1756
  Layer 4: LB min=-13.7454, max=32.8245 | UB min=6.2735, max=48.2164
  Layer 5: LB min=-15.0738, max=33.9558 | UB min=13.0604, max=55.2702
  Layer 6: LB min=-5.4402, max=26.3617 | UB min=28.0218, max=48.1756
  Layer 7: LB min=-16.4177, max=-16.4177 | UB min=13.3655, max=13.3655
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0012888908386230469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009028911590576172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011174678802490234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.009191513061523438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0019097328186035156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016748905181884766

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.0854, max=5.3958 | UB min=0.0000, max=7.6885
  Layer 2: LB min=-6.5960, max=7.1993 | UB min=-3.2588, max=10.8499
  Layer 3: LB min=-12.3872, max=15.7466 | UB min=-7.1225, max=25.4126
  Layer 4: LB min=-7.0233, max=19.7948 | UB min=1.4168, max=26.0348
  Layer 5: LB min=-4.9833, max=18.1378 | UB min=6.2435, max=26.6714
  Layer 6: LB min=0.1306, max=15.7466 | UB min=12.2605, max=25.4126
  Layer 7: LB min=-1.5071, max=-1.5071 | UB min=7.8103, max=7.8103
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0012135505676269531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0010149478912353516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010142326354980469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00124359130859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013165473937988281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001493692398071289

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.6787, max=4.9253 | UB min=0.0000, max=8.2574
  Layer 2: LB min=-7.3338, max=6.2435 | UB min=-2.1793, max=11.7470
  Layer 3: LB min=-14.0601, max=20.6893 | UB min=-5.3533, max=36.2385
  Layer 4: LB min=-10.1256, max=25.9296 | UB min=3.8435, max=36.4704
  Layer 5: LB min=-9.9342, max=24.8740 | UB min=9.5591, max=39.7027
  Layer 6: LB min=-3.6087, max=20.6893 | UB min=19.9547, max=36.2385
  Layer 7: LB min=-9.0449, max=-9.0449 | UB min=11.4172, max=11.4172
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.023979663848876953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.009567975997924805
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014407634735107422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001409769058227539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014531612396240234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015306472778320312

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.3820, max=5.1603 | UB min=0.0000, max=7.9729
  Layer 2: LB min=-6.9591, max=6.7260 | UB min=-2.7192, max=11.2984
  Layer 3: LB min=-13.2230, max=18.1394 | UB min=-6.2566, max=30.7255
  Layer 4: LB min=-8.3952, max=22.7782 | UB min=2.6276, max=31.0388
  Layer 5: LB min=-7.4323, max=21.2426 | UB min=7.8631, max=32.9403
  Layer 6: LB min=-0.6882, max=18.1394 | UB min=16.0174, max=30.7255
  Layer 7: LB min=-4.7814, max=-4.7814 | UB min=8.6679, max=8.6679
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04031181335449219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019895076751708984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013759136199951172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001462697982788086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001312255859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013844966888427734

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.5303, max=5.0428 | UB min=0.0000, max=8.1152
  Layer 2: LB min=-7.1463, max=6.4849 | UB min=-2.4494, max=11.5227
  Layer 3: LB min=-13.6416, max=19.2892 | UB min=-5.8085, max=33.3556
  Layer 4: LB min=-9.2605, max=24.2383 | UB min=3.2356, max=33.6329
  Layer 5: LB min=-8.6793, max=22.8118 | UB min=8.7122, max=36.0813
  Layer 6: LB min=-1.1080, max=19.2892 | UB min=17.9849, max=33.3556
  Layer 7: LB min=-6.5467, max=-6.5467 | UB min=9.0988, max=9.0988
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03253030776977539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01629638671875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010714530944824219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010936260223388672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010581016540527344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012843608856201172

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.4562, max=5.1016 | UB min=0.0000, max=8.0441
  Layer 2: LB min=-7.0527, max=6.6055 | UB min=-2.5844, max=11.4106
  Layer 3: LB min=-13.4323, max=18.7148 | UB min=-6.0334, max=32.0406
  Layer 4: LB min=-8.8280, max=23.5085 | UB min=2.9315, max=32.3341
  Layer 5: LB min=-8.0550, max=22.0245 | UB min=8.2879, max=34.5099
  Layer 6: LB min=-0.8979, max=18.7148 | UB min=17.0006, max=32.0406
  Layer 7: LB min=-5.6632, max=-5.6632 | UB min=8.8831, max=8.8831
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03561544418334961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.036167144775390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001150369644165039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001112222671508789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0037772655487060547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017778873443603516

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.4933, max=5.0722 | UB min=0.0000, max=8.0796
  Layer 2: LB min=-7.0995, max=6.5452 | UB min=-2.5169, max=11.4666
  Layer 3: LB min=-13.5369, max=19.0020 | UB min=-5.9213, max=32.6981
  Layer 4: LB min=-9.0443, max=23.8735 | UB min=3.0836, max=32.9831
  Layer 5: LB min=-8.3669, max=22.4174 | UB min=8.5000, max=35.2952
  Layer 6: LB min=-1.0030, max=19.0020 | UB min=17.4926, max=32.6981
  Layer 7: LB min=-6.1047, max=-6.1047 | UB min=8.9909, max=8.9909
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04988241195678711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.021636962890625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008113384246826172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.005906820297241211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012555122375488281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013175010681152344

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.4747, max=5.0869 | UB min=0.0000, max=8.0618
  Layer 2: LB min=-7.0761, max=6.5754 | UB min=-2.5506, max=11.4386
  Layer 3: LB min=-13.4846, max=18.8585 | UB min=-5.9775, max=32.3694
  Layer 4: LB min=-8.9361, max=23.6910 | UB min=3.0076, max=32.6585
  Layer 5: LB min=-8.2109, max=22.2208 | UB min=8.3940, max=34.9025
  Layer 6: LB min=-0.9504, max=18.8585 | UB min=17.2466, max=32.3694
  Layer 7: LB min=-5.8839, max=-5.8839 | UB min=8.9370, max=8.9370
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.037993431091308594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02288365364074707
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003754138946533203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003213167190551758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0032958984375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.012216329574584961

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.4654, max=5.0942 | UB min=0.0000, max=8.0529
  Layer 2: LB min=-7.0644, max=6.5904 | UB min=-2.5675, max=11.4246
  Layer 3: LB min=-13.4585, max=18.7867 | UB min=-6.0054, max=32.2050
  Layer 4: LB min=-8.8821, max=23.5998 | UB min=2.9695, max=32.4962
  Layer 5: LB min=-8.1329, max=22.1226 | UB min=8.3409, max=34.7062
  Layer 6: LB min=-0.9242, max=18.7867 | UB min=17.1236, max=32.2050
  Layer 7: LB min=-5.7735, max=-5.7735 | UB min=8.9100, max=8.9100
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.033071279525756836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026021718978881836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0042574405670166016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0032744407653808594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0048787593841552734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015408992767333984

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.4701, max=5.0905 | UB min=0.0000, max=8.0574
  Layer 2: LB min=-7.0703, max=6.5829 | UB min=-2.5591, max=11.4316
  Layer 3: LB min=-13.4715, max=18.8226 | UB min=-5.9915, max=32.2872
  Layer 4: LB min=-8.9091, max=23.6454 | UB min=2.9886, max=32.5773
  Layer 5: LB min=-8.1719, max=22.1717 | UB min=8.3674, max=34.8043
  Layer 6: LB min=-0.9373, max=18.8226 | UB min=17.1851, max=32.2872
  Layer 7: LB min=-5.8287, max=-5.8287 | UB min=8.9235, max=8.9235
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.032064199447631836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02559638023376465
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001251220703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010983943939208984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0024504661560058594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015549659729003906

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.4654, max=5.0942 | UB min=0.0000, max=8.0529
  Layer 2: LB min=-7.0644, max=6.5904 | UB min=-2.5675, max=11.4246
  Layer 3: LB min=-13.4585, max=18.7867 | UB min=-6.0054, max=32.2050
  Layer 4: LB min=-8.8821, max=23.5998 | UB min=2.9695, max=32.4962
  Layer 5: LB min=-8.1329, max=22.1226 | UB min=8.3409, max=34.7062
  Layer 6: LB min=-0.9242, max=18.7867 | UB min=17.1236, max=32.2050
  Layer 7: LB min=-5.7735, max=-5.7735 | UB min=8.9100, max=8.9100
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029727697372436523
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.016516447067260742
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010905265808105469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0036857128143310547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001500844955444336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014586448669433594
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02773761749267578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02275252342224121
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0025713443756103516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0022983551025390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0037763118743896484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0053827762603759766
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03302597999572754
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02075815200805664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013222694396972656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0032045841217041016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016989707946777344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0037691593170166016
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.019772768020629883
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02892017364501953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002460002899169922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001132965087890625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018775463104248047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0020084381103515625
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029146909713745117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0308382511138916
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012934207916259766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010843276977539062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011703968048095703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012362003326416016
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.024819612503051758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.025091886520385742
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003998279571533203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011630058288574219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010764598846435547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0025932788848876953
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02884221076965332
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02012777328491211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011322498321533203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00124359130859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001116037368774414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012586116790771484
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029712438583374023
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.012099981307983398
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015709400177001953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010867118835449219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0023860931396484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013659000396728516
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029945850372314453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017347335815429688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001085042953491211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004960536956787109
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001894235610961914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004773855209350586
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02980494499206543
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.012973785400390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00116729736328125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004061222076416016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0020775794982910156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013663768768310547
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.024428844451904297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022404193878173828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012125968933105469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010099411010742188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012359619140625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0020906925201416016
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01303410530090332
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01558232307434082
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003351449966430664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0021736621856689453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004123210906982422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018112659454345703
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0447537899017334
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017894744873046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001172780990600586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010035037994384766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0033698081970214844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0027866363525390625
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02151179313659668
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.012854337692260742
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011060237884521484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010669231414794922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0047299861907958984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0024213790893554688
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.009646177291870117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0011649131774902344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016262531280517578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0016016960144042969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016410350799560547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016548633575439453
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02967047691345215
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02202630043029785
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00482487678527832
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013954639434814453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.006105661392211914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019617080688476562

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-38.7181, max=0.0000 | UB min=0.0000, max=53.5911
  Layer 2: LB min=-59.4868, max=0.0000 | UB min=0.0000, max=91.2738
  Layer 3: LB min=-184.8277, max=223.6259 | UB min=105.1413, max=689.9818
  Layer 4: LB min=-265.5284, max=290.0323 | UB min=205.8919, max=668.7595
  Layer 5: LB min=-323.8907, max=365.7060 | UB min=270.8965, max=850.6973
  Layer 6: LB min=-137.8191, max=196.0179 | UB min=578.1852, max=668.7595
  Layer 7: LB min=-518.6059, max=-518.6059 | UB min=149.1776, max=149.1776
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04341864585876465
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04194498062133789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.007619142532348633
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012371540069580078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0022881031036376953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012059211730957031

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-20.4862, max=0.0000 | UB min=0.0000, max=28.5978
  Layer 2: LB min=-31.8529, max=0.0000 | UB min=0.0000, max=47.4488
  Layer 3: LB min=-95.3704, max=126.1051 | UB min=51.2248, max=362.9197
  Layer 4: LB min=-136.0268, max=159.5990 | UB min=103.9078, max=345.5271
  Layer 5: LB min=-165.8014, max=198.8670 | UB min=136.8170, max=441.0629
  Layer 6: LB min=-70.2536, max=111.4851 | UB min=294.0691, max=345.5271
  Layer 7: LB min=-257.5300, max=-257.5300 | UB min=75.1919, max=75.1919
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02714681625366211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.013373136520385742
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010554790496826172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010061264038085938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001199960708618164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004033088684082031

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-11.2423, max=0.0000 | UB min=0.0000, max=15.9472
  Layer 2: LB min=-17.7292, max=0.0000 | UB min=0.0000, max=25.4267
  Layer 3: LB min=-48.9841, max=78.4801 | UB min=22.1686, max=195.6392
  Layer 4: LB min=-67.3543, max=94.6327 | UB min=49.5001, max=179.8177
  Layer 5: LB min=-82.5551, max=115.3066 | UB min=65.2833, max=231.0688
  Layer 6: LB min=-34.8550, max=70.3943 | UB min=144.5742, max=179.8177
  Layer 7: LB min=-120.3470, max=-120.3470 | UB min=37.3813, max=37.3813
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04287409782409668
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019429683685302734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.013305902481079102
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011775493621826172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013518333435058594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011990070343017578

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.5399, max=3.1971 | UB min=0.0000, max=11.5797
  Layer 2: LB min=-10.3557, max=2.1873 | UB min=0.0000, max=16.5845
  Layer 3: LB min=-25.2776, max=48.6388 | UB min=2.9786, max=100.1543
  Layer 4: LB min=-29.2285, max=58.2266 | UB min=19.1920, max=92.4417
  Layer 5: LB min=-35.4940, max=65.4261 | UB min=27.5537, max=114.0590
  Layer 6: LB min=-9.9748, max=45.6964 | UB min=63.5203, max=92.4417
  Layer 7: LB min=-45.0539, max=-45.0539 | UB min=20.1650, max=20.1650
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0302426815032959
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.024391651153564453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012505054473876953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001157999038696289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003580331802368164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015797615051269531

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-4.1683, max=5.1316 | UB min=0.0000, max=9.4051
  Layer 2: LB min=-7.1562, max=6.0861 | UB min=-0.5928, max=12.8726
  Layer 3: LB min=-15.0505, max=28.0475 | UB min=-4.5193, max=47.5423
  Layer 4: LB min=-13.0875, max=34.5616 | UB min=7.0262, max=47.7648
  Layer 5: LB min=-14.1961, max=34.7700 | UB min=10.5181, max=53.2989
  Layer 6: LB min=-1.3502, max=28.0475 | UB min=28.0949, max=47.2260
  Layer 7: LB min=-12.8338, max=-12.8338 | UB min=10.4844, max=10.4844
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.024718523025512695
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02901935577392578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016379356384277344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0032095909118652344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016238689422607422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0032501220703125

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.9810, max=6.1009 | UB min=-0.6602, max=8.3163
  Layer 2: LB min=-5.6579, max=7.8619 | UB min=-2.4392, max=11.1765
  Layer 3: LB min=-11.8441, max=15.9394 | UB min=-7.3913, max=25.1041
  Layer 4: LB min=-6.2950, max=20.2024 | UB min=2.4626, max=26.1003
  Layer 5: LB min=-5.8738, max=17.9250 | UB min=3.7028, max=25.1041
  Layer 6: LB min=2.3067, max=15.9394 | UB min=13.9621, max=25.1041
  Layer 7: LB min=-0.8290, max=-0.8290 | UB min=7.4584, max=7.4584
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027542829513549805
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0240631103515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002828359603881836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0029425621032714844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0035130977630615234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004119157791137695

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.5747, max=5.6157 | UB min=-0.1687, max=8.8607
  Layer 2: LB min=-6.3971, max=7.0186 | UB min=-1.5537, max=12.0224
  Layer 3: LB min=-13.4021, max=22.3546 | UB min=-6.1832, max=36.1753
  Layer 4: LB min=-9.5669, max=27.6744 | UB min=4.7845, max=36.7692
  Layer 5: LB min=-9.8017, max=26.2130 | UB min=6.8610, max=38.4728
  Layer 6: LB min=0.5353, max=22.3546 | UB min=20.6147, max=36.1753
  Layer 7: LB min=-6.2506, max=-6.2506 | UB min=8.8002, max=8.8002
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029436349868774414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.035154104232788086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0028955936431884766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.012880325317382812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0037703514099121094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017518997192382812

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.2778, max=5.8583 | UB min=-0.4144, max=8.5885
  Layer 2: LB min=-6.0184, max=7.4475 | UB min=-1.9972, max=11.5969
  Layer 3: LB min=-12.6127, max=19.3027 | UB min=-6.8495, max=30.7422
  Layer 4: LB min=-7.8989, max=24.0856 | UB min=3.6799, max=31.5287
  Layer 5: LB min=-7.8104, max=21.8975 | UB min=5.2313, max=31.3266
  Layer 6: LB min=1.4531, max=19.3027 | UB min=17.2370, max=30.7422
  Layer 7: LB min=-3.4527, max=-3.4527 | UB min=8.1260, max=8.1260
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.043435096740722656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028564453125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011487007141113281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001214742660522461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011959075927734375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012116432189941406

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.4262, max=5.7370 | UB min=-0.2915, max=8.7246
  Layer 2: LB min=-6.2077, max=7.2331 | UB min=-1.7754, max=11.8096
  Layer 3: LB min=-13.0068, max=20.9048 | UB min=-6.5373, max=33.5235
  Layer 4: LB min=-8.7321, max=25.9541 | UB min=4.2315, max=34.1937
  Layer 5: LB min=-8.7920, max=24.1341 | UB min=6.0201, max=34.9669
  Layer 6: LB min=0.9988, max=20.9048 | UB min=18.8998, max=33.5235
  Layer 7: LB min=-4.8193, max=-4.8193 | UB min=8.4630, max=8.4630
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03162646293640137
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02269577980041504
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012347698211669922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011072158813476562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0044591426849365234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001965761184692383

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.5005, max=5.6763 | UB min=-0.2301, max=8.7926
  Layer 2: LB min=-6.3024, max=7.1259 | UB min=-1.6646, max=11.9160
  Layer 3: LB min=-13.2044, max=21.6298 | UB min=-6.3605, max=34.8495
  Layer 4: LB min=-9.1500, max=26.8143 | UB min=4.5079, max=35.4584
  Layer 5: LB min=-9.2873, max=25.1820 | UB min=6.4204, max=36.7279
  Layer 6: LB min=0.7669, max=21.6298 | UB min=19.7369, max=34.8495
  Layer 7: LB min=-5.5137, max=-5.5137 | UB min=8.6315, max=8.6315
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02572345733642578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02349853515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011904239654541016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001483917236328125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003073453903198242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015716552734375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.5376, max=5.6460 | UB min=-0.1994, max=8.8266
  Layer 2: LB min=-6.3498, max=7.0723 | UB min=-1.6091, max=11.9692
  Layer 3: LB min=-13.3032, max=21.9922 | UB min=-6.2719, max=35.5124
  Layer 4: LB min=-9.3585, max=27.2444 | UB min=4.6462, max=36.1136
  Layer 5: LB min=-9.5450, max=25.6975 | UB min=6.6406, max=37.6003
  Layer 6: LB min=0.6511, max=21.9922 | UB min=20.1759, max=35.5124
  Layer 7: LB min=-5.8823, max=-5.8823 | UB min=8.7158, max=8.7158
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04838132858276367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0215456485748291
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011959075927734375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004089832305908203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012748241424560547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001447439193725586

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.5561, max=5.6309 | UB min=-0.1840, max=8.8437
  Layer 2: LB min=-6.3734, max=7.0455 | UB min=-1.5814, max=11.9958
  Layer 3: LB min=-13.3526, max=22.1734 | UB min=-6.2276, max=35.8439
  Layer 4: LB min=-9.4627, max=27.4594 | UB min=4.7153, max=36.4414
  Layer 5: LB min=-9.6735, max=25.9553 | UB min=6.7508, max=38.0366
  Layer 6: LB min=0.5932, max=22.1734 | UB min=20.3953, max=35.8439
  Layer 7: LB min=-6.0665, max=-6.0665 | UB min=8.7580, max=8.7580
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04152679443359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026514053344726562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001634359359741211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012557506561279297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011649131774902344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.008241891860961914

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.5654, max=5.6233 | UB min=-0.1764, max=8.8522
  Layer 2: LB min=-6.3852, max=7.0321 | UB min=-1.5675, max=12.0091
  Layer 3: LB min=-13.3774, max=22.2640 | UB min=-6.2054, max=36.0096
  Layer 4: LB min=-9.5148, max=27.5669 | UB min=4.7499, max=36.6053
  Layer 5: LB min=-9.7376, max=26.0841 | UB min=6.8059, max=38.2547
  Layer 6: LB min=0.5643, max=22.2640 | UB min=20.5050, max=36.0096
  Layer 7: LB min=-6.1586, max=-6.1586 | UB min=8.7791, max=8.7791
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03761768341064453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02700352668762207
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012722015380859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014789104461669922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004271507263183594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001379251480102539

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.5700, max=5.6195 | UB min=-0.1725, max=8.8564
  Layer 2: LB min=-6.3912, max=7.0254 | UB min=-1.5606, max=12.0158
  Layer 3: LB min=-13.3897, max=22.3093 | UB min=-6.1943, max=36.0924
  Layer 4: LB min=-9.5408, max=27.6207 | UB min=4.7672, max=36.6873
  Layer 5: LB min=-9.7697, max=26.1485 | UB min=6.8334, max=38.3638
  Layer 6: LB min=0.5498, max=22.3093 | UB min=20.5598, max=36.0924
  Layer 7: LB min=-6.2046, max=-6.2046 | UB min=8.7897, max=8.7897
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04255199432373047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017418384552001953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010983943939208984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013248920440673828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003322601318359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014443397521972656

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.5654, max=5.6233 | UB min=-0.1764, max=8.8522
  Layer 2: LB min=-6.3852, max=7.0321 | UB min=-1.5675, max=12.0091
  Layer 3: LB min=-13.3774, max=22.2640 | UB min=-6.2054, max=36.0096
  Layer 4: LB min=-9.5148, max=27.5669 | UB min=4.7499, max=36.6053
  Layer 5: LB min=-9.7376, max=26.0841 | UB min=6.8059, max=38.2547
  Layer 6: LB min=0.5643, max=22.2640 | UB min=20.5050, max=36.0096
  Layer 7: LB min=-6.1586, max=-6.1586 | UB min=8.7791, max=8.7791
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03420686721801758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02613353729248047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014560222625732422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011072158813476562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00237274169921875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001583099365234375
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.007306337356567383
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0031881332397460938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002355813980102539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001573324203491211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011608600616455078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001318216323852539
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03136634826660156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01715540885925293
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0031991004943847656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003885507583618164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012371540069580078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017421245574951172
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.012427330017089844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.008089303970336914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011737346649169922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010974407196044922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001104593276977539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012004375457763672
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05387067794799805
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030735492706298828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0024576187133789062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004743814468383789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013501644134521484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.013708829879760742
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.043253183364868164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029183626174926758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015709400177001953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.007719993591308594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012590885162353516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014219284057617188
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04045820236206055
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03337430953979492
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009398460388183594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008821487426757812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008912086486816406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001085519790649414
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.026782512664794922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028176307678222656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014925003051757812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003366708755493164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0020890235900878906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001661539077758789
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03496098518371582
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023517370223999023
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00106048583984375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012738704681396484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010728836059570312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00452876091003418
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02953338623046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.012747526168823242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015087127685546875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004901885986328125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014712810516357422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001943349838256836
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.033994436264038086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.013833284378051758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009996891021728516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002668142318725586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0054492950439453125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0063321590423583984
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.021677017211914062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02760910987854004
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011904239654541016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012094974517822266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004178762435913086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013644695281982422
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03235149383544922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.024756431579589844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012362003326416016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0030596256256103516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0043599605560302734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013172626495361328
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028290987014770508
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03842425346374512
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0029754638671875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00488591194152832
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004168033599853516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014798641204833984
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.033196449279785156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029671192169189453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0017893314361572266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012042522430419922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014042854309082031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014297962188720703
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03007984161376953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020160198211669922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.008236885070800781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014433860778808594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002330303192138672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0037174224853515625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-38.2528, max=0.0000 | UB min=0.0000, max=44.3853
  Layer 2: LB min=0.0000, max=0.0000 | UB min=61.5918, max=92.1276
  Layer 3: LB min=-186.8806, max=226.6009 | UB min=106.5619, max=698.0765
  Layer 4: LB min=-267.5422, max=291.3498 | UB min=207.8294, max=679.2784
  Layer 5: LB min=-325.6925, max=370.0150 | UB min=273.8602, max=860.0093
  Layer 6: LB min=-138.7601, max=197.8246 | UB min=582.9850, max=679.2784
  Layer 7: LB min=-524.0948, max=-524.0948 | UB min=151.8792, max=151.8792
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.009562492370605469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.00921773910522461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0031511783599853516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003531217575073242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0028829574584960938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015628337860107422

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-19.6006, max=0.0000 | UB min=0.0000, max=24.2218
  Layer 2: LB min=0.0000, max=0.0000 | UB min=31.6944, max=48.5783
  Layer 3: LB min=-98.3327, max=129.9475 | UB min=53.3753, max=374.1370
  Layer 4: LB min=-138.7225, max=160.7973 | UB min=106.7887, max=365.3714
  Layer 5: LB min=-168.2804, max=204.7945 | UB min=141.2402, max=457.3926
  Layer 6: LB min=-71.8454, max=113.3504 | UB min=301.4164, max=365.3714
  Layer 7: LB min=-269.6901, max=-269.6901 | UB min=78.7443, max=78.7443
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009515285491943359
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0007307529449462891
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012276172637939453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007357597351074219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008523464202880859
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011284351348876953

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-10.1725, max=0.0000 | UB min=0.0000, max=14.6882
  Layer 2: LB min=0.0000, max=0.0000 | UB min=15.9739, max=26.6052
  Layer 3: LB min=-52.0013, max=82.6259 | UB min=24.9387, max=207.1259
  Layer 4: LB min=-70.2949, max=95.8252 | UB min=53.8673, max=202.6215
  Layer 5: LB min=-84.8763, max=122.1686 | UB min=70.7771, max=248.5803
  Layer 6: LB min=-36.3027, max=71.5739 | UB min=154.2939, max=202.6215
  Layer 7: LB min=-134.2800, max=-134.2800 | UB min=44.4692, max=44.4692
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0456538200378418
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029558658599853516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0025641918182373047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009801387786865234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009970664978027344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010597705841064453

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.3873, max=2.4987 | UB min=0.0000, max=10.5054
  Layer 2: LB min=0.0000, max=0.0100 | UB min=8.3561, max=15.8141
  Layer 3: LB min=-27.1693, max=59.8681 | UB min=7.2222, max=116.3836
  Layer 4: LB min=-32.0777, max=63.7511 | UB min=23.9210, max=111.8130
  Layer 5: LB min=-37.6743, max=79.2210 | UB min=30.9997, max=134.5479
  Layer 6: LB min=-14.7877, max=49.5242 | UB min=73.2288, max=111.8130
  Layer 7: LB min=-56.1928, max=-56.1928 | UB min=24.1133, max=24.1133
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03002786636352539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.016404390335083008
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0017445087432861328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014142990112304688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003346681594848633
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010929107666015625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.4621, max=4.2883 | UB min=0.0000, max=8.3921
  Layer 2: LB min=0.0000, max=3.7580 | UB min=4.6189, max=11.5122
  Layer 3: LB min=-16.2496, max=39.4793 | UB min=-1.0089, max=64.1039
  Layer 4: LB min=-13.4057, max=42.9760 | UB min=9.6516, max=62.2830
  Layer 5: LB min=-14.8021, max=51.3567 | UB min=12.4777, max=73.8222
  Layer 6: LB min=2.1229, max=33.8834 | UB min=35.1476, max=62.2830
  Layer 7: LB min=-15.8298, max=-15.8298 | UB min=12.9306, max=12.9306
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.008379220962524414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0076487064361572266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008397102355957031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007891654968261719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.000985860824584961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009398460388183594

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.8223, max=5.1889 | UB min=-0.2996, max=7.3319
  Layer 2: LB min=0.0000, max=5.8524 | UB min=2.4908, max=9.5882
  Layer 3: LB min=-11.4938, max=24.6358 | UB min=-4.7106, max=36.3492
  Layer 4: LB min=-6.2969, max=28.4401 | UB min=2.1906, max=36.8468
  Layer 5: LB min=-5.4929, max=34.0240 | UB min=5.1859, max=43.4535
  Layer 6: LB min=6.4377, max=21.2358 | UB min=19.7420, max=34.7877
  Layer 7: LB min=-2.4922, max=-2.4922 | UB min=9.6714, max=9.6714
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009675025939941406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006682872772216797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0007250308990478516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011813640594482422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008904933929443359
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011963844299316406

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.1426, max=4.7386 | UB min=0.0000, max=7.8626
  Layer 2: LB min=0.0000, max=4.8231 | UB min=3.5454, max=10.5089
  Layer 3: LB min=-13.7704, max=32.7598 | UB min=-2.8984, max=50.8483
  Layer 4: LB min=-9.7562, max=36.8121 | UB min=5.5702, max=49.9535
  Layer 5: LB min=-9.7910, max=43.2863 | UB min=8.5832, max=58.9483
  Layer 6: LB min=4.3377, max=28.8285 | UB min=26.8941, max=49.6195
  Layer 7: LB min=-8.6790, max=-8.6790 | UB min=11.2527, max=11.2527
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03268003463745117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019956111907958984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008549690246582031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008745193481445312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008804798126220703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009996891021728516

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.9828, max=4.9638 | UB min=0.0000, max=7.5975
  Layer 2: LB min=0.0000, max=5.3516 | UB min=2.9673, max=10.0115
  Layer 3: LB min=-12.5597, max=28.9768 | UB min=-3.8337, max=43.8067
  Layer 4: LB min=-7.9659, max=32.9219 | UB min=3.5545, max=43.4987
  Layer 5: LB min=-7.3484, max=38.9020 | UB min=6.7546, max=51.2480
  Layer 6: LB min=5.4156, max=25.3750 | UB min=22.9181, max=42.4147
  Layer 7: LB min=-5.3140, max=-5.3140 | UB min=10.4046, max=10.4046
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0038344860076904297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015723705291748047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0028586387634277344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0046002864837646484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004068613052368164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0049245357513427734

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.9027, max=5.0763 | UB min=-0.0884, max=7.4648
  Layer 2: LB min=0.0000, max=5.6101 | UB min=2.7090, max=9.7856
  Layer 3: LB min=-11.9864, max=26.8274 | UB min=-4.2841, max=40.0405
  Layer 4: LB min=-7.0974, max=30.6488 | UB min=2.6878, max=40.1085
  Layer 5: LB min=-6.2848, max=36.4972 | UB min=5.9401, max=47.2491
  Layer 6: LB min=5.9434, max=23.2830 | UB min=21.1614, max=38.5171
  Layer 7: LB min=-3.8067, max=-3.8067 | UB min=10.0171, max=10.0171
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.019997835159301758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.012420177459716797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.007584333419799805
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.005020856857299805
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.009875059127807617
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0023419857025146484

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.8625, max=5.1326 | UB min=-0.1940, max=7.3983
  Layer 2: LB min=0.0000, max=5.7312 | UB min=2.5999, max=9.6869
  Layer 3: LB min=-11.7400, max=25.7317 | UB min=-4.4973, max=38.1964
  Layer 4: LB min=-6.6973, max=29.5444 | UB min=2.3853, max=38.4775
  Layer 5: LB min=-5.8445, max=35.2809 | UB min=5.5495, max=45.3169
  Layer 6: LB min=6.1905, max=22.2593 | UB min=20.4112, max=36.6521
  Layer 7: LB min=-3.1188, max=-3.1188 | UB min=9.8361, max=9.8361
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.033379554748535156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.032387733459472656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.005144834518432617
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011968612670898438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018284320831298828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012929439544677734

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.8826, max=5.1045 | UB min=-0.1412, max=7.4315
  Layer 2: LB min=0.0000, max=5.6707 | UB min=2.6545, max=9.7363
  Layer 3: LB min=-11.8632, max=26.2796 | UB min=-4.3907, max=39.1188
  Layer 4: LB min=-6.8974, max=30.0966 | UB min=2.5312, max=39.2929
  Layer 5: LB min=-6.0604, max=35.8902 | UB min=5.7514, max=46.2795
  Layer 6: LB min=6.0670, max=22.7712 | UB min=20.7846, max=37.5846
  Layer 7: LB min=-3.4619, max=-3.4619 | UB min=9.9265, max=9.9265
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027989625930786133
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02099013328552246
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013990402221679688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011782646179199219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013802051544189453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001215219497680664

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.8725, max=5.1186 | UB min=-0.1676, max=7.4149
  Layer 2: LB min=0.0000, max=5.7010 | UB min=2.6272, max=9.7116
  Layer 3: LB min=-11.8016, max=26.0057 | UB min=-4.4440, max=38.6577
  Layer 4: LB min=-6.7974, max=29.8205 | UB min=2.4537, max=38.8852
  Layer 5: LB min=-5.9487, max=35.5872 | UB min=5.6489, max=45.7953
  Layer 6: LB min=6.1287, max=22.5153 | UB min=20.5943, max=37.1183
  Layer 7: LB min=-3.2877, max=-3.2877 | UB min=9.8806, max=9.8806
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03453350067138672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026137828826904297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012555122375488281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011835098266601562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002294301986694336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004545688629150391

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.8675, max=5.1256 | UB min=-0.1808, max=7.4066
  Layer 2: LB min=0.0000, max=5.7161 | UB min=2.6135, max=9.6993
  Layer 3: LB min=-11.7708, max=25.8687 | UB min=-4.4707, max=38.4271
  Layer 4: LB min=-6.7474, max=29.6825 | UB min=2.4153, max=38.6814
  Layer 5: LB min=-5.8931, max=35.4358 | UB min=5.5965, max=45.5535
  Layer 6: LB min=6.1596, max=22.3873 | UB min=20.4991, max=36.8852
  Layer 7: LB min=-3.2004, max=-3.2004 | UB min=9.8576, max=9.8576
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03397679328918457
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027423620223999023
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011816024780273438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001161813735961914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005786418914794922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.006716728210449219

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.8650, max=5.1291 | UB min=-0.1874, max=7.4025
  Layer 2: LB min=0.0000, max=5.7237 | UB min=2.6067, max=9.6931
  Layer 3: LB min=-11.7554, max=25.8002 | UB min=-4.4840, max=38.3117
  Layer 4: LB min=-6.7223, max=29.6135 | UB min=2.3975, max=38.5794
  Layer 5: LB min=-5.8664, max=35.3596 | UB min=5.5712, max=45.4334
  Layer 6: LB min=6.1751, max=22.3233 | UB min=20.4527, max=36.7687
  Layer 7: LB min=-3.1577, max=-3.1577 | UB min=9.8463, max=9.8463
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03419661521911621
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03351402282714844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011057853698730469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004263877868652344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015518665313720703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0049016475677490234

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.8625, max=5.1326 | UB min=-0.1940, max=7.3983
  Layer 2: LB min=0.0000, max=5.7312 | UB min=2.5999, max=9.6869
  Layer 3: LB min=-11.7400, max=25.7317 | UB min=-4.4973, max=38.1964
  Layer 4: LB min=-6.6973, max=29.5444 | UB min=2.3853, max=38.4775
  Layer 5: LB min=-5.8445, max=35.2809 | UB min=5.5495, max=45.3169
  Layer 6: LB min=6.1905, max=22.2593 | UB min=20.4112, max=36.6521
  Layer 7: LB min=-3.1188, max=-3.1188 | UB min=9.8361, max=9.8361
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03508472442626953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02014613151550293
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0038900375366210938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004797220230102539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001882791519165039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002913951873779297
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.009536266326904297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.013468265533447266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012271404266357422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010094642639160156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003698110580444336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016145706176757812
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02387833595275879
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022145748138427734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0019254684448242188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0022280216217041016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0023691654205322266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013129711151123047
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027433395385742188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.031685829162597656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015823841094970703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00418400764465332
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011663436889648438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012562274932861328
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04243874549865723
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.036916494369506836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013477802276611328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011479854583740234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010652542114257812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.006173133850097656
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03597211837768555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.025875568389892578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015003681182861328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011758804321289062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003454446792602539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012636184692382812
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02738189697265625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023987293243408203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008823871612548828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007507801055908203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003518342971801758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001453399658203125
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04907941818237305
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03777289390563965
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003080606460571289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002802133560180664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018439292907714844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002166271209716797
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.031889915466308594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03108811378479004
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012505054473876953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0030999183654785156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012125968933105469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012285709381103516
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029861927032470703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030758380889892578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00435185432434082
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012488365173339844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012118816375732422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012483596801757812
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.038742780685424805
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03450822830200195
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004378080368041992
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012125968933105469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004242897033691406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015571117401123047
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.033272743225097656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015390634536743164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012085437774658203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010297298431396484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013279914855957031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011796951293945312
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03646230697631836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03292131423950195
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0029435157775878906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012569427490234375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0035719871520996094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015463829040527344
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.023044824600219727
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03360581398010254
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014178752899169922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003297567367553711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005252361297607422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017452239990234375
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.015886545181274414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03183889389038086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011022090911865234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002882242202758789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003015756607055664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014073848724365234
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.035070180892944336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01746082305908203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011560916900634766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010819435119628906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011370182037353516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012440681457519531

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-27.1018, max=0.0000 | UB min=0.0000, max=53.1439
  Layer 2: LB min=-59.8695, max=0.0000 | UB min=0.0000, max=94.1571
  Layer 3: LB min=-188.3474, max=226.5066 | UB min=109.3038, max=704.2079
  Layer 4: LB min=-269.9059, max=293.6142 | UB min=210.4079, max=684.2476
  Layer 5: LB min=-329.5589, max=371.0576 | UB min=277.7060, max=868.0325
  Layer 6: LB min=-140.6199, max=196.5759 | UB min=591.0344, max=684.2476
  Layer 7: LB min=-531.4607, max=-531.4607 | UB min=152.1028, max=152.1028
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.017377138137817383
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01746225357055664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008685588836669922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007269382476806641
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009644031524658203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009529590606689453

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-14.1565, max=0.0000 | UB min=0.0000, max=27.6521
  Layer 2: LB min=-31.2926, max=0.0000 | UB min=0.0000, max=50.9664
  Layer 3: LB min=-98.4984, max=128.1534 | UB min=56.1881, max=375.5697
  Layer 4: LB min=-139.7264, max=161.7254 | UB min=108.6031, max=364.9220
  Layer 5: LB min=-171.0219, max=202.8391 | UB min=143.9009, max=460.4019
  Layer 6: LB min=-72.8182, max=110.1037 | UB min=307.0939, max=364.9220
  Layer 7: LB min=-274.6605, max=-274.6605 | UB min=77.7441, max=77.7441
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0010068416595458984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0006022453308105469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0005435943603515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0005960464477539062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007526874542236328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007812976837158203

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-7.4186, max=0.0000 | UB min=0.0000, max=15.6052
  Layer 2: LB min=-16.3505, max=0.0000 | UB min=0.0000, max=28.4917
  Layer 3: LB min=-52.1811, max=78.7194 | UB min=28.5371, max=205.9745
  Layer 4: LB min=-71.0284, max=94.3879 | UB min=55.0742, max=198.6330
  Layer 5: LB min=-87.9959, max=116.7314 | UB min=73.7555, max=247.9103
  Layer 6: LB min=-36.8309, max=66.5042 | UB min=158.5772, max=198.6330
  Layer 7: LB min=-139.4216, max=-139.4216 | UB min=38.9630, max=38.9630
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02639627456665039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02986288070678711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0019068717956542969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011258125305175781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018169879913330078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0021944046020507812

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-4.0133, max=1.3064 | UB min=0.0000, max=10.3088
  Layer 2: LB min=-8.3805, max=0.4688 | UB min=0.0000, max=17.2023
  Layer 3: LB min=-26.8500, max=54.8698 | UB min=12.9508, max=115.0795
  Layer 4: LB min=-32.4967, max=61.5973 | UB min=25.0274, max=108.5998
  Layer 5: LB min=-41.3394, max=72.7675 | UB min=34.1830, max=131.8016
  Layer 6: LB min=-16.3817, max=46.0570 | UB min=76.3736, max=108.5998
  Layer 7: LB min=-62.3055, max=-62.3055 | UB min=18.9265, max=18.9265
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.001855611801147461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0007140636444091797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0006051063537597656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0006244182586669922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0007579326629638672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0007803440093994141

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.2892, max=3.2214 | UB min=0.0000, max=7.6398
  Layer 2: LB min=-4.3451, max=3.9099 | UB min=0.0000, max=12.2063
  Layer 3: LB min=-14.6459, max=34.3674 | UB min=4.6479, max=62.5726
  Layer 4: LB min=-13.1308, max=40.8652 | UB min=9.3466, max=60.3160
  Layer 5: LB min=-18.6218, max=42.8014 | UB min=15.9258, max=68.5407
  Layer 6: LB min=-5.4121, max=31.7312 | UB min=36.1728, max=59.5617
  Layer 7: LB min=-24.2469, max=-24.2469 | UB min=10.8316, max=10.8316
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03540825843811035
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030626296997070312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0023353099822998047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0029985904693603516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003488779067993164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.006016254425048828

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.4211, max=4.1828 | UB min=0.0000, max=6.4743
  Layer 2: LB min=-2.4613, max=5.7848 | UB min=0.0000, max=9.8075
  Layer 3: LB min=-10.3611, max=21.5786 | UB min=0.0882, max=34.5289
  Layer 4: LB min=-8.4785, max=28.2182 | UB min=1.6166, max=36.6972
  Layer 5: LB min=-7.0141, max=26.1293 | UB min=5.7807, max=36.7873
  Layer 6: LB min=1.5008, max=21.5786 | UB min=16.8763, max=34.5038
  Layer 7: LB min=-6.5496, max=-6.5496 | UB min=6.2008, max=6.2008
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0010428428649902344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0019483566284179688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0036852359771728516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00803232192993164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.009424209594726562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.006196498870849609

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-0.9871, max=4.6688 | UB min=0.0000, max=5.8959
  Layer 2: LB min=-1.4922, max=6.7285 | UB min=0.0000, max=8.7931
  Layer 3: LB min=-8.2349, max=13.3823 | UB min=-3.3105, max=19.7422
  Layer 4: LB min=-6.3693, max=19.4478 | UB min=-1.8959, max=23.4020
  Layer 5: LB min=-2.2332, max=16.1750 | UB min=2.5937, max=20.5273
  Layer 6: LB min=4.3336, max=13.3823 | UB min=10.0131, max=19.7422
  Layer 7: LB min=-1.1484, max=-1.1484 | UB min=3.6925, max=3.6925
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029677629470825195
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.024530887603759766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0034933090209960938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011677742004394531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00588536262512207
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014617443084716797

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-0.7700, max=4.9121 | UB min=-0.1337, max=5.6055
  Layer 2: LB min=-1.0390, max=7.1681 | UB min=0.0000, max=8.2996
  Layer 3: LB min=-7.2125, max=7.6892 | UB min=-4.6670, max=11.0582
  Layer 4: LB min=-5.4184, max=14.2129 | UB min=-3.1060, max=16.2521
  Layer 5: LB min=-0.6316, max=12.0373 | UB min=1.4794, max=14.0232
  Layer 6: LB min=5.1253, max=7.6892 | UB min=7.7985, max=11.0582
  Layer 7: LB min=0.5420, max=0.5420 | UB min=2.7588, max=2.7588
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.012194395065307617
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.00927424430847168
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010755062103271484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012524127960205078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0021224021911621094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015645027160644531

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-0.8785, max=4.7904 | UB min=0.0000, max=5.7509
  Layer 2: LB min=-1.2503, max=6.9635 | UB min=0.0000, max=8.5465
  Layer 3: LB min=-7.7240, max=10.4504 | UB min=-4.0600, max=15.2733
  Layer 4: LB min=-5.8938, max=16.8198 | UB min=-2.5967, max=19.7431
  Layer 5: LB min=-1.2096, max=13.7787 | UB min=2.0342, max=16.8156
  Layer 6: LB min=4.7575, max=10.4504 | UB min=8.7350, max=15.2733
  Layer 7: LB min=-0.1815, max=-0.1815 | UB min=3.1554, max=3.1554
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.023672819137573242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027231216430664062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012111663818359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012123584747314453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012445449829101562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011947154998779297

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-0.9328, max=4.7296 | UB min=0.0000, max=5.8236
  Layer 2: LB min=-1.3712, max=6.8460 | UB min=0.0000, max=8.6699
  Layer 3: LB min=-7.9797, max=11.9178 | UB min=-3.6952, max=17.5051
  Layer 4: LB min=-6.1316, max=18.1357 | UB min=-2.2570, max=21.5713
  Layer 5: LB min=-1.7040, max=14.7871 | UB min=2.3135, max=18.4628
  Layer 6: LB min=4.5474, max=11.9178 | UB min=9.3570, max=17.5051
  Layer 7: LB min=-0.6483, max=-0.6483 | UB min=3.4237, max=3.4237
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.006850481033325195
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0010671615600585938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.000873565673828125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007770061492919922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008356571197509766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010979175567626953

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-0.9057, max=4.7600 | UB min=0.0000, max=5.7873
  Layer 2: LB min=-1.3108, max=6.9048 | UB min=0.0000, max=8.6082
  Layer 3: LB min=-7.8519, max=11.1840 | UB min=-3.8778, max=16.3892
  Layer 4: LB min=-6.0127, max=17.4779 | UB min=-2.4274, max=20.6572
  Layer 5: LB min=-1.4545, max=14.2272 | UB min=2.1738, max=17.5807
  Layer 6: LB min=4.6525, max=11.1840 | UB min=9.0431, max=16.3892
  Layer 7: LB min=-0.4129, max=-0.4129 | UB min=3.2894, max=3.2894
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.015526533126831055
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026933908462524414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015611648559570312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0019414424896240234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012793540954589844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0022182464599609375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-0.9192, max=4.7448 | UB min=0.0000, max=5.8055
  Layer 2: LB min=-1.3410, max=6.8754 | UB min=0.0000, max=8.6391
  Layer 3: LB min=-7.9158, max=11.5509 | UB min=-3.7865, max=16.9471
  Layer 4: LB min=-6.0721, max=17.8069 | UB min=-2.3424, max=21.1142
  Layer 5: LB min=-1.5784, max=14.4514 | UB min=2.2436, max=17.9651
  Layer 6: LB min=4.6000, max=11.5509 | UB min=9.1992, max=16.9471
  Layer 7: LB min=-0.5299, max=-0.5299 | UB min=3.3565, max=3.3565
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.015441656112670898
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01954936981201172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0024886131286621094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013234615325927734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00232696533203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002589702606201172

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-0.9260, max=4.7372 | UB min=0.0000, max=5.8145
  Layer 2: LB min=-1.3561, max=6.8607 | UB min=0.0000, max=8.6545
  Layer 3: LB min=-7.9478, max=11.7343 | UB min=-3.7409, max=17.2261
  Layer 4: LB min=-6.1019, max=17.9713 | UB min=-2.2997, max=21.3427
  Layer 5: LB min=-1.6410, max=14.6132 | UB min=2.2786, max=18.2077
  Layer 6: LB min=4.5737, max=11.7343 | UB min=9.2779, max=17.2261
  Layer 7: LB min=-0.5889, max=-0.5889 | UB min=3.3901, max=3.3901
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03002762794494629
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.012555360794067383
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011055469512939453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012159347534179688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011794567108154297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011408329010009766

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-0.9294, max=4.7334 | UB min=0.0000, max=5.8191
  Layer 2: LB min=-1.3637, max=6.8534 | UB min=0.0000, max=8.6622
  Layer 3: LB min=-7.9638, max=11.8261 | UB min=-3.7180, max=17.3656
  Layer 4: LB min=-6.1167, max=18.0535 | UB min=-2.2783, max=21.4570
  Layer 5: LB min=-1.6725, max=14.7001 | UB min=2.2960, max=18.3352
  Layer 6: LB min=4.5606, max=11.8261 | UB min=9.3174, max=17.3656
  Layer 7: LB min=-0.6185, max=-0.6185 | UB min=3.4069, max=3.4069
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03526473045349121
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022301912307739258
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011141300201416016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001100301742553711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0072405338287353516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015132427215576172

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-0.9294, max=4.7334 | UB min=0.0000, max=5.8191
  Layer 2: LB min=-1.3637, max=6.8534 | UB min=0.0000, max=8.6622
  Layer 3: LB min=-7.9638, max=11.8261 | UB min=-3.7180, max=17.3656
  Layer 4: LB min=-6.1167, max=18.0535 | UB min=-2.2783, max=21.4570
  Layer 5: LB min=-1.6725, max=14.7001 | UB min=2.2960, max=18.3352
  Layer 6: LB min=4.5606, max=11.8261 | UB min=9.3174, max=17.3656
  Layer 7: LB min=-0.6185, max=-0.6185 | UB min=3.4069, max=3.4069
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01925492286682129
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.014851093292236328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011909008026123047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001138925552368164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013265609741210938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014302730560302734
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.006082296371459961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0025315284729003906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002056598663330078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010762214660644531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011606216430664062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001161336898803711
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02646803855895996
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.024776220321655273
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011913776397705078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011925697326660156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002118349075317383
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00170135498046875
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029306650161743164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030937910079956055
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013086795806884766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001123666763305664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001215219497680664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013065338134765625
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.026620864868164062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019481658935546875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00107574462890625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010755062103271484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0033223628997802734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002408266067504883
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.015641212463378906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.016361474990844727
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0018694400787353516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003926515579223633
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014810562133789062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0031270980834960938
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.021713972091674805
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027435302734375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013189315795898438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.000986337661743164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011513233184814453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012874603271484375
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.010048627853393555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0008227825164794922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0007238388061523438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008556842803955078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009357929229736328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014388561248779297
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.025562286376953125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.008178949356079102
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009434223175048828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008528232574462891
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013031959533691406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011692047119140625
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0015368461608886719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0007812976837158203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008141994476318359
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007524490356445312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009477138519287109
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009949207305908203
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02241969108581543
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.014186382293701172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012562274932861328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009937286376953125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011324882507324219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012781620025634766
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.026955842971801758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.025968313217163086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00209808349609375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001275777816772461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018186569213867188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014009475708007812
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.00807046890258789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.007796764373779297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010151863098144531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0024421215057373047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004083156585693359
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004097461700439453
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05324912071228027
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030414342880249023
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012650489807128906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012984275817871094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012216567993164062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001279592514038086
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.060431480407714844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.033583879470825195
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014379024505615234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012407302856445312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012664794921875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012259483337402344
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05073404312133789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030994176864624023
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011413097381591797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.005441427230834961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0021467208862304688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00138092041015625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-38.0983, max=0.0000 | UB min=0.0000, max=52.9117
  Layer 2: LB min=-59.6748, max=0.0000 | UB min=0.0000, max=92.2435
  Layer 3: LB min=-186.2810, max=227.4786 | UB min=106.2327, max=697.4130
  Layer 4: LB min=-267.9215, max=293.6506 | UB min=207.0329, max=676.6032
  Layer 5: LB min=-325.9630, max=371.0374 | UB min=272.5373, max=859.1422
  Layer 6: LB min=-139.0855, max=198.9515 | UB min=581.9624, max=676.6032
  Layer 7: LB min=-521.8190, max=-521.8190 | UB min=151.0652, max=151.0652
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.012089729309082031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.013225555419921875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0017211437225341797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014803409576416016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014951229095458984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018742084503173828

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-19.3465, max=0.0000 | UB min=0.0000, max=27.4344
  Layer 2: LB min=-32.0870, max=0.0000 | UB min=0.0000, max=48.9136
  Layer 3: LB min=-97.7954, max=132.1280 | UB min=52.6496, max=373.8161
  Layer 4: LB min=-139.6527, max=165.0974 | UB min=105.2529, max=358.6536
  Layer 5: LB min=-168.8077, max=206.9507 | UB min=139.1947, max=453.9920
  Layer 6: LB min=-72.3013, max=116.4097 | UB min=299.1173, max=358.6536
  Layer 7: LB min=-263.1086, max=-263.1086 | UB min=78.2828, max=78.2828
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0012617111206054688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009341239929199219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010638236999511719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012493133544921875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013971328735351562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001485586166381836

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-9.8753, max=0.0000 | UB min=0.0000, max=16.6907
  Layer 2: LB min=-17.8505, max=0.0000 | UB min=0.0000, max=27.5421
  Layer 3: LB min=-51.4087, max=85.6266 | UB min=22.4200, max=206.8531
  Layer 4: LB min=-70.9525, max=100.8249 | UB min=50.0966, max=199.2300
  Layer 5: LB min=-84.7447, max=124.3523 | UB min=67.0788, max=245.6622
  Layer 6: LB min=-36.7034, max=76.5197 | UB min=148.2298, max=199.2300
  Layer 7: LB min=-128.4474, max=-128.4474 | UB min=43.6629, max=43.6629
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0012171268463134766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0011625289916992188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010061264038085938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011708736419677734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001397848129272461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015213489532470703

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.0981, max=3.4879 | UB min=0.0000, max=12.2473
  Layer 2: LB min=-10.8305, max=3.6148 | UB min=0.0000, max=18.7669
  Layer 3: LB min=-28.4946, max=53.4529 | UB min=4.7347, max=109.5700
  Layer 4: LB min=-34.1617, max=61.7417 | UB min=20.4657, max=106.0397
  Layer 5: LB min=-39.6058, max=72.0508 | UB min=30.1377, max=127.4858
  Layer 6: LB min=-15.2412, max=50.0823 | UB min=68.8695, max=106.0397
  Layer 7: LB min=-53.3221, max=-53.3221 | UB min=25.0180, max=25.0180
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0010581016540527344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0008957386016845703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010762214660644531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001219034194946289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014309883117675781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016665458679199219

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.6938, max=5.5286 | UB min=0.0000, max=10.0067
  Layer 2: LB min=-7.1740, max=7.8499 | UB min=-0.0612, max=14.9617
  Layer 3: LB min=-17.0475, max=33.5961 | UB min=-3.5391, max=57.8445
  Layer 4: LB min=-16.8714, max=38.6793 | UB min=6.9718, max=57.8445
  Layer 5: LB min=-16.6385, max=40.7671 | UB min=12.0658, max=64.2057
  Layer 6: LB min=-3.4504, max=33.5961 | UB min=30.2908, max=57.8445
  Layer 7: LB min=-15.9432, max=-15.9432 | UB min=15.5667, max=15.5667
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03710365295410156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02948141098022461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011200904846191406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.006953239440917969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013206005096435547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012962818145751953

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.4917, max=6.5522 | UB min=0.0000, max=8.8862
  Layer 2: LB min=-5.4962, max=9.6257 | UB min=-1.9770, max=13.1979
  Layer 3: LB min=-13.1497, max=19.7978 | UB min=-6.6865, max=31.7008
  Layer 4: LB min=-10.4291, max=23.7284 | UB min=2.0337, max=32.1523
  Layer 5: LB min=-6.8589, max=22.2579 | UB min=4.3393, max=32.0649
  Layer 6: LB min=0.9747, max=19.7978 | UB min=14.5739, max=31.7008
  Layer 7: LB min=-1.0337, max=-1.0337 | UB min=10.7710, max=10.7710
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.039457082748413086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028390884399414062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002012014389038086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012638568878173828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012676715850830078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001203298568725586

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.0928, max=6.0399 | UB min=0.0000, max=9.4464
  Layer 2: LB min=-6.3024, max=8.8310 | UB min=-1.0569, max=14.0809
  Layer 3: LB min=-15.0362, max=27.4708 | UB min=-5.3487, max=45.0647
  Layer 4: LB min=-13.4127, max=32.0388 | UB min=4.5236, max=45.0647
  Layer 5: LB min=-11.5524, max=31.8079 | UB min=8.2176, max=48.3909
  Layer 6: LB min=-1.1349, max=27.4708 | UB min=22.1362, max=45.0647
  Layer 7: LB min=-7.9199, max=-7.9199 | UB min=13.3688, max=13.3688
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03078174591064453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.025507211685180664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0019440650939941406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.005565166473388672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012710094451904297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014743804931640625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.7922, max=6.2959 | UB min=0.0000, max=9.1663
  Layer 2: LB min=-5.8975, max=9.2299 | UB min=-1.5172, max=13.6395
  Layer 3: LB min=-14.0925, max=23.6558 | UB min=-6.0166, max=38.3989
  Layer 4: LB min=-11.9162, max=27.8928 | UB min=3.3192, max=38.3989
  Layer 5: LB min=-9.4490, max=26.7856 | UB min=6.5851, max=40.4594
  Layer 6: LB min=-0.2298, max=23.6558 | UB min=18.6569, max=38.3989
  Layer 7: LB min=-4.5792, max=-4.5792 | UB min=12.4011, max=12.4011
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.024661779403686523
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0218198299407959
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001199483871459961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011301040649414062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012431144714355469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001111745834350586

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.9425, max=6.1678 | UB min=0.0000, max=9.3064
  Layer 2: LB min=-6.0982, max=9.0320 | UB min=-1.2871, max=13.8603
  Layer 3: LB min=-14.5644, max=25.5847 | UB min=-5.6851, max=41.7481
  Layer 4: LB min=-12.6593, max=29.9840 | UB min=3.9211, max=41.7481
  Layer 5: LB min=-10.5020, max=29.3085 | UB min=7.4077, max=44.4384
  Layer 6: LB min=-0.6785, max=25.5847 | UB min=20.3959, max=41.7481
  Layer 7: LB min=-6.2453, max=-6.2453 | UB min=12.8982, max=12.8982
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04315900802612305
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.014849424362182617
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010254383087158203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012078285217285156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011792182922363281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011570453643798828

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8674, max=6.2319 | UB min=0.0000, max=9.2363
  Layer 2: LB min=-5.9978, max=9.1310 | UB min=-1.4022, max=13.7499
  Layer 3: LB min=-14.3284, max=24.6203 | UB min=-5.8506, max=40.0735
  Layer 4: LB min=-12.2878, max=28.9379 | UB min=3.6201, max=40.0735
  Layer 5: LB min=-9.9766, max=28.0439 | UB min=6.9984, max=42.4489
  Layer 6: LB min=-0.4542, max=24.6203 | UB min=19.5271, max=40.0735
  Layer 7: LB min=-5.4133, max=-5.4133 | UB min=12.6548, max=12.6548
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03508591651916504
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.025312423706054688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011606216430664062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011217594146728516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002716541290283203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001596212387084961

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8298, max=6.2639 | UB min=0.0000, max=9.2013
  Layer 2: LB min=-5.9477, max=9.1804 | UB min=-1.4597, max=13.6947
  Layer 3: LB min=-14.2104, max=24.1380 | UB min=-5.9335, max=39.2362
  Layer 4: LB min=-12.1020, max=28.4152 | UB min=3.4697, max=39.2362
  Layer 5: LB min=-9.7131, max=27.4139 | UB min=6.7923, max=41.4542
  Layer 6: LB min=-0.3420, max=24.1380 | UB min=19.0922, max=39.2362
  Layer 7: LB min=-4.9966, max=-4.9966 | UB min=12.5294, max=12.5294
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04752922058105469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.024758100509643555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016069412231445312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.006666898727416992
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016350746154785156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0022935867309570312

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8110, max=6.2799 | UB min=0.0000, max=9.1838
  Layer 2: LB min=-5.9226, max=9.2052 | UB min=-1.4885, max=13.6671
  Layer 3: LB min=-14.1515, max=23.8969 | UB min=-5.9750, max=38.8175
  Layer 4: LB min=-12.0091, max=28.1540 | UB min=3.3944, max=38.8175
  Layer 5: LB min=-9.5811, max=27.0995 | UB min=6.6889, max=40.9568
  Layer 6: LB min=-0.2859, max=23.8969 | UB min=18.8746, max=38.8175
  Layer 7: LB min=-4.7880, max=-4.7880 | UB min=12.4656, max=12.4656
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03141355514526367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017929553985595703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012798309326171875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004099607467651367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004047393798828125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014910697937011719

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8204, max=6.2719 | UB min=0.0000, max=9.1926
  Layer 2: LB min=-5.9351, max=9.1928 | UB min=-1.4741, max=13.6809
  Layer 3: LB min=-14.1809, max=24.0174 | UB min=-5.9543, max=39.0269
  Layer 4: LB min=-12.0555, max=28.2846 | UB min=3.4320, max=39.0269
  Layer 5: LB min=-9.6471, max=27.2567 | UB min=6.7406, max=41.2055
  Layer 6: LB min=-0.3139, max=24.0174 | UB min=18.9834, max=39.0269
  Layer 7: LB min=-4.8923, max=-4.8923 | UB min=12.4976, max=12.4976
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.032564640045166016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03170418739318848
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011184215545654297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0038688182830810547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014240741729736328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0031447410583496094

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8251, max=6.2679 | UB min=0.0000, max=9.1970
  Layer 2: LB min=-5.9414, max=9.1866 | UB min=-1.4669, max=13.6878
  Layer 3: LB min=-14.1957, max=24.0777 | UB min=-5.9439, max=39.1315
  Layer 4: LB min=-12.0788, max=28.3499 | UB min=3.4508, max=39.1315
  Layer 5: LB min=-9.6801, max=27.3353 | UB min=6.7665, max=41.3298
  Layer 6: LB min=-0.3280, max=24.0777 | UB min=19.0378, max=39.1315
  Layer 7: LB min=-4.9444, max=-4.9444 | UB min=12.5135, max=12.5135
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.024142980575561523
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023801565170288086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00395965576171875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012271404266357422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013468265533447266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016226768493652344

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8204, max=6.2719 | UB min=0.0000, max=9.1926
  Layer 2: LB min=-5.9351, max=9.1928 | UB min=-1.4741, max=13.6809
  Layer 3: LB min=-14.1809, max=24.0174 | UB min=-5.9543, max=39.0269
  Layer 4: LB min=-12.0555, max=28.2846 | UB min=3.4320, max=39.0269
  Layer 5: LB min=-9.6471, max=27.2567 | UB min=6.7406, max=41.2055
  Layer 6: LB min=-0.3139, max=24.0174 | UB min=18.9834, max=39.0269
  Layer 7: LB min=-4.8923, max=-4.8923 | UB min=12.4976, max=12.4976
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04166007041931152
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023627758026123047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011296272277832031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004603862762451172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014920234680175781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.005265712738037109
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.014883041381835938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01815032958984375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0029456615447998047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0031197071075439453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003729581832885742
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004133462905883789
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05482125282287598
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029326438903808594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001310586929321289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010421276092529297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.006916046142578125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004239082336425781
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05579376220703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028539419174194336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0054705142974853516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011188983917236328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010666847229003906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019183158874511719
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.011821269989013672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028978586196899414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010819435119628906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001954317092895508
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0024089813232421875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013599395751953125
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.06049036979675293
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01596212387084961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010609626770019531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011327266693115234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010693073272705078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.011194705963134766
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.021514177322387695
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.012746334075927734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014910697937011719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014090538024902344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014963150024414062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016105175018310547
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.046604156494140625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019348621368408203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011527538299560547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011141300201416016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001096487045288086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012631416320800781
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028512954711914062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019358158111572266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014643669128417969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014460086822509766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015468597412109375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015995502471923828
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05356955528259277
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03605818748474121
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0056438446044921875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0016121864318847656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014691352844238281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001226663589477539
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03075265884399414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017412424087524414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010652542114257812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001129150390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012197494506835938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001180410385131836
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.032356977462768555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026559829711914062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011582374572753906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010464191436767578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012753009796142578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.006931304931640625
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.034732818603515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03447890281677246
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010747909545898438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011506080627441406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0063245296478271484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017654895782470703
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.058042049407958984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.035466909408569336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012984275817871094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.009704828262329102
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0033648014068603516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015594959259033203
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01924610137939453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0321345329284668
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001435995101928711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013058185577392578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011851787567138672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001123666763305664
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029255390167236328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017223834991455078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011169910430908203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011487007141113281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011854171752929688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011899471282958984

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-38.2096, max=0.0000 | UB min=0.0000, max=44.8499
  Layer 2: LB min=0.0000, max=0.0000 | UB min=61.7371, max=92.5392
  Layer 3: LB min=-186.1945, max=227.2946 | UB min=106.6472, max=697.4863
  Layer 4: LB min=-266.3423, max=292.2263 | UB min=207.4361, max=678.8033
  Layer 5: LB min=-324.9018, max=370.5624 | UB min=273.5218, max=859.3911
  Layer 6: LB min=-138.1610, max=197.4598 | UB min=582.2991, max=678.8033
  Layer 7: LB min=-522.9834, max=-522.9834 | UB min=150.0557, max=150.0557
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.007874011993408203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.009372711181640625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010495185852050781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009696483612060547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001119375228881836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001094818115234375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-19.6099, max=0.0000 | UB min=0.0000, max=24.9984
  Layer 2: LB min=0.0000, max=0.0000 | UB min=32.2867, max=49.6898
  Layer 3: LB min=-97.4495, max=131.3149 | UB min=53.6151, max=374.0377
  Layer 4: LB min=-137.1606, max=162.6529 | UB min=106.4939, max=365.6069
  Layer 5: LB min=-167.6487, max=205.7851 | UB min=141.0930, max=457.5130
  Layer 6: LB min=-70.8529, max=113.2422 | UB min=301.4005, max=365.6069
  Layer 7: LB min=-268.6306, max=-268.6306 | UB min=76.4376, max=76.4376
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009944438934326172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0008494853973388672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0007030963897705078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007996559143066406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009565353393554688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.000995635986328125

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-10.1276, max=0.0000 | UB min=0.0000, max=15.1823
  Layer 2: LB min=0.0000, max=0.0000 | UB min=16.5882, max=27.7903
  Layer 3: LB min=-50.8628, max=84.1739 | UB min=25.2029, max=206.9346
  Layer 4: LB min=-68.2119, max=98.5023 | UB min=53.2420, max=202.0359
  Layer 5: LB min=-84.1193, max=123.0645 | UB min=70.6643, max=248.1544
  Layer 6: LB min=-34.6999, max=71.6417 | UB min=154.1052, max=202.0359
  Layer 7: LB min=-132.5004, max=-132.5004 | UB min=38.6904, max=38.6904
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04734230041503906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03506040573120117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004041194915771484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0016016960144042969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012428760528564453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0060541629791259766

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.3006, max=3.0324 | UB min=0.0000, max=11.0251
  Layer 2: LB min=0.0000, max=0.7790 | UB min=8.5871, max=17.0942
  Layer 3: LB min=-26.3068, max=60.6725 | UB min=8.1058, max=115.6215
  Layer 4: LB min=-29.9440, max=65.7844 | UB min=23.8316, max=110.0008
  Layer 5: LB min=-36.4324, max=78.0866 | UB min=30.6964, max=132.0578
  Layer 6: LB min=-6.7802, max=48.6722 | UB min=73.1593, max=110.0008
  Layer 7: LB min=-51.5981, max=-51.5981 | UB min=22.4923, max=22.4923
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027586698532104492
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.012969255447387695
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0027387142181396484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0030939579010009766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003272533416748047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001491546630859375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.8727, max=4.8278 | UB min=0.0000, max=8.9179
  Layer 2: LB min=0.0000, max=4.5556 | UB min=4.9589, max=12.6781
  Layer 3: LB min=-15.9728, max=39.5159 | UB min=-0.1671, max=63.9121
  Layer 4: LB min=-13.5184, max=44.7542 | UB min=9.3357, max=62.1404
  Layer 5: LB min=-14.6192, max=50.0510 | UB min=12.2317, max=72.6588
  Layer 6: LB min=3.2761, max=33.3798 | UB min=36.3653, max=62.1404
  Layer 7: LB min=-15.7369, max=-15.7369 | UB min=12.4376, max=12.4376
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03107428550720215
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.021469593048095703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00127410888671875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011355876922607422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015888214111328125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004215717315673828

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.6577, max=5.7294 | UB min=0.0000, max=7.8624
  Layer 2: LB min=0.0000, max=6.5222 | UB min=2.8677, max=10.6171
  Layer 3: LB min=-11.0288, max=23.8330 | UB min=-3.9388, max=34.9866
  Layer 4: LB min=-5.6437, max=29.8097 | UB min=2.4983, max=37.6987
  Layer 5: LB min=-4.9291, max=32.6734 | UB min=5.1143, max=41.0185
  Layer 6: LB min=6.7286, max=20.6105 | UB min=20.5887, max=34.6851
  Layer 7: LB min=-2.3157, max=-2.3157 | UB min=8.7724, max=8.7724
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.025872230529785156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03012561798095703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012257099151611328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003244638442993164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012009143829345703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013093948364257812

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.2652, max=5.2783 | UB min=0.0000, max=8.3902
  Layer 2: LB min=0.0000, max=5.5307 | UB min=4.0043, max=11.6462
  Layer 3: LB min=-13.5325, max=32.8663 | UB min=-2.0840, max=50.4302
  Layer 4: LB min=-9.9399, max=38.8136 | UB min=6.2989, max=51.1958
  Layer 5: LB min=-9.7357, max=42.2892 | UB min=8.5362, max=57.8131
  Layer 6: LB min=5.4664, max=28.6445 | UB min=28.3395, max=49.9788
  Layer 7: LB min=-8.8054, max=-8.8054 | UB min=10.6344, max=10.6344
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04370617866516113
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.031783103942871094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013451576232910156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0016565322875976562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013332366943359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013566017150878906

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.9615, max=5.5038 | UB min=0.0000, max=8.1263
  Layer 2: LB min=0.0000, max=6.0160 | UB min=3.4353, max=11.1312
  Layer 3: LB min=-12.1979, max=28.4053 | UB min=-3.0276, max=42.7786
  Layer 4: LB min=-7.2637, max=34.4136 | UB min=4.2928, max=44.5040
  Layer 5: LB min=-7.2306, max=37.4828 | UB min=6.7919, max=49.1751
  Layer 6: LB min=6.6432, max=24.7240 | UB min=24.3057, max=42.5308
  Layer 7: LB min=-5.3545, max=-5.3545 | UB min=9.6932, max=9.6932
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01804518699645996
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015305757522583008
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011811256408691406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010700225830078125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0023856163024902344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.005526304244995117

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8096, max=5.6166 | UB min=0.0000, max=7.9944
  Layer 2: LB min=0.0000, max=6.2613 | UB min=3.1512, max=10.8740
  Layer 3: LB min=-11.5821, max=26.1609 | UB min=-3.4947, max=38.9014
  Layer 4: LB min=-6.4375, max=32.1834 | UB min=3.3136, max=41.1664
  Layer 5: LB min=-6.0168, max=35.1056 | UB min=5.9497, max=45.0435
  Layer 6: LB min=7.1966, max=22.7564 | UB min=22.3931, max=38.6779
  Layer 7: LB min=-3.7866, max=-3.7866 | UB min=9.2376, max=9.2376
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03761887550354004
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02586841583251953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013117790222167969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001336812973022461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010800361633300781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0054476261138916016

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.7337, max=5.6730 | UB min=0.0000, max=7.9284
  Layer 2: LB min=0.0000, max=6.3892 | UB min=3.0094, max=10.7454
  Layer 3: LB min=-11.2974, max=25.0088 | UB min=-3.7283, max=36.9434
  Layer 4: LB min=-6.0311, max=31.0108 | UB min=2.8610, max=39.4427
  Layer 5: LB min=-5.4206, max=33.9057 | UB min=5.5303, max=42.9895
  Layer 6: LB min=6.4312, max=21.7009 | UB min=21.4550, max=36.6873
  Layer 7: LB min=-3.0184, max=-3.0184 | UB min=8.9981, max=8.9981
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028879404067993164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.018349647521972656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011644363403320312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009903907775878906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011816024780273438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0065670013427734375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.6957, max=5.7012 | UB min=0.0000, max=7.8954
  Layer 2: LB min=0.0000, max=6.4557 | UB min=2.9385, max=10.6812
  Layer 3: LB min=-11.1630, max=24.4237 | UB min=-3.8373, max=35.9648
  Layer 4: LB min=-5.8340, max=30.4102 | UB min=2.6549, max=38.5697
  Layer 5: LB min=-5.1441, max=33.3048 | UB min=5.3217, max=41.9805
  Layer 6: LB min=6.5818, max=21.1557 | UB min=21.0009, max=35.6832
  Layer 7: LB min=-2.6492, max=-2.6492 | UB min=8.8797, max=8.8797
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.026757001876831055
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023644447326660156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.005089759826660156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012173652648925781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011336803436279297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003887176513671875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.7147, max=5.6871 | UB min=0.0000, max=7.9119
  Layer 2: LB min=0.0000, max=6.4225 | UB min=2.9739, max=10.7133
  Layer 3: LB min=-11.2302, max=24.7191 | UB min=-3.7865, max=36.4536
  Layer 4: LB min=-5.9299, max=30.7105 | UB min=2.7531, max=39.0051
  Layer 5: LB min=-5.2754, max=33.6092 | UB min=5.4257, max=42.4789
  Layer 6: LB min=6.5084, max=21.4283 | UB min=21.2233, max=36.1823
  Layer 7: LB min=-2.8287, max=-2.8287 | UB min=8.9370, max=8.9370
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03281116485595703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.016429424285888672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010852813720703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0032548904418945312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012898445129394531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.007355690002441406

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.7242, max=5.6801 | UB min=0.0000, max=7.9202
  Layer 2: LB min=0.0000, max=6.4058 | UB min=2.9917, max=10.7294
  Layer 3: LB min=-11.2638, max=24.8640 | UB min=-3.7574, max=36.6985
  Layer 4: LB min=-5.9805, max=30.8607 | UB min=2.8070, max=39.2239
  Layer 5: LB min=-5.3478, max=33.7573 | UB min=5.4780, max=42.7341
  Layer 6: LB min=6.4698, max=21.5646 | UB min=21.3391, max=36.4348
  Layer 7: LB min=-2.9235, max=-2.9235 | UB min=8.9677, max=8.9677
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03481483459472656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027978897094726562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011522769927978516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0041561126708984375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001425027847290039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001422882080078125

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.7194, max=5.6836 | UB min=0.0000, max=7.9160
  Layer 2: LB min=0.0000, max=6.4141 | UB min=2.9828, max=10.7213
  Layer 3: LB min=-11.2470, max=24.7915 | UB min=-3.7720, max=36.5760
  Layer 4: LB min=-5.9552, max=30.7856 | UB min=2.7801, max=39.1145
  Layer 5: LB min=-5.3116, max=33.6832 | UB min=5.4518, max=42.6065
  Layer 6: LB min=6.4891, max=21.4965 | UB min=21.2812, max=36.3086
  Layer 7: LB min=-2.8761, max=-2.8761 | UB min=8.9524, max=8.9524
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028113603591918945
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023469209671020508
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001184701919555664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0038597583770751953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012280941009521484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.005919218063354492

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.7147, max=5.6871 | UB min=0.0000, max=7.9119
  Layer 2: LB min=0.0000, max=6.4225 | UB min=2.9739, max=10.7133
  Layer 3: LB min=-11.2302, max=24.7191 | UB min=-3.7865, max=36.4536
  Layer 4: LB min=-5.9299, max=30.7105 | UB min=2.7531, max=39.0051
  Layer 5: LB min=-5.2754, max=33.6092 | UB min=5.4257, max=42.4789
  Layer 6: LB min=6.5084, max=21.4283 | UB min=21.2233, max=36.1823
  Layer 7: LB min=-2.8287, max=-2.8287 | UB min=8.9370, max=8.9370
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.025234699249267578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.014006853103637695
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010399818420410156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011937618255615234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004727363586425781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018892288208007812
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.008545637130737305
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.002890348434448242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011556148529052734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002232789993286133
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015339851379394531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018990039825439453
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0015752315521240234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009996891021728516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010170936584472656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012068748474121094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014388561248779297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014526844024658203
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.001653909683227539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0011243820190429688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0018002986907958984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00122833251953125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012819766998291016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015895366668701172
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03630185127258301
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030909299850463867
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012493133544921875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009922981262207031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0024840831756591797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014700889587402344
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04160881042480469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.032224178314208984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012500286102294922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010824203491210938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010364055633544922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012409687042236328
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02936697006225586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019541025161743164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010864734649658203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010814666748046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011301040649414062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0022704601287841797
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03878974914550781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02138042449951172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012683868408203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010783672332763672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011873245239257812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0070095062255859375
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05137753486633301
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03519415855407715
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011403560638427734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.005442619323730469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016751289367675781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0056688785552978516
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05920696258544922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0303647518157959
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0020072460174560547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001077890396118164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011963844299316406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011191368103027344
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.046460866928100586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017993450164794922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.005171060562133789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011906623840332031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013675689697265625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00735926628112793
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02951812744140625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01733088493347168
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001493692398071289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0024242401123046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001125335693359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013413429260253906
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03152871131896973
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02551746368408203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010025501251220703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.006949186325073242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008656978607177734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009887218475341797
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05277132987976074
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03908586502075195
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012509822845458984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012428760528564453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004037141799926758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014376640319824219
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029232025146484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030332088470458984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001331329345703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0022749900817871094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002662181854248047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013859272003173828
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028740406036376953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01973414421081543
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012600421905517578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011467933654785156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012063980102539062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012595653533935547

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-21.1373, max=0.0000 | UB min=0.0000, max=45.3236
  Layer 2: LB min=0.0000, max=0.0000 | UB min=60.8619, max=93.2607
  Layer 3: LB min=-188.4960, max=230.9631 | UB min=107.6139, max=706.1479
  Layer 4: LB min=-270.3340, max=296.5221 | UB min=209.4373, max=686.1248
  Layer 5: LB min=-328.7570, max=375.7255 | UB min=275.8401, max=869.4008
  Layer 6: LB min=-140.3326, max=201.2217 | UB min=588.2056, max=686.1248
  Layer 7: LB min=-528.1277, max=-528.1277 | UB min=152.6265, max=152.6265
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.006991863250732422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.003409862518310547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0028772354125976562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0036242008209228516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0035791397094726562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00406956672668457

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-11.1171, max=0.0000 | UB min=0.0000, max=25.5707
  Layer 2: LB min=0.0000, max=0.0000 | UB min=32.2409, max=49.7860
  Layer 3: LB min=-99.9857, max=135.4708 | UB min=54.2974, max=383.0384
  Layer 4: LB min=-141.7392, max=167.2578 | UB min=108.2056, max=372.4677
  Layer 5: LB min=-171.5483, max=211.1920 | UB min=142.9950, max=467.5290
  Layer 6: LB min=-73.4457, max=118.0448 | UB min=306.2310, max=372.4677
  Layer 7: LB min=-273.3978, max=-273.3978 | UB min=79.5747, max=79.5747
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04300856590270996
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02085399627685547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003618955612182617
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010876655578613281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018167495727539062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013561248779296875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.9114, max=0.0000 | UB min=0.0000, max=15.5698
  Layer 2: LB min=0.0000, max=0.0000 | UB min=17.1279, max=27.7218
  Layer 3: LB min=-53.1214, max=89.2098 | UB min=25.4627, max=215.4265
  Layer 4: LB min=-72.3578, max=102.7232 | UB min=54.0490, max=208.1569
  Layer 5: LB min=-87.2291, max=128.4651 | UB min=71.0721, max=256.8636
  Layer 6: LB min=-37.0756, max=77.4190 | UB min=156.2900, max=208.1569
  Layer 7: LB min=-135.2487, max=-135.2487 | UB min=45.2354, max=45.2354
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.018166303634643555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.021656274795532227
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0027916431427001953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0031723976135253906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0035867691040039062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0024261474609375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.2212, max=2.2489 | UB min=0.0000, max=10.7594
  Layer 2: LB min=0.0000, max=1.0803 | UB min=9.0953, max=17.2695
  Layer 3: LB min=-28.5952, max=61.9985 | UB min=7.6517, max=121.1525
  Layer 4: LB min=-34.1219, max=68.1572 | UB min=23.4976, max=116.0194
  Layer 5: LB min=-39.6547, max=80.0353 | UB min=31.4447, max=138.1295
  Layer 6: LB min=-9.1744, max=54.8210 | UB min=73.4810, max=116.0194
  Layer 7: LB min=-54.9042, max=-54.9042 | UB min=23.9801, max=23.9801
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.06315350532531738
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.032509565353393555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0019221305847167969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014116764068603516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012412071228027344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.005326747894287109

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8562, max=4.1443 | UB min=0.0000, max=8.4847
  Layer 2: LB min=0.0000, max=5.1194 | UB min=4.8167, max=12.8924
  Layer 3: LB min=-17.0879, max=39.6640 | UB min=-0.5917, max=67.3051
  Layer 4: LB min=-17.2031, max=45.5175 | UB min=9.1265, max=66.0193
  Layer 5: LB min=-17.7224, max=50.1771 | UB min=12.2090, max=75.8306
  Layer 6: LB min=0.6666, max=37.6524 | UB min=34.9313, max=66.0193
  Layer 7: LB min=-17.6173, max=-17.6173 | UB min=13.5406, max=13.5406
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01705455780029297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015347480773925781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011196136474609375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0017497539520263672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014150142669677734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015416145324707031

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.1724, max=5.0931 | UB min=0.0000, max=7.3425
  Layer 2: LB min=0.0000, max=7.0719 | UB min=2.4149, max=10.9458
  Layer 3: LB min=-12.2340, max=25.1014 | UB min=-4.6412, max=39.2571
  Layer 4: LB min=-10.1523, max=31.1208 | UB min=2.2812, max=39.6792
  Layer 5: LB min=-7.5324, max=32.7565 | UB min=3.9146, max=42.9403
  Layer 6: LB min=4.9777, max=25.1014 | UB min=17.9381, max=39.2571
  Layer 7: LB min=-2.9679, max=-2.9679 | UB min=9.0124, max=9.0124
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01999068260192871
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023073911666870117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014777183532714844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011069774627685547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012116432189941406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013282299041748047

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-0.8305, max=5.5690 | UB min=0.0000, max=6.7709
  Layer 2: LB min=0.0000, max=8.0084 | UB min=1.2226, max=9.9493
  Layer 3: LB min=-10.1493, max=14.5799 | UB min=-6.4090, max=22.0212
  Layer 4: LB min=-7.2280, max=19.9842 | UB min=-1.5780, max=24.3372
  Layer 5: LB min=-4.1151, max=21.0506 | UB min=0.4401, max=25.4956
  Layer 6: LB min=6.7749, max=14.5799 | UB min=11.1462, max=22.0212
  Layer 7: LB min=2.4704, max=2.4704 | UB min=7.0616, max=7.0616
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04775738716125488
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03554034233093262
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00625300407409668
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010867118835449219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011932849884033203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0042552947998046875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.0015, max=5.3308 | UB min=0.0000, max=7.0567
  Layer 2: LB min=0.0000, max=7.5406 | UB min=1.8169, max=10.4556
  Layer 3: LB min=-11.1745, max=20.0942 | UB min=-5.4908, max=31.0133
  Layer 4: LB min=-8.5508, max=25.6354 | UB min=0.3474, max=32.1058
  Layer 5: LB min=-5.3821, max=26.9733 | UB min=2.1494, max=33.8734
  Layer 6: LB min=5.8515, max=20.0942 | UB min=13.9410, max=31.0133
  Layer 7: LB min=0.2208, max=0.2208 | UB min=8.0362, max=8.0362
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.009362936019897461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015636920928955078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013284683227539062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001440286636352539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014646053314208984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015790462493896484

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.0870, max=5.2119 | UB min=0.0000, max=7.1996
  Layer 2: LB min=0.0000, max=7.3063 | UB min=2.1153, max=10.7099
  Layer 3: LB min=-11.7359, max=22.6955 | UB min=-5.0611, max=35.2097
  Layer 4: LB min=-9.4319, max=28.4766 | UB min=1.3168, max=35.9946
  Layer 5: LB min=-6.4581, max=29.9299 | UB min=3.0386, max=38.4546
  Layer 6: LB min=5.3903, max=22.6955 | UB min=15.9837, max=35.2097
  Layer 7: LB min=-1.3792, max=-1.3792 | UB min=8.5256, max=8.5256
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04839158058166504
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.031966209411621094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012998580932617188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012862682342529297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010809898376464844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012421607971191406

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.1297, max=5.1524 | UB min=0.0000, max=7.2710
  Layer 2: LB min=0.0000, max=7.1890 | UB min=2.2650, max=10.8280
  Layer 3: LB min=-11.9853, max=23.9995 | UB min=-4.8499, max=37.3347
  Layer 4: LB min=-9.7928, max=29.8967 | UB min=1.7992, max=37.9356
  Layer 5: LB min=-6.9878, max=31.4094 | UB min=3.4761, max=40.7629
  Layer 6: LB min=5.1839, max=23.9995 | UB min=16.9589, max=37.3347
  Layer 7: LB min=-2.1719, max=-2.1719 | UB min=8.7690, max=8.7690
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.031287431716918945
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015831470489501953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011954307556152344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001220703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012271404266357422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004645347595214844

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.1511, max=5.1228 | UB min=0.0000, max=7.3067
  Layer 2: LB min=0.0000, max=7.1305 | UB min=2.3400, max=10.8869
  Layer 3: LB min=-12.1097, max=24.6298 | UB min=-4.7453, max=38.3753
  Layer 4: LB min=-9.9727, max=30.5859 | UB min=2.0402, max=38.8847
  Layer 5: LB min=-7.2598, max=32.1347 | UB min=3.6952, max=41.9032
  Layer 6: LB min=5.0808, max=24.6298 | UB min=17.4479, max=38.3753
  Layer 7: LB min=-2.5697, max=-2.5697 | UB min=8.8907, max=8.8907
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.053646087646484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03318977355957031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00115966796875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010356903076171875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001377105712890625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0024652481079101562

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.1404, max=5.1376 | UB min=0.0000, max=7.2889
  Layer 2: LB min=0.0000, max=7.1598 | UB min=2.3025, max=10.8574
  Layer 3: LB min=-12.0475, max=24.3252 | UB min=-4.7975, max=37.8656
  Layer 4: LB min=-9.8829, max=30.2516 | UB min=1.9197, max=38.4205
  Layer 5: LB min=-7.1233, max=31.7790 | UB min=3.5856, max=41.3399
  Layer 6: LB min=5.1324, max=24.3252 | UB min=17.2021, max=37.8656
  Layer 7: LB min=-2.3707, max=-2.3707 | UB min=8.8299, max=8.8299
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.046202898025512695
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01873159408569336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011913776397705078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00103759765625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012774467468261719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012366771697998047

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.1457, max=5.1302 | UB min=0.0000, max=7.2978
  Layer 2: LB min=0.0000, max=7.1451 | UB min=2.3212, max=10.8722
  Layer 3: LB min=-12.0786, max=24.4881 | UB min=-4.7714, max=38.1310
  Layer 4: LB min=-9.9279, max=30.4290 | UB min=1.9800, max=38.6629
  Layer 5: LB min=-7.1916, max=31.9637 | UB min=3.6404, max=41.6284
  Layer 6: LB min=5.1066, max=24.4881 | UB min=17.3251, max=38.1310
  Layer 7: LB min=-2.4702, max=-2.4702 | UB min=8.8603, max=8.8603
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03787565231323242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01651930809020996
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014789104461669922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002770662307739258
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009748935699462891
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009217262268066406

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.1484, max=5.1265 | UB min=0.0000, max=7.3023
  Layer 2: LB min=0.0000, max=7.1378 | UB min=2.3306, max=10.8795
  Layer 3: LB min=-12.0942, max=24.5695 | UB min=-4.7583, max=38.2637
  Layer 4: LB min=-9.9503, max=30.5178 | UB min=2.0101, max=38.7841
  Layer 5: LB min=-7.2257, max=32.0561 | UB min=3.6678, max=41.7727
  Layer 6: LB min=5.0937, max=24.5695 | UB min=17.3865, max=38.2637
  Layer 7: LB min=-2.5199, max=-2.5199 | UB min=8.8755, max=8.8755
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.030392169952392578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01131582260131836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002546548843383789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004055023193359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0017018318176269531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016515254974365234

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.1457, max=5.1302 | UB min=0.0000, max=7.2978
  Layer 2: LB min=0.0000, max=7.1451 | UB min=2.3212, max=10.8722
  Layer 3: LB min=-12.0786, max=24.4881 | UB min=-4.7714, max=38.1310
  Layer 4: LB min=-9.9279, max=30.4290 | UB min=1.9800, max=38.6629
  Layer 5: LB min=-7.1916, max=31.9637 | UB min=3.6404, max=41.6284
  Layer 6: LB min=5.1066, max=24.4881 | UB min=17.3251, max=38.1310
  Layer 7: LB min=-2.4702, max=-2.4702 | UB min=8.8603, max=8.8603
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03471040725708008
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.024930715560913086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009958744049072266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012738704681396484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002258777618408203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002763032913208008
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.016179800033569336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.025309085845947266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001035451889038086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001781463623046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001249551773071289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012710094451904297
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.035990238189697266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022969961166381836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001781463623046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0019979476928710938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014071464538574219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002881765365600586
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01613140106201172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.012959003448486328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013360977172851562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010273456573486328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001142740249633789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003041505813598633
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04960060119628906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03492331504821777
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001256704330444336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010411739349365234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004870176315307617
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011851787567138672
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03767228126525879
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03434634208679199
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011806488037109375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012469291687011719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011773109436035156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012023448944091797
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.031661033630371094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028670310974121094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001287221908569336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001239776611328125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013897418975830078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011587142944335938
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.015383005142211914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02248692512512207
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0019371509552001953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001191854476928711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014374256134033203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011546611785888672
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.012483358383178711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.010388374328613281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015382766723632812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004622936248779297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014531612396240234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012736320495605469
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.019698381423950195
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.012940645217895508
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013272762298583984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010433197021484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011832714080810547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0033769607543945312
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027110576629638672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02029705047607422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011017322540283203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.005413532257080078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001958131790161133
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0064280033111572266
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03071761131286621
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.012452840805053711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011577606201171875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010955333709716797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003746509552001953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013768672943115234
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.030099868774414062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01650691032409668
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00213623046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013852119445800781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0020787715911865234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015676021575927734
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029820680618286133
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020418643951416016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012612342834472656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003933906555175781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001332998275756836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012764930725097656
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02911376953125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0255739688873291
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013165473937988281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010464191436767578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003398895263671875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001333475112915039
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03133583068847656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.034006357192993164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001287221908569336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001100778579711914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010249614715576172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0041904449462890625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-40.6862, max=0.0000 | UB min=0.0000, max=55.9807
  Layer 2: LB min=-59.3281, max=0.0000 | UB min=0.0000, max=93.3212
  Layer 3: LB min=-186.7726, max=231.1129 | UB min=105.4779, max=700.1001
  Layer 4: LB min=-266.7504, max=298.9606 | UB min=208.6122, max=678.3906
  Layer 5: LB min=-325.8034, max=373.9977 | UB min=274.0912, max=862.1071
  Layer 6: LB min=-136.5103, max=201.3875 | UB min=585.9352, max=678.3906
  Layer 7: LB min=-520.8062, max=-520.8062 | UB min=148.6481, max=148.6481
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0017511844635009766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0012249946594238281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013451576232910156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009748935699462891
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008928775787353516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001051187515258789

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-22.8782, max=0.0000 | UB min=0.0000, max=31.7560
  Layer 2: LB min=-30.9669, max=0.0000 | UB min=0.0000, max=49.9524
  Layer 3: LB min=-96.0087, max=136.8949 | UB min=50.5807, max=372.9179
  Layer 4: LB min=-134.3696, max=171.4042 | UB min=105.6748, max=350.9061
  Layer 5: LB min=-165.0349, max=209.0378 | UB min=138.5418, max=450.8304
  Layer 6: LB min=-65.5102, max=118.1195 | UB min=299.9653, max=348.5884
  Layer 7: LB min=-254.6461, max=-254.6461 | UB min=73.0661, max=73.0661
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029168128967285156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015566825866699219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003078460693359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003118753433227539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001836538314819336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013377666473388672

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-13.7331, max=1.2072 | UB min=0.0000, max=19.4905
  Layer 2: LB min=-15.6274, max=1.1222 | UB min=0.0000, max=28.3392
  Layer 3: LB min=-47.6938, max=88.9475 | UB min=19.0695, max=201.6276
  Layer 4: LB min=-60.4306, max=108.1525 | UB min=47.7373, max=185.3406
  Layer 5: LB min=-76.2993, max=124.5985 | UB min=63.6130, max=233.6251
  Layer 6: LB min=-23.2576, max=76.7815 | UB min=144.9084, max=178.7601
  Layer 7: LB min=-108.9860, max=-108.9860 | UB min=34.3821, max=34.3821
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0352330207824707
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03243899345397949
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014190673828125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012099742889404297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005069255828857422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.005246162414550781

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-9.0935, max=5.3262 | UB min=0.0000, max=14.6406
  Layer 2: LB min=-8.1790, max=7.2711 | UB min=0.0000, max=19.3232
  Layer 3: LB min=-24.8862, max=51.4485 | UB min=2.3284, max=101.6270
  Layer 4: LB min=-22.9850, max=70.5811 | UB min=17.7145, max=99.0599
  Layer 5: LB min=-30.6329, max=67.5294 | UB min=28.1400, max=113.1571
  Layer 6: LB min=1.2583, max=46.9785 | UB min=70.6555, max=89.3505
  Layer 7: LB min=-37.2848, max=-37.2848 | UB min=15.4690, max=15.4690
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.022058725357055664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.006200313568115234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011403560638427734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0031354427337646484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004726886749267578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017876625061035156

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.7545, max=7.3967 | UB min=-2.0540, max=12.1802
  Layer 2: LB min=-4.6576, max=9.9699 | UB min=0.0000, max=15.9021
  Layer 3: LB min=-15.8518, max=31.8718 | UB min=-4.1870, max=55.1533
  Layer 4: LB min=-10.2362, max=50.1234 | UB min=7.3260, max=63.3426
  Layer 5: LB min=-11.8029, max=39.8773 | UB min=14.4599, max=59.2023
  Layer 6: LB min=14.5084, max=30.1937 | UB min=42.4290, max=50.1144
  Layer 7: LB min=-12.9439, max=-12.9439 | UB min=9.0020, max=9.0020
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.019455909729003906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02729511260986328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012164115905761719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011398792266845703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0023069381713867188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003923177719116211

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.5746, max=8.4372 | UB min=-3.1302, max=10.9285
  Layer 2: LB min=-3.0319, max=11.1354 | UB min=0.0000, max=14.1882
  Layer 3: LB min=-12.2647, max=19.0721 | UB min=-6.9466, max=29.8253
  Layer 4: LB min=-5.5277, max=36.8043 | UB min=3.2201, max=43.1820
  Layer 5: LB min=-3.6410, max=23.4273 | UB min=8.3263, max=31.7925
  Layer 6: LB min=18.1208, max=19.0721 | UB min=28.6066, max=30.1826
  Layer 7: LB min=-3.1973, max=-3.1973 | UB min=5.8681, max=5.8681
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0010826587677001953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.000667572021484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00084686279296875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007526874542236328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008976459503173828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009336471557617188

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-4.9831, max=8.9582 | UB min=-3.6690, max=10.3006
  Layer 2: LB min=-2.3091, max=11.6845 | UB min=-0.4813, max=13.3269
  Layer 3: LB min=-10.8872, max=16.2984 | UB min=-8.1652, max=20.7818
  Layer 4: LB min=-3.2440, max=28.4087 | UB min=1.3362, max=31.8102
  Layer 5: LB min=-0.2676, max=16.8742 | UB min=5.5319, max=20.8629
  Layer 6: LB min=10.4224, max=19.6294 | UB min=15.4331, max=24.8861
  Layer 7: LB min=0.5223, max=0.5223 | UB min=4.4855, max=4.4855
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0011169910430908203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0011699199676513672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009913444519042969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002216815948486328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001455545425415039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017652511596679688

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.2789, max=8.6977 | UB min=-3.3996, max=10.6148
  Layer 2: LB min=-2.6710, max=11.4100 | UB min=-0.0564, max=13.7580
  Layer 3: LB min=-11.5002, max=15.5160 | UB min=-7.6160, max=22.8376
  Layer 4: LB min=-4.3850, max=32.6407 | UB min=2.2615, max=37.4981
  Layer 5: LB min=-1.9122, max=20.2224 | UB min=6.8694, max=26.3200
  Layer 6: LB min=14.8349, max=18.8758 | UB min=22.0227, max=27.4678
  Layer 7: LB min=-1.2530, max=-1.2530 | UB min=5.1488, max=5.1488
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.022561073303222656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022317171096801758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004429340362548828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0036897659301757812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014138221740722656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013570785522460938

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.4268, max=8.5674 | UB min=-3.2649, max=10.7717
  Layer 2: LB min=-2.8515, max=11.2727 | UB min=0.0000, max=13.9731
  Layer 3: LB min=-11.8703, max=16.9636 | UB min=-7.2848, max=26.3492
  Layer 4: LB min=-4.9563, max=34.7280 | UB min=2.7429, max=40.3401
  Layer 5: LB min=-2.7753, max=21.8358 | UB min=7.5895, max=29.0544
  Layer 6: LB min=16.9636, max=18.4984 | UB min=25.3146, max=28.8236
  Layer 7: LB min=-2.2144, max=-2.2144 | UB min=5.5031, max=5.5031
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.025708913803100586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.021973609924316406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011141300201416016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001110076904296875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005078792572021484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0021414756774902344

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.3528, max=8.6326 | UB min=-3.3323, max=10.6932
  Layer 2: LB min=-2.7613, max=11.3414 | UB min=0.0000, max=13.8655
  Layer 3: LB min=-11.6736, max=15.9107 | UB min=-7.4597, max=24.5903
  Layer 4: LB min=-4.6706, max=33.6900 | UB min=2.5010, max=38.9191
  Layer 5: LB min=-2.3348, max=21.0399 | UB min=7.2208, max=27.6854
  Layer 6: LB min=15.9107, max=18.6872 | UB min=23.6686, max=28.1360
  Layer 7: LB min=-1.7267, max=-1.7267 | UB min=5.3210, max=5.3210
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0250246524810791
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01982426643371582
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010311603546142578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011975765228271484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002293825149536133
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010647773742675781

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.3159, max=8.6651 | UB min=-3.3659, max=10.6540
  Layer 2: LB min=-2.7161, max=11.3757 | UB min=-0.0033, max=13.8118
  Layer 3: LB min=-11.5767, max=15.4185 | UB min=-7.5477, max=23.6983
  Layer 4: LB min=-4.5278, max=33.1703 | UB min=2.3771, max=38.2086
  Layer 5: LB min=-2.1136, max=20.6404 | UB min=7.0367, max=27.0014
  Layer 6: LB min=15.3861, max=18.7815 | UB min=22.8457, max=27.7905
  Layer 7: LB min=-1.4835, max=-1.4835 | UB min=5.2306, max=5.2306
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.024487018585205078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02868938446044922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009379386901855469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007593631744384766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008223056793212891
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0034799575805664062

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.3344, max=8.6488 | UB min=-3.3491, max=10.6736
  Layer 2: LB min=-2.7387, max=11.3585 | UB min=0.0000, max=13.8386
  Layer 3: LB min=-11.6245, max=15.6493 | UB min=-7.5042, max=24.1436
  Layer 4: LB min=-4.5992, max=33.4305 | UB min=2.4388, max=38.5639
  Layer 5: LB min=-2.2237, max=20.8408 | UB min=7.1282, max=27.3433
  Layer 6: LB min=15.6493, max=18.7343 | UB min=23.2571, max=27.9626
  Layer 7: LB min=-1.6046, max=-1.6046 | UB min=5.2755, max=5.2755
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02695465087890625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.014204740524291992
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0037300586700439453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001178741455078125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012805461883544922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012769699096679688

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.3251, max=8.6570 | UB min=-3.3575, max=10.6638
  Layer 2: LB min=-2.7274, max=11.3671 | UB min=0.0000, max=13.8252
  Layer 3: LB min=-11.5999, max=15.5186 | UB min=-7.5266, max=23.9200
  Layer 4: LB min=-4.5635, max=33.3007 | UB min=2.4077, max=38.3862
  Layer 5: LB min=-2.1680, max=20.7413 | UB min=7.0819, max=27.1723
  Layer 6: LB min=15.5186, max=18.7579 | UB min=23.0514, max=27.8758
  Layer 7: LB min=-1.5437, max=-1.5437 | UB min=5.2528, max=5.2528
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03444051742553711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.018836021423339844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001207590103149414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001201629638671875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010867118835449219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001201629638671875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.3205, max=8.6610 | UB min=-3.3617, max=10.6589
  Layer 2: LB min=-2.7218, max=11.3714 | UB min=0.0000, max=13.8185
  Layer 3: LB min=-11.5876, max=15.4533 | UB min=-7.5378, max=23.8081
  Layer 4: LB min=-4.5457, max=33.2359 | UB min=2.3921, max=38.2974
  Layer 5: LB min=-2.1401, max=20.6915 | UB min=7.0587, max=27.0868
  Layer 6: LB min=15.4533, max=18.7697 | UB min=22.9485, max=27.8323
  Layer 7: LB min=-1.5132, max=-1.5132 | UB min=5.2414, max=5.2414
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.012520790100097656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.010621070861816406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010418891906738281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001519918441772461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014486312866210938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0021467208862304688

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.3159, max=8.6651 | UB min=-3.3659, max=10.6540
  Layer 2: LB min=-2.7161, max=11.3757 | UB min=-0.0033, max=13.8118
  Layer 3: LB min=-11.5767, max=15.4185 | UB min=-7.5477, max=23.6983
  Layer 4: LB min=-4.5278, max=33.1703 | UB min=2.3771, max=38.2086
  Layer 5: LB min=-2.1136, max=20.6404 | UB min=7.0367, max=27.0014
  Layer 6: LB min=15.3861, max=18.7815 | UB min=22.8457, max=27.7905
  Layer 7: LB min=-1.4835, max=-1.4835 | UB min=5.2306, max=5.2306
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0469362735748291
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028883934020996094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013136863708496094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012483596801757812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012860298156738281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011851787567138672
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.011153697967529297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017708778381347656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011186599731445312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009975433349609375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012121200561523438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012745857238769531
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02949357032775879
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02913808822631836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011396408081054688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004566669464111328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013384819030761719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015990734100341797
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03450369834899902
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028064489364624023
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012226104736328125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010628700256347656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005361318588256836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001371622085571289
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04241037368774414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03470206260681152
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011255741119384766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011684894561767578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.010099411010742188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002814054489135742
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027312040328979492
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03279757499694824
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012810230255126953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012812614440917969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0021822452545166016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015566349029541016
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.025809526443481445
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023125410079956055
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0017054080963134766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002821207046508789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001598358154296875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015878677368164062
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.009478569030761719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0039136409759521484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010652542114257812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013873577117919922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015327930450439453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014879703521728516
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0463719367980957
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04374051094055176
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001087188720703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0044057369232177734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013585090637207031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00121307373046875
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05524945259094238
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03535199165344238
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.006015777587890625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012879371643066406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012547969818115234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0033140182495117188
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03194022178649902
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023313045501708984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012483596801757812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011565685272216797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0038788318634033203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013628005981445312
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04975485801696777
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.047478437423706055
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011153221130371094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001260519027709961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0029430389404296875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013875961303710938
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04692220687866211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030835866928100586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012936592102050781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010755062103271484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011296272277832031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011641979217529297
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04263806343078613
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02987360954284668
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010995864868164062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003690958023071289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014400482177734375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013189315795898438
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03131604194641113
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02789139747619629
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013699531555175781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013005733489990234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003283262252807617
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003783702850341797
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02771759033203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030773401260375977
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012335777282714844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011234283447265625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002018451690673828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001516103744506836

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-38.2362, max=0.0000 | UB min=0.0000, max=52.8419
  Layer 2: LB min=-59.5002, max=0.0000 | UB min=0.0000, max=91.4805
  Layer 3: LB min=-186.0435, max=223.1641 | UB min=105.7873, max=690.9216
  Layer 4: LB min=-266.8692, max=289.3281 | UB min=206.8498, max=670.1929
  Layer 5: LB min=-324.7184, max=365.5592 | UB min=271.9561, max=852.1200
  Layer 6: LB min=-138.3249, max=195.1645 | UB min=580.1642, max=670.1929
  Layer 7: LB min=-520.1788, max=-520.1788 | UB min=151.1506, max=151.1506
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05221247673034668
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04014158248901367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010635852813720703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012640953063964844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011687278747558594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004461050033569336

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-19.5565, max=0.0000 | UB min=0.0000, max=27.4051
  Layer 2: LB min=-31.7733, max=0.0000 | UB min=0.0000, max=47.8216
  Layer 3: LB min=-97.5031, max=125.5395 | UB min=52.1266, max=364.8928
  Layer 4: LB min=-138.4214, max=158.6047 | UB min=105.5113, max=349.9709
  Layer 5: LB min=-167.4238, max=198.7491 | UB min=138.7497, max=445.1636
  Layer 6: LB min=-71.2098, max=110.5359 | UB min=297.7053, max=349.9709
  Layer 7: LB min=-262.0695, max=-262.0695 | UB min=78.6709, max=78.6709
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03000783920288086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02184581756591797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009980201721191406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001544952392578125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011887550354003906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0020294189453125

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-10.1049, max=0.0000 | UB min=0.0000, max=15.5188
  Layer 2: LB min=-17.5514, max=0.0000 | UB min=0.0000, max=26.8131
  Layer 3: LB min=-51.2439, max=77.2770 | UB min=23.2149, max=196.9352
  Layer 4: LB min=-70.6348, max=92.8108 | UB min=51.7305, max=183.6109
  Layer 5: LB min=-84.3496, max=114.3190 | UB min=67.6252, max=234.6817
  Layer 6: LB min=-35.7631, max=68.7279 | UB min=148.6807, max=183.6109
  Layer 7: LB min=-125.3907, max=-125.3907 | UB min=42.0874, max=42.0874
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03357410430908203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.031729698181152344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013577938079833984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012280941009521484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011568069458007812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0035719871520996094

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.3236, max=2.0979 | UB min=0.0000, max=10.9294
  Layer 2: LB min=-10.4816, max=2.3773 | UB min=0.0000, max=17.9242
  Layer 3: LB min=-28.3385, max=47.5328 | UB min=5.3023, max=104.2397
  Layer 4: LB min=-34.9077, max=55.2184 | UB min=22.9022, max=96.5682
  Layer 5: LB min=-39.7335, max=64.8101 | UB min=30.7520, max=120.9777
  Layer 6: LB min=-14.4118, max=43.4254 | UB min=70.5135, max=96.5682
  Layer 7: LB min=-53.5099, max=-53.5099 | UB min=22.8623, max=22.8623
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03424715995788574
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04536700248718262
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001247406005859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010983943939208984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0040264129638671875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015397071838378906

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.9221, max=4.1178 | UB min=0.0000, max=8.6110
  Layer 2: LB min=-7.0259, max=6.6340 | UB min=0.0000, max=14.1582
  Layer 3: LB min=-17.3590, max=28.0871 | UB min=-3.9158, max=50.7000
  Layer 4: LB min=-17.7512, max=32.7759 | UB min=10.7286, max=50.7000
  Layer 5: LB min=-17.0872, max=33.6136 | UB min=13.3412, max=58.8346
  Layer 6: LB min=-2.9972, max=26.8883 | UB min=33.3902, max=50.7000
  Layer 7: LB min=-18.9490, max=-18.9490 | UB min=13.4776, max=13.4776
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.011107444763183594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.013248205184936523
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010290145874023438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008084774017333984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008175373077392578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001621246337890625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.7213, max=5.1283 | UB min=0.0000, max=7.4511
  Layer 2: LB min=-5.4863, max=8.5982 | UB min=-1.8413, max=12.3947
  Layer 3: LB min=-13.4066, max=15.7227 | UB min=-7.6292, max=27.1024
  Layer 4: LB min=-9.3459, max=19.1126 | UB min=5.0572, max=27.1024
  Layer 5: LB min=-6.3075, max=16.4786 | UB min=5.3836, max=27.5716
  Layer 6: LB min=1.5904, max=15.7227 | UB min=16.8003, max=27.1024
  Layer 7: LB min=-4.3857, max=-4.3857 | UB min=8.8639, max=8.8639
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03373241424560547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0302579402923584
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00128173828125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001283407211303711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010690689086914062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011179447174072266

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.1209, max=5.6336 | UB min=0.0000, max=6.8712
  Layer 2: LB min=-4.7195, max=9.5791 | UB min=-2.8417, max=11.5294
  Layer 3: LB min=-11.7065, max=10.0810 | UB min=-8.9938, max=15.9665
  Layer 4: LB min=-5.4461, max=12.2829 | UB min=1.3011, max=16.2048
  Layer 5: LB min=-1.8745, max=10.0810 | UB min=2.1966, max=15.9665
  Layer 6: LB min=3.1966, max=10.0810 | UB min=9.9065, max=15.9665
  Layer 7: LB min=0.6862, max=0.6862 | UB min=6.2798, max=6.2798
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.016278505325317383
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.010547161102294922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013165473937988281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003937482833862305
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012123584747314453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012965202331542969

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.4211, max=5.3809 | UB min=0.0000, max=7.1611
  Layer 2: LB min=-5.1020, max=9.0888 | UB min=-2.3383, max=11.9617
  Layer 3: LB min=-12.5169, max=13.3290 | UB min=-8.3361, max=21.9355
  Layer 4: LB min=-7.3633, max=16.1010 | UB min=3.1397, max=21.9355
  Layer 5: LB min=-3.9146, max=13.4118 | UB min=3.7179, max=21.9355
  Layer 6: LB min=2.5654, max=13.3290 | UB min=13.1973, max=21.9355
  Layer 7: LB min=-1.6740, max=-1.6740 | UB min=7.7586, max=7.7586
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0274808406829834
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023987531661987305
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011463165283203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012242794036865234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001104593276977539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012001991271972656

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.5712, max=5.2546 | UB min=0.0000, max=7.3061
  Layer 2: LB min=-5.2940, max=8.8436 | UB min=-2.0867, max=12.1781
  Layer 3: LB min=-12.9335, max=14.5259 | UB min=-8.0059, max=24.4967
  Layer 4: LB min=-8.3381, max=17.6099 | UB min=4.0240, max=24.4967
  Layer 5: LB min=-5.0532, max=14.9913 | UB min=4.5038, max=24.4967
  Layer 6: LB min=2.0994, max=14.5259 | UB min=14.8939, max=24.4967
  Layer 7: LB min=-2.9187, max=-2.9187 | UB min=8.2694, max=8.2694
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.008866071701049805
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01027679443359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002849102020263672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003108978271484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.007295846939086914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004413127899169922

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.6462, max=5.1915 | UB min=0.0000, max=7.3786
  Layer 2: LB min=-5.3902, max=8.7209 | UB min=-1.9632, max=12.2864
  Layer 3: LB min=-13.1696, max=15.1244 | UB min=-7.8256, max=25.7944
  Layer 4: LB min=-8.8395, max=18.3613 | UB min=4.5222, max=25.7944
  Layer 5: LB min=-5.6691, max=15.7477 | UB min=4.9273, max=25.9642
  Layer 6: LB min=1.8451, max=15.1244 | UB min=15.8136, max=25.7944
  Layer 7: LB min=-3.6143, max=-3.6143 | UB min=8.5523, max=8.5523
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.036214590072631836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02561020851135254
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010933876037597656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001142263412475586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0021936893463134766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011553764343261719

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.6087, max=5.2230 | UB min=0.0000, max=7.3424
  Layer 2: LB min=-5.3421, max=8.7822 | UB min=-2.0242, max=12.2322
  Layer 3: LB min=-13.0513, max=14.8252 | UB min=-7.9233, max=25.1408
  Layer 4: LB min=-8.5858, max=17.9856 | UB min=4.2561, max=25.1408
  Layer 5: LB min=-5.3526, max=15.3879 | UB min=4.7132, max=25.1639
  Layer 6: LB min=1.9723, max=14.8252 | UB min=15.3311, max=25.1408
  Layer 7: LB min=-3.2417, max=-3.2417 | UB min=8.3956, max=8.3956
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03087759017944336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029926300048828125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011463165283203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0026547908782958984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013301372528076172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003556489944458008

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.5900, max=5.2388 | UB min=0.0000, max=7.3242
  Layer 2: LB min=-5.3181, max=8.8129 | UB min=-2.0552, max=12.2052
  Layer 3: LB min=-12.9924, max=14.6756 | UB min=-7.9646, max=24.8188
  Layer 4: LB min=-8.4620, max=17.7978 | UB min=4.1402, max=24.8188
  Layer 5: LB min=-5.2028, max=15.1893 | UB min=4.6084, max=24.8188
  Layer 6: LB min=2.0359, max=14.6756 | UB min=15.1124, max=24.8188
  Layer 7: LB min=-3.0801, max=-3.0801 | UB min=8.3328, max=8.3328
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05025148391723633
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02964043617248535
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013091564178466797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003936052322387695
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003312349319458008
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001789093017578125

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.5806, max=5.2467 | UB min=0.0000, max=7.3152
  Layer 2: LB min=-5.3060, max=8.8282 | UB min=-2.0709, max=12.1916
  Layer 3: LB min=-12.9629, max=14.6008 | UB min=-7.9852, max=24.6577
  Layer 4: LB min=-8.4001, max=17.7038 | UB min=4.0821, max=24.6577
  Layer 5: LB min=-5.1280, max=15.0902 | UB min=4.5561, max=24.6577
  Layer 6: LB min=2.0677, max=14.6008 | UB min=15.0032, max=24.6577
  Layer 7: LB min=-2.9994, max=-2.9994 | UB min=8.3012, max=8.3012
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03541064262390137
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029855012893676758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010631084442138672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012176036834716797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005254507064819336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001430511474609375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.5853, max=5.2428 | UB min=0.0000, max=7.3197
  Layer 2: LB min=-5.3121, max=8.8206 | UB min=-2.0631, max=12.1984
  Layer 3: LB min=-12.9777, max=14.6382 | UB min=-7.9749, max=24.7383
  Layer 4: LB min=-8.4310, max=17.7508 | UB min=4.1111, max=24.7383
  Layer 5: LB min=-5.1654, max=15.1397 | UB min=4.5823, max=24.7383
  Layer 6: LB min=2.0518, max=14.6382 | UB min=15.0578, max=24.7383
  Layer 7: LB min=-3.0398, max=-3.0398 | UB min=8.3170, max=8.3170
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03725385665893555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.024580001831054688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003487110137939453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001271963119506836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012054443359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.008885860443115234

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.5806, max=5.2467 | UB min=0.0000, max=7.3152
  Layer 2: LB min=-5.3060, max=8.8282 | UB min=-2.0709, max=12.1916
  Layer 3: LB min=-12.9629, max=14.6008 | UB min=-7.9852, max=24.6577
  Layer 4: LB min=-8.4001, max=17.7038 | UB min=4.0821, max=24.6577
  Layer 5: LB min=-5.1280, max=15.0902 | UB min=4.5561, max=24.6577
  Layer 6: LB min=2.0677, max=14.6008 | UB min=15.0032, max=24.6577
  Layer 7: LB min=-2.9994, max=-2.9994 | UB min=8.3012, max=8.3012
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03842616081237793
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.012999534606933594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010781288146972656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011532306671142578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005766630172729492
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013794898986816406
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03872966766357422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022085189819335938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016360282897949219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003750324249267578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001306295394897461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0039708614349365234
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.023174524307250977
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01720285415649414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0030601024627685547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014986991882324219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001249074935913086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001363515853881836
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.00660252571105957
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.003908634185791016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003134489059448242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011610984802246094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012431144714355469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011310577392578125
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05776023864746094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023563623428344727
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016477108001708984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001556396484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.007083415985107422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018129348754882812
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04313778877258301
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028740882873535156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010502338409423828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.008898258209228516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012423992156982422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013606548309326172
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03181099891662598
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.018955230712890625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010905265808105469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011985301971435547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010960102081298828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011701583862304688
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01141810417175293
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.009736299514770508
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008461475372314453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.000995635986328125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008392333984375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010063648223876953
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04918813705444336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01604461669921875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0007758140563964844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.006496906280517578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009195804595947266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.006730318069458008
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03491806983947754
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023273229598999023
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010483264923095703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011017322540283203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010461807250976562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.007649898529052734
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03036212921142578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015815258026123047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010304450988769531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010721683502197266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016818046569824219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015003681182861328
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028962373733520508
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03668665885925293
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011489391326904297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014312267303466797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001432657241821289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012660026550292969
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.026258468627929688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030864477157592773
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011415481567382812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0070645809173583984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014185905456542969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013587474822998047
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03749418258666992
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04733705520629883
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0018916130065917969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001092672348022461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004990100860595703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013427734375
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03220248222351074
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03083658218383789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.004742860794067383
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001116037368774414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012085437774658203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0028085708618164062
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.025307655334472656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017988204956054688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013589859008789062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011987686157226562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011897087097167969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011904239654541016

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-38.2387, max=0.0000 | UB min=0.0000, max=45.1526
  Layer 2: LB min=0.0000, max=0.0000 | UB min=61.2134, max=92.3761
  Layer 3: LB min=-186.2481, max=228.0685 | UB min=107.0476, max=698.5107
  Layer 4: LB min=-267.6531, max=293.4589 | UB min=207.7931, max=679.7352
  Layer 5: LB min=-325.0362, max=372.0949 | UB min=273.3951, max=860.9996
  Layer 6: LB min=-139.2585, max=197.9632 | UB min=582.4729, max=679.7352
  Layer 7: LB min=-523.5504, max=-523.5504 | UB min=150.3689, max=150.3689
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.012185096740722656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0021126270294189453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0025136470794677734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003306865692138672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0033919811248779297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0035333633422851562

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-19.5231, max=0.0000 | UB min=0.0000, max=25.3913
  Layer 2: LB min=0.0000, max=0.0000 | UB min=33.2566, max=49.3190
  Layer 3: LB min=-97.1941, max=132.2740 | UB min=54.0456, max=374.7090
  Layer 4: LB min=-138.6544, max=164.2298 | UB min=106.5611, max=366.1567
  Layer 5: LB min=-167.4532, max=207.5312 | UB min=140.4648, max=458.9201
  Layer 6: LB min=-72.1265, max=113.9412 | UB min=300.5836, max=366.1567
  Layer 7: LB min=-268.7283, max=-268.7283 | UB min=76.6524, max=76.6524
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.057271480560302734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02813720703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001203298568725586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004513978958129883
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014753341674804688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.005447864532470703

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-10.0214, max=0.0000 | UB min=0.0000, max=15.3672
  Layer 2: LB min=0.0000, max=0.0000 | UB min=17.6651, max=27.2873
  Layer 3: LB min=-50.0764, max=88.4602 | UB min=25.8358, max=207.8035
  Layer 4: LB min=-69.7476, max=100.6047 | UB min=52.8793, max=202.7159
  Layer 5: LB min=-82.7301, max=125.1713 | UB min=67.9130, max=249.0799
  Layer 6: LB min=-36.1683, max=73.3425 | UB min=150.6237, max=202.7159
  Layer 7: LB min=-130.5931, max=-130.5931 | UB min=44.3090, max=44.3090
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03168845176696777
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015877962112426758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011150836944580078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011742115020751953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011699199676513672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012011528015136719

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.2116, max=3.1171 | UB min=0.0000, max=11.0915
  Layer 2: LB min=0.0000, max=0.9993 | UB min=9.7920, max=16.8578
  Layer 3: LB min=-25.1875, max=62.4298 | UB min=8.4448, max=116.4990
  Layer 4: LB min=-30.9656, max=68.5856 | UB min=22.7613, max=110.7168
  Layer 5: LB min=-37.0381, max=80.3938 | UB min=29.1407, max=134.4460
  Layer 6: LB min=-13.1783, max=52.1005 | UB min=70.4229, max=110.7168
  Layer 7: LB min=-52.7739, max=-52.7739 | UB min=23.7301, max=23.7301
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04740262031555176
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.025833606719970703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0007488727569580078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.000850677490234375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0055353641510009766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001546621322631836

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.8028, max=4.9016 | UB min=0.0000, max=9.0016
  Layer 2: LB min=0.0000, max=4.5652 | UB min=5.1801, max=12.4961
  Layer 3: LB min=-14.1483, max=39.1075 | UB min=0.8013, max=62.3024
  Layer 4: LB min=-14.5536, max=45.7820 | UB min=7.6907, max=61.9830
  Layer 5: LB min=-14.4343, max=50.1398 | UB min=10.9794, max=72.5845
  Layer 6: LB min=1.5532, max=34.2096 | UB min=32.7252, max=61.6649
  Layer 7: LB min=-14.4142, max=-14.4142 | UB min=12.9092, max=12.9092
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02133941650390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017843246459960938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0029141902923583984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0032939910888671875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003566741943359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004499197006225586

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8372, max=5.7939 | UB min=0.0000, max=7.9553
  Layer 2: LB min=0.0000, max=6.4039 | UB min=2.9146, max=10.4753
  Layer 3: LB min=-9.4955, max=23.8925 | UB min=-2.3855, max=36.2290
  Layer 4: LB min=-7.2641, max=32.5413 | UB min=1.8077, max=40.1883
  Layer 5: LB min=-5.1589, max=33.6028 | UB min=3.9971, max=43.0024
  Layer 6: LB min=5.4168, max=22.3218 | UB min=17.4094, max=36.2290
  Layer 7: LB min=-1.7417, max=-1.7417 | UB min=9.3092, max=9.3092
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03559470176696777
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.025856733322143555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0019745826721191406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0038564205169677734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012564659118652344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011625289916992188

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.2492, max=5.3478 | UB min=0.0000, max=8.4791
  Layer 2: LB min=0.0000, max=5.4597 | UB min=4.0478, max=11.4849
  Layer 3: LB min=-11.8058, max=31.8220 | UB min=-0.8373, max=49.7293
  Layer 4: LB min=-11.3351, max=39.5502 | UB min=4.6054, max=51.4911
  Layer 5: LB min=-9.6867, max=42.1000 | UB min=7.3394, max=57.8424
  Layer 6: LB min=3.5052, max=29.1621 | UB min=24.8426, max=49.7293
  Layer 7: LB min=-7.7735, max=-7.7735 | UB min=11.1225, max=11.1225
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02194833755493164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01148676872253418
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009739398956298828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0041277408599853516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00173187255859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014805793762207031

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.0434, max=5.5709 | UB min=0.0000, max=8.2175
  Layer 2: LB min=0.0000, max=5.9313 | UB min=3.4812, max=10.9799
  Layer 3: LB min=-10.5617, max=28.1027 | UB min=-1.6479, max=43.8182
  Layer 4: LB min=-8.8742, max=36.3817 | UB min=3.1181, max=46.0956
  Layer 5: LB min=-7.0531, max=38.1858 | UB min=5.6106, max=50.2551
  Layer 6: LB min=4.5168, max=26.4660 | UB min=20.8082, max=43.8182
  Layer 7: LB min=-4.4150, max=-4.4150 | UB min=10.1394, max=10.1394
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0426325798034668
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03351092338562012
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002652406692504883
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0030977725982666016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003367900848388672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.011509895324707031

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.9403, max=5.6824 | UB min=0.0000, max=8.0865
  Layer 2: LB min=0.0000, max=6.1670 | UB min=3.1979, max=10.7275
  Layer 3: LB min=-10.0276, max=26.0557 | UB min=-2.0181, max=40.1139
  Layer 4: LB min=-8.0648, max=34.5432 | UB min=2.4344, max=43.2217
  Layer 5: LB min=-6.0226, max=35.9826 | UB min=4.8005, max=46.6215
  Layer 6: LB min=4.9681, max=24.4871 | UB min=19.0476, max=40.1139
  Layer 7: LB min=-3.0272, max=-3.0272 | UB min=9.7218, max=9.7218
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04645228385925293
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03737759590148926
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.007328510284423828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011608600616455078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00112152099609375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012645721435546875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8888, max=5.7382 | UB min=0.0000, max=8.0209
  Layer 2: LB min=0.0000, max=6.2853 | UB min=3.0562, max=10.6013
  Layer 3: LB min=-9.7612, max=25.0239 | UB min=-2.2018, max=38.2478
  Layer 4: LB min=-7.6637, max=33.6169 | UB min=2.1219, max=41.7794
  Layer 5: LB min=-5.5892, max=34.8446 | UB min=4.3983, max=44.8539
  Layer 6: LB min=5.1925, max=23.4809 | UB min=18.2279, max=38.2478
  Layer 7: LB min=-2.3830, max=-2.3830 | UB min=9.5197, max=9.5197
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02982020378112793
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.008902788162231445
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001434326171875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004125356674194336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0017130374908447266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016715526580810547

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8630, max=5.7660 | UB min=0.0000, max=7.9881
  Layer 2: LB min=0.0000, max=6.3446 | UB min=2.9854, max=10.5383
  Layer 3: LB min=-9.6283, max=24.5080 | UB min=-2.2937, max=37.3147
  Layer 4: LB min=-7.4637, max=33.1535 | UB min=1.9660, max=41.0582
  Layer 5: LB min=-5.3737, max=34.2745 | UB min=4.1974, max=43.9752
  Layer 6: LB min=5.3047, max=22.9777 | UB min=17.8185, max=37.3147
  Layer 7: LB min=-2.0620, max=-2.0620 | UB min=9.4157, max=9.4157
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.032361507415771484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.018560409545898438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001041412353515625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010542869567871094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001146554946899414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.007204532623291016

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8501, max=5.7800 | UB min=0.0000, max=7.9717
  Layer 2: LB min=0.0000, max=6.3742 | UB min=2.9500, max=10.5068
  Layer 3: LB min=-9.5619, max=24.2076 | UB min=-2.3396, max=36.7832
  Layer 4: LB min=-7.3638, max=32.8584 | UB min=1.8880, max=40.6343
  Layer 5: LB min=-5.2662, max=33.9457 | UB min=4.0971, max=43.4961
  Layer 6: LB min=5.3608, max=22.6611 | UB min=17.6139, max=36.7832
  Layer 7: LB min=-1.9018, max=-1.9018 | UB min=9.3628, max=9.3628
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0412900447845459
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01747584342956543
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0028848648071289062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.007203340530395508
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0037496089935302734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018024444580078125

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8565, max=5.7730 | UB min=0.0000, max=7.9799
  Layer 2: LB min=0.0000, max=6.3594 | UB min=2.9677, max=10.5225
  Layer 3: LB min=-9.5951, max=24.3652 | UB min=-2.3166, max=37.0603
  Layer 4: LB min=-7.4137, max=33.0170 | UB min=1.9270, max=40.8573
  Layer 5: LB min=-5.3199, max=34.1174 | UB min=4.1472, max=43.7430
  Layer 6: LB min=5.3327, max=22.8307 | UB min=17.7162, max=37.0603
  Layer 7: LB min=-1.9818, max=-1.9818 | UB min=9.3893, max=9.3893
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.026012420654296875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0175478458404541
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016720294952392578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0020508766174316406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018024444580078125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017743110656738281

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8533, max=5.7765 | UB min=0.0000, max=7.9758
  Layer 2: LB min=0.0000, max=6.3668 | UB min=2.9588, max=10.5147
  Layer 3: LB min=-9.5785, max=24.2864 | UB min=-2.3281, max=36.9217
  Layer 4: LB min=-7.3888, max=32.9377 | UB min=1.9075, max=40.7458
  Layer 5: LB min=-5.2931, max=34.0315 | UB min=4.1222, max=43.6195
  Layer 6: LB min=5.3467, max=22.7459 | UB min=17.6651, max=36.9217
  Layer 7: LB min=-1.9418, max=-1.9418 | UB min=9.3761, max=9.3761
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.039098501205444336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020043611526489258
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014019012451171875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.008878469467163086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014042854309082031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0037326812744140625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.8533, max=5.7765 | UB min=0.0000, max=7.9758
  Layer 2: LB min=0.0000, max=6.3668 | UB min=2.9588, max=10.5147
  Layer 3: LB min=-9.5785, max=24.2864 | UB min=-2.3281, max=36.9217
  Layer 4: LB min=-7.3888, max=32.9377 | UB min=1.9075, max=40.7458
  Layer 5: LB min=-5.2931, max=34.0315 | UB min=4.1222, max=43.6195
  Layer 6: LB min=5.3467, max=22.7459 | UB min=17.6651, max=36.9217
  Layer 7: LB min=-1.9418, max=-1.9418 | UB min=9.3761, max=9.3761
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04109549522399902
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.016979694366455078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0020296573638916016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0017652511596679688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015583038330078125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002512693405151367
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02646613121032715
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023549318313598633
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001123666763305664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009922981262207031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010104179382324219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012557506561279297
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029662370681762695
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026346445083618164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010714530944824219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012888908386230469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003224611282348633
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001608133316040039
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0380551815032959
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030122756958007812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011501312255859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010602474212646484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003177165985107422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014920234680175781
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02994704246520996
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04027295112609863
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014111995697021484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0016219615936279297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0023779869079589844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017096996307373047
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.036432743072509766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04174995422363281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014579296112060547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0025718212127685547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00107574462890625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010089874267578125
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03337693214416504
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03153800964355469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001890420913696289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011343955993652344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001287698745727539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004068851470947266
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05182933807373047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03207063674926758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00121307373046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010485649108886719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001277923583984375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012958049774169922
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.026921987533569336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04522085189819336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001132965087890625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012519359588623047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013828277587890625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010027885437011719
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02900838851928711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.039188385009765625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011284351348876953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011944770812988281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011799335479736328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001178741455078125
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02983546257019043
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023434162139892578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001651763916015625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0042133331298828125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011944770812988281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002764463424682617
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04339194297790527
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017661094665527344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0041239261627197266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012927055358886719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013647079467773438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013921260833740234
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03358602523803711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.032720088958740234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010883808135986328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012035369873046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001069784164428711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011925697326660156
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.026465892791748047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029359102249145508
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012595653533935547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012269020080566406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0026259422302246094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00125885009765625
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03485846519470215
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.024565935134887695
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0020630359649658203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011811256408691406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011606216430664062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017621517181396484
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028975248336791992
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03926396369934082
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011610984802246094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011506080627441406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001068115234375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003037691116333008

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-21.6388, max=0.0000 | UB min=0.0000, max=44.7603
  Layer 2: LB min=0.0000, max=0.0000 | UB min=61.0292, max=91.6786
  Layer 3: LB min=-188.7446, max=231.4972 | UB min=106.7021, max=706.0533
  Layer 4: LB min=-269.9435, max=295.2955 | UB min=208.7821, max=684.3127
  Layer 5: LB min=-327.0095, max=376.2468 | UB min=274.9684, max=867.9398
  Layer 6: LB min=-139.7852, max=202.2856 | UB min=584.9633, max=684.3127
  Layer 7: LB min=-526.1682, max=-526.1682 | UB min=152.6850, max=152.6850
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.009492874145507812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.014778614044189453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003172636032104492
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0021555423736572266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001608133316040039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011987686157226562

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-12.2693, max=0.0000 | UB min=0.0000, max=24.6806
  Layer 2: LB min=0.0000, max=0.0000 | UB min=31.5830, max=48.0130
  Layer 3: LB min=-101.0133, max=137.5750 | UB min=53.1843, max=385.0081
  Layer 4: LB min=-142.1482, max=166.5955 | UB min=107.8256, max=372.6306
  Layer 5: LB min=-169.9257, max=213.6380 | UB min=142.1801, max=468.1605
  Layer 6: LB min=-73.1557, max=120.4396 | UB min=303.5675, max=372.6306
  Layer 7: LB min=-271.9804, max=-271.9804 | UB min=82.7545, max=82.7545
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0597684383392334
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023017168045043945
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.007012128829956055
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012722015380859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013146400451660156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.005187511444091797

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-7.4144, max=0.0000 | UB min=0.0000, max=14.8899
  Layer 2: LB min=0.0000, max=0.0000 | UB min=15.8351, max=27.4932
  Layer 3: LB min=-54.1233, max=96.1301 | UB min=23.3503, max=218.1016
  Layer 4: LB min=-72.7511, max=104.2010 | UB min=53.2546, max=210.2450
  Layer 5: LB min=-83.7494, max=133.0407 | UB min=68.9627, max=257.9167
  Layer 6: LB min=-37.0625, max=81.3281 | UB min=151.9147, max=210.2450
  Layer 7: LB min=-132.6270, max=-132.6270 | UB min=44.0124, max=44.0124
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01392054557800293
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.005571603775024414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001071929931640625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011332035064697266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011258125305175781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011184215545654297

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-4.9023, max=1.8107 | UB min=0.0000, max=10.6996
  Layer 2: LB min=0.0000, max=2.6236 | UB min=8.2759, max=17.5558
  Layer 3: LB min=-29.3097, max=71.3868 | UB min=4.2629, max=124.0168
  Layer 4: LB min=-34.3204, max=70.8110 | UB min=21.9427, max=118.9171
  Layer 5: LB min=-35.3825, max=88.5819 | UB min=26.8798, max=142.0749
  Layer 6: LB min=-11.2214, max=60.0996 | UB min=67.6250, max=118.9171
  Layer 7: LB min=-51.7212, max=-51.7212 | UB min=22.5174, max=22.5174
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0014960765838623047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0010259151458740234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009772777557373047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011801719665527344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014090538024902344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0022759437561035156

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.6366, max=3.9399 | UB min=0.0000, max=8.5959
  Layer 2: LB min=0.0000, max=6.4781 | UB min=4.5019, max=13.5931
  Layer 3: LB min=-19.1444, max=43.1910 | UB min=-3.9652, max=67.8442
  Layer 4: LB min=-19.4138, max=43.8185 | UB min=7.3379, max=65.4079
  Layer 5: LB min=-15.4159, max=54.7570 | UB min=9.7949, max=78.5522
  Layer 6: LB min=1.1911, max=38.1470 | UB min=34.0624, max=65.4079
  Layer 7: LB min=-16.7856, max=-16.7856 | UB min=11.8718, max=11.8718
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03936481475830078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01947927474975586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012359619140625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010352134704589844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00488591194152832
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012922286987304688

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.0034, max=5.1151 | UB min=-0.4854, max=7.5428
  Layer 2: LB min=0.0000, max=8.1349 | UB min=2.3686, max=11.6034
  Layer 3: LB min=-14.6883, max=26.3462 | UB min=-7.4000, max=38.8310
  Layer 4: LB min=-13.0987, max=27.1429 | UB min=-0.5840, max=36.3982
  Layer 5: LB min=-7.0463, max=36.6033 | UB min=2.3311, max=46.4883
  Layer 6: LB min=6.8099, max=22.9623 | UB min=19.4778, max=36.3478
  Layer 7: LB min=-3.9745, max=-3.9745 | UB min=7.1056, max=7.1056
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.009774446487426758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.004457712173461914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002203226089477539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0017566680908203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014252662658691406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015931129455566406

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.6828, max=5.7032 | UB min=-1.3254, max=7.0112
  Layer 2: LB min=0.0000, max=8.7817 | UB min=1.5012, max=10.6058
  Layer 3: LB min=-12.6247, max=15.3548 | UB min=-9.0007, max=21.7726
  Layer 4: LB min=-10.3100, max=16.5214 | UB min=-4.3076, max=20.8579
  Layer 5: LB min=-4.7455, max=24.7464 | UB min=-0.8696, max=29.6088
  Layer 6: LB min=9.3930, max=13.5526 | UB min=15.0074, max=20.5910
  Layer 7: LB min=0.1967, max=0.1967 | UB min=5.0591, max=5.0591
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0011548995971679688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009284019470214844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001050710678100586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011954307556152344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0017735958099365234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016460418701171875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.8451, max=5.4090 | UB min=-0.9049, max=7.2796
  Layer 2: LB min=0.0000, max=8.4568 | UB min=1.9351, max=11.1076
  Layer 3: LB min=-13.6174, max=21.1987 | UB min=-8.2284, max=30.6268
  Layer 4: LB min=-11.6233, max=22.0396 | UB min=-2.5302, max=28.8043
  Layer 5: LB min=-5.6838, max=31.0273 | UB min=0.6289, max=38.2567
  Layer 6: LB min=8.1461, max=18.3386 | UB min=16.8440, max=28.5142
  Layer 7: LB min=-1.4878, max=-1.4878 | UB min=6.0411, max=6.0411
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0010883808135986328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0017037391662597656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011200904846191406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013849735260009766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013930797576904297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015749931335449219

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7646, max=5.5560 | UB min=-1.1149, max=7.1462
  Layer 2: LB min=0.0000, max=8.6187 | UB min=1.7182, max=10.8576
  Layer 3: LB min=-13.1063, max=18.2946 | UB min=-8.6136, max=26.2157
  Layer 4: LB min=-10.9459, max=19.2911 | UB min=-3.4532, max=24.8313
  Layer 5: LB min=-5.1373, max=27.9136 | UB min=-0.1547, max=33.9156
  Layer 6: LB min=8.7815, max=15.9537 | UB min=15.7133, max=24.5593
  Layer 7: LB min=-0.4668, max=-0.4668 | UB min=5.5353, max=5.5353
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009410381317138672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0014653205871582031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013968944549560547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002575397491455078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0022199153900146484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004282474517822266

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7237, max=5.6296 | UB min=-1.2202, max=7.0787
  Layer 2: LB min=0.0000, max=8.7002 | UB min=1.6096, max=10.7315
  Layer 3: LB min=-12.8647, max=16.8251 | UB min=-8.8072, max=23.9939
  Layer 4: LB min=-10.6280, max=17.9063 | UB min=-3.8778, max=22.8418
  Layer 5: LB min=-4.9414, max=26.3300 | UB min=-0.5167, max=31.7622
  Layer 6: LB min=9.0872, max=14.7532 | UB min=15.3604, max=22.5751
  Layer 7: LB min=-0.1351, max=-0.1351 | UB min=5.2972, max=5.2972
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.048947811126708984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030394792556762695
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003549337387084961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001142740249633789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.008713006973266602
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.005671501159667969

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7033, max=5.6664 | UB min=-1.2728, max=7.0449
  Layer 2: LB min=0.0000, max=8.7410 | UB min=1.5554, max=10.6686
  Layer 3: LB min=-12.7445, max=16.0900 | UB min=-8.9040, max=22.8830
  Layer 4: LB min=-10.4690, max=17.2138 | UB min=-4.0928, max=21.8494
  Layer 5: LB min=-4.8434, max=25.5382 | UB min=-0.6943, max=30.6855
  Layer 6: LB min=9.2401, max=14.1529 | UB min=15.1839, max=21.5831
  Layer 7: LB min=0.0308, max=0.0308 | UB min=5.1781, max=5.1781
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.012767791748046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0047855377197265625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011758804321289062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010027885437011719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001117706298828125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.005414247512817383

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7135, max=5.6480 | UB min=-1.2465, max=7.0618
  Layer 2: LB min=0.0000, max=8.7206 | UB min=1.5825, max=10.7000
  Layer 3: LB min=-12.8046, max=16.4576 | UB min=-8.8556, max=23.4384
  Layer 4: LB min=-10.5485, max=17.5601 | UB min=-3.9854, max=22.3454
  Layer 5: LB min=-4.8924, max=25.9341 | UB min=-0.6058, max=31.2239
  Layer 6: LB min=9.1637, max=14.4531 | UB min=15.2722, max=22.0791
  Layer 7: LB min=-0.0521, max=-0.0521 | UB min=5.2376, max=5.2376
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.001035928726196289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0008153915405273438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0006957054138183594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007352828979492188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009343624114990234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010411739349365234

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7084, max=5.6572 | UB min=-1.2596, max=7.0534
  Layer 2: LB min=0.0000, max=8.7308 | UB min=1.5689, max=10.6843
  Layer 3: LB min=-12.7745, max=16.2738 | UB min=-8.8798, max=23.1607
  Layer 4: LB min=-10.5087, max=17.3869 | UB min=-4.0391, max=22.0973
  Layer 5: LB min=-4.8679, max=25.7362 | UB min=-0.6502, max=30.9547
  Layer 6: LB min=9.2019, max=14.3030 | UB min=15.2280, max=21.8311
  Layer 7: LB min=-0.0106, max=-0.0106 | UB min=5.2079, max=5.2079
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05847811698913574
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.024075984954833984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008752346038818359
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0044596195220947266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016036033630371094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001369476318359375

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7058, max=5.6618 | UB min=-1.2662, max=7.0491
  Layer 2: LB min=0.0000, max=8.7359 | UB min=1.5621, max=10.6764
  Layer 3: LB min=-12.7595, max=16.1819 | UB min=-8.8919, max=23.0219
  Layer 4: LB min=-10.4889, max=17.3004 | UB min=-4.0660, max=21.9733
  Layer 5: LB min=-4.8557, max=25.6372 | UB min=-0.6723, max=30.8201
  Layer 6: LB min=9.2210, max=14.2280 | UB min=15.2060, max=21.7071
  Layer 7: LB min=0.0101, max=0.0101 | UB min=5.1930, max=5.1930
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.018227577209472656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02442169189453125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011246204376220703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010933876037597656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011334419250488281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011529922485351562

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7058, max=5.6618 | UB min=-1.2662, max=7.0491
  Layer 2: LB min=0.0000, max=8.7359 | UB min=1.5621, max=10.6764
  Layer 3: LB min=-12.7595, max=16.1819 | UB min=-8.8919, max=23.0219
  Layer 4: LB min=-10.4889, max=17.3004 | UB min=-4.0660, max=21.9733
  Layer 5: LB min=-4.8557, max=25.6372 | UB min=-0.6723, max=30.8201
  Layer 6: LB min=9.2210, max=14.2280 | UB min=15.2060, max=21.7071
  Layer 7: LB min=0.0101, max=0.0101 | UB min=5.1930, max=5.1930
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0013203620910644531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0007233619689941406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0007257461547851562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011942386627197266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009741783142089844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010118484497070312
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.025682449340820312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023295879364013672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00135040283203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010051727294921875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011363029479980469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001089334487915039
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.016561031341552734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01232600212097168
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001802682876586914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001210927963256836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011641979217529297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012497901916503906
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0019440650939941406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0010361671447753906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010440349578857422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008168220520019531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015957355499267578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019865036010742188
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04348945617675781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028499603271484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0043332576751708984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013201236724853516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011000633239746094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0027632713317871094
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028000831604003906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026102304458618164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001111745834350586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011060237884521484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004616975784301758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002754688262939453
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.05499744415283203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030177831649780273
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00115203857421875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0017390251159667969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002469301223754883
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002256631851196289
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.013682126998901367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.009460210800170898
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011463165283203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010242462158203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014247894287109375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011796951293945312
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.036687612533569336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02558732032775879
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011467933654785156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0028285980224609375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0037331581115722656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001348257064819336
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01842808723449707
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.007365226745605469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010428428649902344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010609626770019531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011448860168457031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011708736419677734
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04625201225280762
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029217004776000977
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001216888427734375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012652873992919922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0056247711181640625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017964839935302734
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.00875997543334961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.007719516754150391
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001516580581665039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013363361358642578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014789104461669922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016918182373046875
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0024442672729492188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009450912475585938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010464191436767578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012526512145996094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015790462493896484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017457008361816406
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0037670135498046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0010557174682617188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010733604431152344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013179779052734375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001468658447265625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001590728759765625
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0011000633239746094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009059906005859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001074075698852539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012941360473632812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012989044189453125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019783973693847656
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0017323493957519531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0014681816101074219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014357566833496094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013816356658935547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002263784408569336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001775503158569336

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-21.2880, max=0.0000 | UB min=0.0000, max=43.6567
  Layer 2: LB min=0.0000, max=0.0000 | UB min=60.3533, max=91.2456
  Layer 3: LB min=-187.6057, max=224.2516 | UB min=106.7346, max=697.4436
  Layer 4: LB min=-268.4496, max=289.2856 | UB min=208.1535, max=675.7191
  Layer 5: LB min=-325.9924, max=369.2351 | UB min=274.2256, max=859.3190
  Layer 6: LB min=-139.5047, max=195.9855 | UB min=583.1793, max=675.7191
  Layer 7: LB min=-524.6232, max=-524.6232 | UB min=152.3364, max=152.3364
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0014939308166503906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0026023387908935547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010943412780761719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012438297271728516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0018291473388671875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001781463623046875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-11.6020, max=0.0000 | UB min=0.0000, max=23.0714
  Layer 2: LB min=0.0000, max=0.0000 | UB min=31.8110, max=47.3819
  Layer 3: LB min=-99.4660, max=126.1671 | UB min=53.7108, max=372.9214
  Layer 4: LB min=-140.6071, max=157.3378 | UB min=107.3482, max=360.7582
  Layer 5: LB min=-169.3361, max=202.8182 | UB min=142.2179, max=456.6273
  Layer 6: LB min=-73.0270, max=110.6370 | UB min=302.1333, max=360.7582
  Layer 7: LB min=-271.6071, max=-271.6071 | UB min=79.6374, max=79.6374
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0011451244354248047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0010638236999511719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010495185852050781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001165628433227539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013320446014404297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002845287322998047

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.5964, max=0.0000 | UB min=0.0000, max=13.5588
  Layer 2: LB min=0.0000, max=0.0000 | UB min=15.9923, max=25.4852
  Layer 3: LB min=-53.6484, max=77.6009 | UB min=25.8685, max=205.7611
  Layer 4: LB min=-73.8477, max=91.2198 | UB min=54.8732, max=198.3605
  Layer 5: LB min=-87.2088, max=118.9648 | UB min=72.6879, max=248.7869
  Layer 6: LB min=-38.0106, max=68.1648 | UB min=155.9239, max=198.3605
  Layer 7: LB min=-138.4580, max=-138.4580 | UB min=44.0113, max=44.0113
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0012767314910888672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0008947849273681641
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0018093585968017578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014636516571044922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014657974243164062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018699169158935547

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.9884, max=0.1788 | UB min=0.0000, max=9.2902
  Layer 2: LB min=0.0000, max=0.0000 | UB min=7.9644, max=15.2410
  Layer 3: LB min=-28.6286, max=57.0303 | UB min=8.3548, max=116.6488
  Layer 4: LB min=-36.4152, max=59.7284 | UB min=24.5383, max=112.4879
  Layer 5: LB min=-40.1239, max=77.5097 | UB min=32.6027, max=137.2070
  Layer 6: LB min=-16.6943, max=48.4515 | UB min=73.5779, max=112.4879
  Layer 7: LB min=-62.0170, max=-62.0170 | UB min=23.6067, max=23.6067
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0012879371643066406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009431838989257812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016703605651855469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013737678527832031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015759468078613281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015177726745605469

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.6618, max=2.4747 | UB min=0.0000, max=7.1192
  Layer 2: LB min=0.0000, max=3.2347 | UB min=4.3277, max=11.0112
  Layer 3: LB min=-16.9955, max=37.2041 | UB min=-0.4981, max=64.2030
  Layer 4: LB min=-17.0872, max=37.4888 | UB min=9.4980, max=61.4999
  Layer 5: LB min=-16.8803, max=49.5954 | UB min=11.4484, max=75.2542
  Layer 6: LB min=-3.5340, max=31.3751 | UB min=33.1928, max=61.4999
  Layer 7: LB min=-21.2717, max=-21.2717 | UB min=12.1360, max=12.1360
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0021326541900634766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.002118825912475586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0019190311431884766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0018734931945800781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016994476318359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016450881958007812

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.9966, max=3.6229 | UB min=0.0000, max=6.0276
  Layer 2: LB min=0.0000, max=5.3134 | UB min=2.7167, max=9.2989
  Layer 3: LB min=-12.1520, max=21.8531 | UB min=-4.4556, max=34.8410
  Layer 4: LB min=-10.0882, max=22.3647 | UB min=0.8086, max=32.6360
  Layer 5: LB min=-7.4252, max=32.8259 | UB min=3.1234, max=43.0646
  Layer 6: LB min=2.8781, max=18.4236 | UB min=16.4517, max=32.6360
  Layer 7: LB min=-4.8544, max=-4.8544 | UB min=7.0556, max=7.0556
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03090667724609375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02710270881652832
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010721683502197266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0015368461608886719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012204647064208984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011947154998779297

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.6640, max=4.1970 | UB min=-0.3173, max=5.4817
  Layer 2: LB min=0.0000, max=6.3192 | UB min=1.7302, max=8.3655
  Layer 3: LB min=-10.1105, max=14.0155 | UB min=-6.3464, max=20.5519
  Layer 4: LB min=-7.2819, max=14.8756 | UB min=-2.3953, max=19.3662
  Layer 5: LB min=-5.2463, max=24.1411 | UB min=-0.5392, max=29.0911
  Layer 6: LB min=5.5700, max=11.9087 | UB min=11.2032, max=18.9647
  Layer 7: LB min=-0.0407, max=-0.0407 | UB min=4.9093, max=4.9093
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.011089801788330078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01129770278930664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0028023719787597656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014629364013671875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0017437934875488281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018253326416015625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.4922, max=4.4845 | UB min=-0.7407, max=5.2014
  Layer 2: LB min=0.2379, max=6.7968 | UB min=1.2875, max=7.9176
  Layer 3: LB min=-9.1588, max=8.4363 | UB min=-7.1653, max=11.9684
  Layer 4: LB min=-5.9765, max=10.5813 | UB min=-3.2874, max=13.2527
  Layer 5: LB min=-4.3982, max=18.1426 | UB min=-1.8927, max=20.8139
  Layer 6: LB min=6.8127, max=7.5407 | UB min=9.8749, max=11.4226
  Layer 7: LB min=1.2709, max=1.2709 | UB min=3.9423, max=3.9423
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0017778873443603516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009160041809082031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00103759765625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002159595489501953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014116764068603516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019507408142089844

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.5790, max=4.3407 | UB min=-0.5284, max=5.3428
  Layer 2: LB min=0.0357, max=6.5578 | UB min=1.5093, max=8.1434
  Layer 3: LB min=-9.6264, max=11.4374 | UB min=-6.7732, max=16.4458
  Layer 4: LB min=-6.6132, max=12.7915 | UB min=-2.8406, max=16.5832
  Layer 5: LB min=-4.7918, max=21.3260 | UB min=-1.2685, max=25.1177
  Layer 6: LB min=6.1971, max=10.0522 | UB min=10.5155, max=15.4926
  Layer 7: LB min=0.6363, max=0.6363 | UB min=4.4280, max=4.4280
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0015375614166259766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0009875297546386719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0009925365447998047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011696815490722656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012927055358886719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003945827484130859

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.6224, max=4.2688 | UB min=-0.4223, max=5.4134
  Layer 2: LB min=0.0000, max=6.4382 | UB min=1.6203, max=8.2563
  Layer 3: LB min=-9.8640, max=12.7521 | UB min=-6.5624, max=18.5153
  Layer 4: LB min=-6.9441, max=13.7762 | UB min=-2.6173, max=17.9764
  Layer 5: LB min=-4.9895, max=22.7471 | UB min=-0.9474, max=27.1122
  Layer 6: LB min=5.8835, max=11.0054 | UB min=10.8434, max=17.2450
  Layer 7: LB min=0.3058, max=0.3058 | UB min=4.6709, max=4.6709
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0024149417877197266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0007672309875488281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0007083415985107422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008718967437744141
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001148223876953125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012738704681396484

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.6432, max=4.2329 | UB min=-0.3698, max=5.4476
  Layer 2: LB min=0.0000, max=6.3787 | UB min=1.6753, max=8.3109
  Layer 3: LB min=-9.9871, max=13.3841 | UB min=-6.4544, max=19.5338
  Layer 4: LB min=-7.1129, max=14.3260 | UB min=-2.5063, max=18.6714
  Layer 5: LB min=-5.1190, max=23.4443 | UB min=-0.7460, max=28.1019
  Layer 6: LB min=5.7267, max=11.4573 | UB min=11.0232, max=18.1050
  Layer 7: LB min=0.1326, max=0.1326 | UB min=4.7901, max=4.7901
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.022724628448486328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030498266220092773
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016050338745117188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001032114028930664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011892318725585938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0036516189575195312

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.6536, max=4.2149 | UB min=-0.3436, max=5.4646
  Layer 2: LB min=0.0000, max=6.3490 | UB min=1.7027, max=8.3382
  Layer 3: LB min=-10.0488, max=13.6998 | UB min=-6.4004, max=20.0429
  Layer 4: LB min=-7.1974, max=14.6008 | UB min=-2.4508, max=19.0188
  Layer 5: LB min=-5.1834, max=23.7927 | UB min=-0.6426, max=28.5965
  Layer 6: LB min=5.6483, max=11.6830 | UB min=11.1131, max=18.5348
  Layer 7: LB min=0.0460, max=0.0460 | UB min=4.8497, max=4.8497
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0019028186798095703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.002170085906982422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002504110336303711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0028312206268310547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0035889148712158203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003887653350830078

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.6588, max=4.2060 | UB min=-0.3305, max=5.4732
  Layer 2: LB min=0.0000, max=6.3341 | UB min=1.7165, max=8.3518
  Layer 3: LB min=-10.0796, max=13.8577 | UB min=-6.3734, max=20.2974
  Layer 4: LB min=-7.2396, max=14.7382 | UB min=-2.4231, max=19.1925
  Layer 5: LB min=-5.2150, max=23.9669 | UB min=-0.5909, max=28.8438
  Layer 6: LB min=5.6091, max=11.7959 | UB min=11.1581, max=18.7497
  Layer 7: LB min=0.0026, max=0.0026 | UB min=4.8795, max=4.8795
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03155350685119629
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022920846939086914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001310110092163086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010449886322021484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004340648651123047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015323162078857422

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.6614, max=4.2015 | UB min=-0.3239, max=5.4774
  Layer 2: LB min=0.0000, max=6.3267 | UB min=1.7233, max=8.3586
  Layer 3: LB min=-10.0951, max=13.9366 | UB min=-6.3599, max=20.4246
  Layer 4: LB min=-7.2607, max=14.8069 | UB min=-2.4092, max=19.2793
  Layer 5: LB min=-5.2307, max=24.0540 | UB min=-0.5651, max=28.9674
  Layer 6: LB min=5.5896, max=11.8523 | UB min=11.1807, max=18.8572
  Layer 7: LB min=-0.0190, max=-0.0190 | UB min=4.8944, max=4.8944
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.012618541717529297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.013963460922241211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012195110321044922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010721683502197266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011286735534667969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001135110855102539

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-1.6588, max=4.2060 | UB min=-0.3305, max=5.4732
  Layer 2: LB min=0.0000, max=6.3341 | UB min=1.7165, max=8.3518
  Layer 3: LB min=-10.0796, max=13.8577 | UB min=-6.3734, max=20.2974
  Layer 4: LB min=-7.2396, max=14.7382 | UB min=-2.4231, max=19.1925
  Layer 5: LB min=-5.2150, max=23.9669 | UB min=-0.5909, max=28.8438
  Layer 6: LB min=5.6091, max=11.7959 | UB min=11.1581, max=18.7497
  Layer 7: LB min=0.0026, max=0.0026 | UB min=4.8795, max=4.8795
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.011263370513916016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0057103633880615234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.009763002395629883
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003323793411254883
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0030477046966552734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010418891906738281
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009737014770507812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0007572174072265625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010530948638916016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0009071826934814453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008838176727294922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010900497436523438
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.040419816970825195
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03477120399475098
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012698173522949219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012142658233642578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011594295501708984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017201900482177734
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04454445838928223
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022217273712158203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011477470397949219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011434555053710938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010995864868164062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001291513442993164
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.017319679260253906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01754164695739746
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013685226440429688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003542184829711914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0017993450164794922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.006445884704589844
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03563213348388672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026600360870361328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016031265258789062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004612445831298828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009419918060302734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0009248256683349609
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029607772827148438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015508174896240234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011057853698730469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012488365173339844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013837814331054688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001340627670288086
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03696274757385254
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03254508972167969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011289119720458984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010039806365966797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013511180877685547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012662410736083984
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.013408184051513672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.009042024612426758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014379024505615234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011794567108154297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004411458969116211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001371145248413086
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.009349584579467773
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.006712198257446289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.005074739456176758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.008920431137084961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002337217330932617
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011336803436279297
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04716658592224121
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.027652502059936523
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001299142837524414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001222848892211914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011942386627197266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001958131790161133
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.014289140701293945
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.014958620071411133
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012209415435791016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004160165786743164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013344287872314453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014145374298095703
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01258540153503418
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02297496795654297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013630390167236328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010991096496582031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011112689971923828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0018229484558105469
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.00883936882019043
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.004324197769165039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010652542114257812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001177072525024414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011038780212402344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010955333709716797
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03948354721069336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.042664289474487305
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0018701553344726562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003584623336791992
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001157522201538086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013308525085449219
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Early stopping
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.017410755157470703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.012495994567871094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001039743423461914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010972023010253906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012726783752441406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0062754154205322266

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-38.3102, max=0.0000 | UB min=0.0000, max=53.2436
  Layer 2: LB min=-59.2852, max=0.0000 | UB min=0.0000, max=91.6209
  Layer 3: LB min=-184.0658, max=222.8754 | UB min=105.3830, max=687.9152
  Layer 4: LB min=-264.6808, max=289.3677 | UB min=205.5924, max=667.9590
  Layer 5: LB min=-323.0827, max=364.3948 | UB min=270.2493, max=848.3746
  Layer 6: LB min=-137.4564, max=194.6707 | UB min=577.4047, max=667.9590
  Layer 7: LB min=-517.3615, max=-517.3615 | UB min=149.1763, max=149.1763
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02378082275390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.022545814514160156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00130462646484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011916160583496094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012233257293701172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013065338134765625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-19.8493, max=0.0000 | UB min=0.0000, max=28.0832
  Layer 2: LB min=-31.1102, max=0.0000 | UB min=0.0000, max=48.0161
  Layer 3: LB min=-94.8291, max=125.2130 | UB min=51.8727, max=360.4131
  Layer 4: LB min=-134.8715, max=158.2773 | UB min=103.7255, max=345.0502
  Layer 5: LB min=-165.2251, max=196.7739 | UB min=136.3773, max=438.2760
  Layer 6: LB min=-69.9412, max=109.6088 | UB min=293.4336, max=345.0502
  Layer 7: LB min=-256.9283, max=-256.9283 | UB min=75.7801, max=75.7801
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02540302276611328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.029225587844848633
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016083717346191406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010876655578613281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005995512008666992
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001537322998046875

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-10.5294, max=0.0000 | UB min=0.0000, max=15.4036
  Layer 2: LB min=-16.7666, max=0.0000 | UB min=0.0000, max=26.1284
  Layer 3: LB min=-48.1183, max=77.5617 | UB min=20.2301, max=193.3393
  Layer 4: LB min=-66.2424, max=94.9783 | UB min=48.7121, max=179.2903
  Layer 5: LB min=-82.2016, max=113.1621 | UB min=64.9401, max=228.6252
  Layer 6: LB min=-34.0418, max=68.4195 | UB min=144.2118, max=179.2903
  Layer 7: LB min=-119.5159, max=-119.5159 | UB min=37.7045, max=37.7045
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02915191650390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.014446496963500977
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002340078353881836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0047991275787353516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014753341674804688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014472007751464844

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-5.8314, max=2.6306 | UB min=0.0000, max=10.8932
  Layer 2: LB min=-9.9412, max=1.8594 | UB min=0.0000, max=16.4522
  Layer 3: LB min=-25.1084, max=46.3234 | UB min=4.1374, max=99.1430
  Layer 4: LB min=-30.4091, max=58.3065 | UB min=19.8480, max=93.7294
  Layer 5: LB min=-36.5649, max=63.1060 | UB min=28.7400, max=114.1632
  Layer 6: LB min=-10.5986, max=43.4696 | UB min=66.1513, max=93.5790
  Layer 7: LB min=-47.0942, max=-47.0942 | UB min=21.8111, max=21.8111
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027080535888671875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026177406311035156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012478828430175781
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004065990447998047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00136566162109375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001993894577026367

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-3.4788, max=4.4983 | UB min=0.0000, max=8.7418
  Layer 2: LB min=-6.6739, max=5.5619 | UB min=-0.0291, max=12.6387
  Layer 3: LB min=-14.3165, max=28.3483 | UB min=-3.3995, max=49.5689
  Layer 4: LB min=-13.3797, max=36.8094 | UB min=6.7932, max=50.4932
  Layer 5: LB min=-14.0534, max=34.1591 | UB min=11.6396, max=54.7408
  Layer 6: LB min=-2.0145, max=28.3483 | UB min=29.2022, max=49.5689
  Layer 7: LB min=-13.6636, max=-13.6636 | UB min=12.2498, max=12.2498
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01872849464416504
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.024631738662719727
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012857913970947266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010976791381835938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0020246505737304688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014243125915527344

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.2989, max=5.4338 | UB min=-0.0993, max=7.6542
  Layer 2: LB min=-5.1688, max=7.4849 | UB min=-2.0197, max=10.9541
  Layer 3: LB min=-10.9301, max=17.2856 | UB min=-6.6606, max=27.2662
  Layer 4: LB min=-6.4419, max=23.3835 | UB min=2.3653, max=29.3965
  Layer 5: LB min=-4.5615, max=17.6050 | UB min=5.3207, max=27.2662
  Layer 6: LB min=3.0004, max=17.2856 | UB min=14.5933, max=27.2662
  Layer 7: LB min=-1.4447, max=-1.4447 | UB min=7.4946, max=7.4946
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0023164749145507812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.002607583999633789
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008594989776611328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001062631607055664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.000985860824584961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011091232299804688

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.8906, max=4.9656 | UB min=0.0000, max=8.2039
  Layer 2: LB min=-5.9100, max=6.5281 | UB min=-1.0415, max=11.7780
  Layer 3: LB min=-12.4369, max=23.1369 | UB min=-5.1656, max=38.5598
  Layer 4: LB min=-9.7991, max=30.3561 | UB min=4.4996, max=40.1094
  Layer 5: LB min=-9.2595, max=25.9474 | UB min=8.3699, max=39.8222
  Layer 6: LB min=-0.0485, max=23.1369 | UB min=21.7002, max=38.5598
  Layer 7: LB min=-7.0111, max=-7.0111 | UB min=10.0169, max=10.0169
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03723454475402832
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.040715694427490234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00128173828125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011882781982421875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012392997741699219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011637210845947266

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.5965, max=5.1992 | UB min=0.0000, max=7.9329
  Layer 2: LB min=-5.5344, max=7.0108 | UB min=-1.5347, max=11.3568
  Layer 3: LB min=-11.6375, max=20.2180 | UB min=-5.9251, max=32.8954
  Layer 4: LB min=-8.0951, max=26.8578 | UB min=3.3957, max=34.7139
  Layer 5: LB min=-6.8784, max=21.6631 | UB min=6.7949, max=32.8954
  Layer 6: LB min=0.8295, max=20.2180 | UB min=18.0756, max=32.8954
  Layer 7: LB min=-4.1311, max=-4.1311 | UB min=9.0773, max=9.0773
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02840709686279297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.011784076690673828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0015215873718261719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001096487045288086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005723476409912109
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015702247619628906

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7436, max=5.0824 | UB min=0.0000, max=8.0687
  Layer 2: LB min=-5.7223, max=6.7695 | UB min=-1.2881, max=11.5678
  Layer 3: LB min=-12.0365, max=21.7451 | UB min=-5.5453, max=35.7953
  Layer 4: LB min=-8.9553, max=28.6586 | UB min=3.9478, max=37.4634
  Layer 5: LB min=-8.0829, max=23.8065 | UB min=7.5794, max=36.1148
  Layer 6: LB min=0.3907, max=21.7451 | UB min=19.8903, max=35.7953
  Layer 7: LB min=-5.5641, max=-5.5641 | UB min=9.5547, max=9.5547
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.026107311248779297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015380859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0053403377532958984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012903213500976562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00125885009765625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003094911575317383

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.6701, max=5.1408 | UB min=0.0000, max=8.0008
  Layer 2: LB min=-5.6283, max=6.8902 | UB min=-1.4114, max=11.4623
  Layer 3: LB min=-11.8363, max=20.9816 | UB min=-5.7352, max=34.3452
  Layer 4: LB min=-8.5271, max=27.7582 | UB min=3.6715, max=36.0885
  Layer 5: LB min=-7.4805, max=22.7349 | UB min=7.1862, max=34.3452
  Layer 6: LB min=0.6102, max=20.9816 | UB min=18.9821, max=34.3452
  Layer 7: LB min=-4.8465, max=-4.8465 | UB min=9.3202, max=9.3202
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029643535614013672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.024243593215942383
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0028944015502929688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.012145757675170898
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0038940906524658203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003988504409790039

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7068, max=5.1116 | UB min=0.0000, max=8.0348
  Layer 2: LB min=-5.6753, max=6.8298 | UB min=-1.3498, max=11.5151
  Layer 3: LB min=-11.9363, max=21.3634 | UB min=-5.6402, max=35.0702
  Layer 4: LB min=-8.7416, max=28.2084 | UB min=3.8097, max=36.7759
  Layer 5: LB min=-7.7817, max=23.2707 | UB min=7.3827, max=35.1878
  Layer 6: LB min=0.5005, max=21.3634 | UB min=19.4361, max=35.0702
  Layer 7: LB min=-5.2051, max=-5.2051 | UB min=9.4384, max=9.4384
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029604673385620117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030290603637695312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012133121490478516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0036478042602539062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001312255859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013728141784667969

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7252, max=5.0970 | UB min=0.0000, max=8.0517
  Layer 2: LB min=-5.6988, max=6.7996 | UB min=-1.3189, max=11.5415
  Layer 3: LB min=-11.9864, max=21.5542 | UB min=-5.5928, max=35.4327
  Layer 4: LB min=-8.8486, max=28.4335 | UB min=3.8787, max=37.1196
  Layer 5: LB min=-7.9323, max=23.5386 | UB min=7.4809, max=35.6512
  Layer 6: LB min=0.4456, max=21.5542 | UB min=19.6631, max=35.4327
  Layer 7: LB min=-5.3845, max=-5.3845 | UB min=9.4968, max=9.4968
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028614282608032227
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0233156681060791
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003558635711669922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001428365707397461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.008958101272583008
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0042459964752197266

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7344, max=5.0897 | UB min=0.0000, max=8.0602
  Layer 2: LB min=-5.7105, max=6.7846 | UB min=-1.3035, max=11.5547
  Layer 3: LB min=-12.0114, max=21.6496 | UB min=-5.5690, max=35.6140
  Layer 4: LB min=-8.9020, max=28.5461 | UB min=3.9133, max=37.2915
  Layer 5: LB min=-8.0076, max=23.6726 | UB min=7.5301, max=35.8830
  Layer 6: LB min=0.4181, max=21.6496 | UB min=19.7767, max=35.6140
  Layer 7: LB min=-5.4743, max=-5.4743 | UB min=9.5258, max=9.5258
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03298330307006836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02764105796813965
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011982917785644531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011947154998779297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0029561519622802734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012936592102050781

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7390, max=5.0861 | UB min=0.0000, max=8.0645
  Layer 2: LB min=-5.7164, max=6.7770 | UB min=-1.2958, max=11.5612
  Layer 3: LB min=-12.0240, max=21.6974 | UB min=-5.5572, max=35.7047
  Layer 4: LB min=-8.9286, max=28.6024 | UB min=3.9306, max=37.3775
  Layer 5: LB min=-8.0453, max=23.7396 | UB min=7.5547, max=35.9989
  Layer 6: LB min=0.4044, max=21.6974 | UB min=19.8335, max=35.7047
  Layer 7: LB min=-5.5192, max=-5.5192 | UB min=9.5402, max=9.5402
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.00795602798461914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.016638994216918945
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.005246400833129883
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.005029439926147461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002462625503540039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013451576232910156

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-2.7344, max=5.0897 | UB min=0.0000, max=8.0602
  Layer 2: LB min=-5.7105, max=6.7846 | UB min=-1.3035, max=11.5547
  Layer 3: LB min=-12.0114, max=21.6496 | UB min=-5.5690, max=35.6140
  Layer 4: LB min=-8.9020, max=28.5461 | UB min=3.9133, max=37.2915
  Layer 5: LB min=-8.0076, max=23.6726 | UB min=7.5301, max=35.8830
  Layer 6: LB min=0.4181, max=21.6496 | UB min=19.7767, max=35.6140
  Layer 7: LB min=-5.4743, max=-5.4743 | UB min=9.5258, max=9.5258
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04500579833984375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.009690523147583008
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011861324310302734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011386871337890625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003610372543334961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001711130142211914
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027692079544067383
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028763771057128906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014362335205078125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0026848316192626953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012023448944091797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0038709640502929688
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02653670310974121
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.008467674255371094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001070261001586914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010592937469482422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001188516616821289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012454986572265625
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.019830703735351562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01789569854736328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0025482177734375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011632442474365234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012462139129638672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016477108001708984
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03630805015563965
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03185319900512695
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011532306671142578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0038254261016845703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.00122833251953125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004080057144165039
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0397028923034668
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01757669448852539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011501312255859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011484622955322266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0019643306732177734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013017654418945312
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04933762550354004
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02836322784423828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012738704681396484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011456012725830078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.003771543502807617
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003660440444946289
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03415560722351074
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02702641487121582
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012183189392089844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014719963073730469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0027709007263183594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003913164138793945
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.030736207962036133
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03003096580505371
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002644777297973633
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012061595916748047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013470649719238281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.00396728515625
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04673504829406738
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.033824920654296875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010657310485839844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012581348419189453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011353492736816406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.009758949279785156
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.019563913345336914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023418188095092773
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011985301971435547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010941028594970703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004853725433349609
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013434886932373047
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03187751770019531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019870758056640625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010464191436767578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.004350185394287109
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013518333435058594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004563808441162109
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0299837589263916
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.023271560668945312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011396408081054688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0029082298278808594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014257431030273438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.002290010452270508
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03045344352722168
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04262375831604004
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012273788452148438
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011398792266845703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013227462768554688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.003813505172729492
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03029012680053711
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.025580883026123047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012691020965576172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010411739349365234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004419803619384766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012755393981933594
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Loading ONNX model...
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.01737380027770996
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01352834701538086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012602806091308594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011827945709228516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011703968048095703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017426013946533203

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-40.2063, max=0.0000 | UB min=0.0000, max=53.5448
  Layer 2: LB min=-59.5554, max=0.0000 | UB min=0.0000, max=89.8729
  Layer 3: LB min=-185.0657, max=220.4690 | UB min=104.4848, max=685.4364
  Layer 4: LB min=-264.7758, max=286.2012 | UB min=205.3116, max=662.1421
  Layer 5: LB min=-322.4523, max=362.1617 | UB min=270.5692, max=845.2559
  Layer 6: LB min=-137.2062, max=193.5975 | UB min=575.4315, max=662.1421
  Layer 7: LB min=-517.2190, max=-517.2190 | UB min=148.4927, max=148.4927
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.023485660552978516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.015769481658935547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011076927185058594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0015063285827636719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002020597457885742
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0019519329071044922

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-22.7506, max=0.0000 | UB min=0.0000, max=28.6282
  Layer 2: LB min=-31.8592, max=0.0000 | UB min=0.0000, max=45.7347
  Layer 3: LB min=-95.4339, max=121.0818 | UB min=50.2443, max=356.6429
  Layer 4: LB min=-135.0135, max=153.9916 | UB min=103.3162, max=337.9113
  Layer 5: LB min=-164.2679, max=193.4771 | UB min=136.5278, max=433.9257
  Layer 6: LB min=-69.7048, max=107.8237 | UB min=290.9479, max=337.9113
  Layer 7: LB min=-256.8698, max=-256.8698 | UB min=74.5912, max=74.5912
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.011009454727172852
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.008860588073730469
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013442039489746094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.003313779830932617
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012903213500976562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013499259948730469

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-13.8697, max=0.0000 | UB min=0.0000, max=16.0104
  Layer 2: LB min=-17.5946, max=0.0000 | UB min=0.0000, max=24.8380
  Layer 3: LB min=-49.2527, max=72.2935 | UB min=21.7184, max=188.2845
  Layer 4: LB min=-65.8624, max=87.7463 | UB min=49.3013, max=171.0525
  Layer 5: LB min=-81.3536, max=108.5773 | UB min=65.2470, max=222.7577
  Layer 6: LB min=-34.1295, max=65.2554 | UB min=142.0735, max=170.7445
  Layer 7: LB min=-119.9898, max=-119.9898 | UB min=36.7899, max=36.7899
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.024225234985351562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.00499415397644043
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0008113384246826172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007600784301757812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008854866027832031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010781288146972656

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-9.4070, max=3.0929 | UB min=-0.5615, max=11.5034
  Layer 2: LB min=-10.3721, max=1.2966 | UB min=0.0000, max=15.5687
  Layer 3: LB min=-24.6693, max=44.1561 | UB min=4.6014, max=96.2277
  Layer 4: LB min=-27.1147, max=51.0454 | UB min=19.5125, max=85.4921
  Layer 5: LB min=-35.5148, max=61.2139 | UB min=27.1731, max=108.7256
  Layer 6: LB min=-13.5142, max=40.8253 | UB min=62.3183, max=85.1551
  Layer 7: LB min=-46.5211, max=-46.5211 | UB min=18.4848, max=18.4848
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0009946823120117188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0007419586181640625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0007343292236328125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0007522106170654297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0008151531219482422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001056671142578125

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-7.1648, max=4.9886 | UB min=-2.6482, max=9.2938
  Layer 2: LB min=-7.2872, max=4.4590 | UB min=-0.4531, max=11.7033
  Layer 3: LB min=-15.5328, max=24.6601 | UB min=-2.6373, max=47.6157
  Layer 4: LB min=-12.4593, max=29.8288 | UB min=7.3286, max=45.0821
  Layer 5: LB min=-16.4672, max=32.4727 | UB min=11.7786, max=53.0877
  Layer 6: LB min=-3.7812, max=24.6601 | UB min=30.1282, max=44.9126
  Layer 7: LB min=-15.5524, max=-15.5524 | UB min=11.8216, max=11.8216
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.018764972686767578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019383907318115234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012938976287841797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010018348693847656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011250972747802734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0028052330017089844

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.0438, max=5.9364 | UB min=-3.6916, max=8.1885
  Layer 2: LB min=-5.7700, max=6.1418 | UB min=-2.3032, max=9.9106
  Layer 3: LB min=-12.2653, max=14.5207 | UB min=-5.7422, max=24.8689
  Layer 4: LB min=-6.8883, max=17.7525 | UB min=2.7661, max=24.9386
  Layer 5: LB min=-8.2012, max=16.5053 | UB min=5.1009, max=25.9084
  Layer 6: LB min=0.3284, max=14.5207 | UB min=16.4650, max=24.8689
  Layer 7: LB min=-2.4593, max=-2.4593 | UB min=8.9572, max=8.9572
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.021075725555419922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04032444953918457
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002907276153564453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011780261993408203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004437446594238281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015060901641845703

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6043, max=5.4625 | UB min=-3.1699, max=8.7412
  Layer 2: LB min=-6.5390, max=5.3123 | UB min=-1.3633, max=10.8069
  Layer 3: LB min=-13.9304, max=19.5998 | UB min=-4.1975, max=35.1620
  Layer 4: LB min=-9.8215, max=23.7231 | UB min=5.0601, max=34.9920
  Layer 5: LB min=-12.3755, max=24.0013 | UB min=8.5558, max=39.0429
  Layer 6: LB min=-1.7557, max=19.5998 | UB min=23.3143, max=34.9033
  Layer 7: LB min=-8.9766, max=-8.9766 | UB min=10.5194, max=10.5194
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03182053565979004
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.025763988494873047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011911392211914062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011324882507324219
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0036766529083251953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013434886932373047

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.8846, max=5.2255 | UB min=-2.9091, max=9.0175
  Layer 2: LB min=-6.9147, max=4.8857 | UB min=-0.9070, max=11.2551
  Layer 3: LB min=-14.7329, max=22.1342 | UB min=-3.4177, max=41.3792
  Layer 4: LB min=-11.1703, max=26.7722 | UB min=6.2000, max=40.0318
  Layer 5: LB min=-14.4256, max=28.2287 | UB min=10.1890, max=46.0519
  Layer 6: LB min=-2.7722, max=22.1342 | UB min=26.7239, max=39.8972
  Layer 7: LB min=-12.2670, max=-12.2670 | UB min=11.1928, max=11.1928
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04283761978149414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.012265443801879883
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011522769927978516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013620853424072266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002167224884033203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014889240264892578

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.7445, max=5.3440 | UB min=-3.0395, max=8.8793
  Layer 2: LB min=-6.7273, max=5.0990 | UB min=-1.1348, max=11.0310
  Layer 3: LB min=-14.3325, max=20.8651 | UB min=-3.8073, max=38.2703
  Layer 4: LB min=-10.5182, max=25.2452 | UB min=5.6320, max=37.5139
  Layer 5: LB min=-13.4030, max=26.1107 | UB min=9.3836, max=42.5466
  Layer 6: LB min=-2.2658, max=20.8651 | UB min=25.0243, max=37.4001
  Layer 7: LB min=-10.6272, max=-10.6272 | UB min=10.8638, max=10.8638
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027122974395751953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030310392379760742
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012919902801513672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012102127075195312
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002591371536254883
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0049533843994140625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6744, max=5.4033 | UB min=-3.1047, max=8.8103
  Layer 2: LB min=-6.6333, max=5.2057 | UB min=-1.2490, max=10.9190
  Layer 3: LB min=-14.1317, max=20.2319 | UB min=-4.0023, max=36.7160
  Layer 4: LB min=-10.1700, max=24.4832 | UB min=5.3466, max=36.2529
  Layer 5: LB min=-12.8902, max=25.0549 | UB min=8.9711, max=40.7948
  Layer 6: LB min=-2.0117, max=20.2319 | UB min=24.1700, max=36.1517
  Layer 7: LB min=-9.8026, max=-9.8026 | UB min=10.6941, max=10.6941
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02924513816833496
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01981949806213379
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010106563568115234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002646207809448242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013620853424072266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.005495786666870117

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03473210334777832
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.041815996170043945
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012404918670654297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0017859935760498047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015416145324707031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012583732604980469

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6569, max=5.4181 | UB min=-3.1210, max=8.7930
  Layer 2: LB min=-6.6097, max=5.2324 | UB min=-1.2775, max=10.8909
  Layer 3: LB min=-14.0814, max=20.0738 | UB min=-4.0511, max=36.3275
  Layer 4: LB min=-10.0830, max=24.2930 | UB min=5.2751, max=35.9377
  Layer 5: LB min=-12.7617, max=24.7913 | UB min=8.8676, max=40.3567
  Layer 6: LB min=-1.9479, max=20.0738 | UB min=23.9562, max=35.8396
  Layer 7: LB min=-9.5962, max=-9.5962 | UB min=10.6508, max=10.6508
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03150510787963867
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04085826873779297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.003960609436035156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002872943878173828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012726783752441406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001363515853881836

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6481, max=5.4255 | UB min=-3.1292, max=8.7843
  Layer 2: LB min=-6.5980, max=5.2457 | UB min=-1.2918, max=10.8769
  Layer 3: LB min=-14.0563, max=19.9948 | UB min=-4.0755, max=36.1332
  Layer 4: LB min=-10.0394, max=24.1979 | UB min=5.2393, max=35.7801
  Layer 5: LB min=-12.6974, max=24.6595 | UB min=8.8158, max=40.1377
  Layer 6: LB min=-1.9159, max=19.9948 | UB min=23.8493, max=35.6836
  Layer 7: LB min=-9.4930, max=-9.4930 | UB min=10.6291, max=10.6291
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03253769874572754
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03182101249694824
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011525154113769531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001176595687866211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002526521682739258
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001550912857055664

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6437, max=5.4292 | UB min=-3.1332, max=8.7800
  Layer 2: LB min=-6.5921, max=5.2524 | UB min=-1.2990, max=10.8699
  Layer 3: LB min=-14.0437, max=19.9552 | UB min=-4.0877, max=36.0361
  Layer 4: LB min=-10.0176, max=24.1504 | UB min=5.2214, max=35.7013
  Layer 5: LB min=-12.6652, max=24.5937 | UB min=8.7898, max=40.0282
  Layer 6: LB min=-1.8999, max=19.9552 | UB min=23.7958, max=35.6055
  Layer 7: LB min=-9.4414, max=-9.4414 | UB min=10.6182, max=10.6182
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03138613700866699
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0173952579498291
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0016660690307617188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010173320770263672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011267662048339844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012967586517333984

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028186321258544922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01915121078491211
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012199878692626953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.00104522705078125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011920928955078125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011625289916992188
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.035989999771118164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02859044075012207
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.00208282470703125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001074075698852539
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012996196746826172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0028781890869140625
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04284024238586426
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030335664749145508
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011489391326904297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010645389556884766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.007342338562011719
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015316009521484375
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.016513347625732422
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01755237579345703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0007367134094238281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008726119995117188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0016317367553710938
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0017094612121582031
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.045583248138427734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03499126434326172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0017006397247314453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001049041748046875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011301040649414062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.008241891860961914
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02657485008239746
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03644514083862305
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010845661163330078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012054443359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012345314025878906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011363029479980469
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02483534812927246
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030777692794799805
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012714862823486328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0053441524505615234
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014243125915527344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001168966293334961
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0483551025390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.030725955963134766
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012226104736328125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011670589447021484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010807514190673828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012400150299072266
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0346989631652832
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0278017520904541
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011470317840576172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011196136474609375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0015189647674560547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001245260238647461
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028512239456176758
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03625369071960449
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011148452758789062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010416507720947266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010526180267333984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0042111873626708984
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0303647518157959
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.0406341552734375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011196136474609375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0020656585693359375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013096332550048828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016510486602783203
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.031047344207763672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.028393268585205078
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011889934539794922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001039743423461914
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005048274993896484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016841888427734375
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04133296012878418
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.04243803024291992
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011646747589111328
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011472702026367188
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011250972747802734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0024347305297851562
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02639460563659668
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.052855491638183594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014123916625976562
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001127481460571289
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001190185546875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001199960708618164
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.024666786193847656
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.019475221633911133
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010707378387451172
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012159347534179688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.005360603332519531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015912055969238281
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
 Found input where NAP improves robustness! at index 15 epsilons are  0.024901855468749998 and  0.0189263916015625
[INFO] Found NAP-exclusive robust input for label 1 at epsilon=0.0249
[INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02514028549194336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020741939544677734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010216236114501953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011718273162841797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0022809505462646484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010991096496582031

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Coarsening NAP:   0%|          | 0/20 [00:00<?, ?neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04069709777832031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02957010269165039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011591911315917969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011513233184814453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011925697326660156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0022826194763183594

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Coarsening NAP:   5%|5         | 1/20 [00:00<00:06,  2.96neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.029731273651123047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03766751289367676
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001323699951171875
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011975765228271484
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012962818145751953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001306772232055664

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Coarsening NAP:  10%|#         | 2/20 [00:00<00:05,  3.25neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03098130226135254
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.026169300079345703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0019042491912841797
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0012373924255371094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013365745544433594
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001917123794555664

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Coarsening NAP:  15%|#5        | 3/20 [00:00<00:05,  3.33neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.0463404655456543
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03904294967651367
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001216888427734375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011792182922363281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011403560638427734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.004073381423950195

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Coarsening NAP:  20%|##        | 4/20 [00:01<00:04,  3.32neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03245067596435547
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03173375129699707
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013599395751953125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011048316955566406
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.002731800079345703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015475749969482422

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Coarsening NAP:  25%|##5       | 5/20 [00:01<00:04,  3.45neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02834796905517578
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.012773752212524414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010406970977783203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013227462768554688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0017905235290527344
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0014071464538574219

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Coarsening NAP:  30%|###       | 6/20 [00:01<00:03,  3.55neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.02951192855834961
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.01629781723022461
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012285709381103516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0014269351959228516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0031425952911376953
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013909339904785156

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Coarsening NAP:  35%|###5      | 7/20 [00:02<00:03,  3.48neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04022574424743652
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03139781951904297
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012030601501464844
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011916160583496094
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011568069458007812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0037026405334472656

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Coarsening NAP:  40%|####      | 8/20 [00:02<00:03,  3.39neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.022866010665893555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.017827749252319336
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.001068115234375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.002320528030395508
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0013353824615478516
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012862682342529297

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Coarsening NAP:  45%|####5     | 9/20 [00:02<00:03,  3.37neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.027564525604248047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.020291805267333984
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0012521743774414062
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011603832244873047
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.004842042922973633
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0015676021575927734

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 0
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Coarsening NAP:  50%|#####     | 10/20 [00:02<00:02,  3.39neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04118967056274414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.014498233795166016
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0013012886047363281
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011286735534667969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0027589797973632812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016143321990966797

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 1
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[Coarsening] Neuron (1,0) coarsened successfully.
Coarsening NAP:  55%|#####5    | 11/20 [00:03<00:02,  3.69neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04268980026245117
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.025152921676635742
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014841556549072266
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0051326751708984375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001310110092163086
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0013127326965332031

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 2
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[Coarsening] Neuron (1,1) coarsened successfully.
Coarsening NAP:  60%|######    | 12/20 [00:03<00:02,  3.86neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03011155128479004
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.016422748565673828
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011548995971679688
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0010406970977783203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0019197463989257812
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010929107666015625

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 3
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[Coarsening] Neuron (1,2) coarsened successfully.
Coarsening NAP:  65%|######5   | 13/20 [00:03<00:01,  4.16neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.036942481994628906
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03391122817993164
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0031185150146484375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008692741394042969
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0010776519775390625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001135110855102539

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 4
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[Coarsening] Neuron (1,3) coarsened successfully.
Coarsening NAP:  70%|#######   | 14/20 [00:03<00:01,  4.15neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.042707204818725586
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03557634353637695
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.002191781997680664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.000850677490234375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0009491443634033203
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0023682117462158203

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 5
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[Coarsening] Neuron (1,4) coarsened successfully.
Coarsening NAP:  75%|#######5  | 15/20 [00:04<00:01,  4.20neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.028345823287963867
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03670644760131836
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0011513233184814453
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0013751983642578125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0014286041259765625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0011742115020751953

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 6
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[Coarsening] Neuron (1,5) coarsened successfully.
Coarsening NAP:  80%|########  | 16/20 [00:04<00:00,  4.20neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.04912877082824707
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03429245948791504
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.000997781753540039
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0008854866027832031
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0011467933654785156
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0010759830474853516

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 7
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
[Coarsening] Neuron (1,6) coarsened successfully.
Coarsening NAP:  85%|########5 | 17/20 [00:04<00:00,  4.27neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.017538785934448242
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.016925573348999023
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0014576911926269531
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.0011126995086669922
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0012004375457763672
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.001302957534790039

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
    [Inactive neuron in Nap] Layer 2, Neuron 8
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[Coarsening] Neuron (1,7) coarsened successfully.
Coarsening NAP:  90%|######### | 18/20 [00:04<00:00,  4.40neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.03211212158203125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.03063225746154785
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0010793209075927734
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001215219497680664
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.001970529556274414
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0016808509826660156

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
    [ACTive neuron in Nap] Layer 2, Neuron 9
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[Coarsening] Neuron (1,8) coarsened successfully.
Coarsening NAP:  95%|#########5| 19/20 [00:04<00:00,  4.32neuron/s][INFO] Loading ONNX model from tools/mnist-10x2.onnx
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 3: 0.042946577072143555
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 5: 0.02719593048095703
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 7: 0.0046100616455078125
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 9: 0.001247406005859375
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 11: 0.0025272369384765625
<class 'plnn.proxlp_solver.propagation.Propagation'> Time used for layer 13: 0.0012824535369873047

[DEBUG] Layer-wise bound shapes BEFORE NAP:
  Layer 0: LB shape = torch.Size([1, 784]), UB shape = torch.Size([1, 784])
  Layer 1: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 2: LB shape = torch.Size([1, 10]), UB shape = torch.Size([1, 10])
  Layer 3: LB shape = torch.Size([1, 9]), UB shape = torch.Size([1, 9])
  Layer 4: LB shape = torch.Size([1, 5]), UB shape = torch.Size([1, 5])
  Layer 5: LB shape = torch.Size([1, 3]), UB shape = torch.Size([1, 3])
  Layer 6: LB shape = torch.Size([1, 2]), UB shape = torch.Size([1, 2])
  Layer 7: LB shape = torch.Size([1, 1]), UB shape = torch.Size([1, 1])
[DEBUG] Total bound layers: 8 (includes input and output)
[DEBUG] Intermidiate Layer 1: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 0
[DEBUG] Now working on the 1 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 1
[DEBUG] Now working on the 2 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 2
[DEBUG] Now working on the 3 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 3
[DEBUG] Now working on the 4 th neuron of 1 th relu layer 
    [Inactive neuron in Nap] Layer 1, Neuron 4
[DEBUG] Now working on the 5 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 5
[DEBUG] Now working on the 6 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 6
[DEBUG] Now working on the 7 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 7
[DEBUG] Now working on the 8 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 8
[DEBUG] Now working on the 9 th neuron of 1 th relu layer 
    [ACTive neuron in Nap] Layer 1, Neuron 9
[DEBUG] Intermidiate Layer 2: NAP length = 10, Bounds neurons = 10
[DEBUG] Now working on the 0 th neuron of 2 th relu layer 
[DEBUG] Now working on the 1 th neuron of 2 th relu layer 
[DEBUG] Now working on the 2 th neuron of 2 th relu layer 
[DEBUG] Now working on the 3 th neuron of 2 th relu layer 
[DEBUG] Now working on the 4 th neuron of 2 th relu layer 
[DEBUG] Now working on the 5 th neuron of 2 th relu layer 
[DEBUG] Now working on the 6 th neuron of 2 th relu layer 
[DEBUG] Now working on the 7 th neuron of 2 th relu layer 
[DEBUG] Now working on the 8 th neuron of 2 th relu layer 
[DEBUG] Now working on the 9 th neuron of 2 th relu layer 
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.
NAP update only for inner bounds, skipping because this is either an  output or/an extra verif layer.

[DEBUG] Layer-wise bounds AFTER applying NAP:
  Layer 0: LB min=-1.0000, max=-1.0000 | UB min=1.0000, max=1.0000
  Layer 1: LB min=-6.6393, max=5.4329 | UB min=-3.1373, max=8.7757
  Layer 2: LB min=-6.5862, max=5.2590 | UB min=-1.3061, max=10.8629
  Layer 3: LB min=-14.0311, max=19.9157 | UB min=-4.0999, max=35.9390
  Layer 4: LB min=-9.9958, max=24.1029 | UB min=5.2035, max=35.6224
  Layer 5: LB min=-12.6331, max=24.5278 | UB min=8.7639, max=39.9187
  Layer 6: LB min=-1.8840, max=19.9157 | UB min=23.7423, max=35.5275
  Layer 7: LB min=-9.3898, max=-9.3898 | UB min=10.6073, max=10.6073
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2684372
Academic license 2684372 - for non-commercial use only - registered to sa___@bordeaux-inp.fr
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Warning: environment still referenced so free is deferred (Continue to use WLS)
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
Running Nb states visited: 0.0
[Coarsening] Neuron (1,9) coarsened successfully.
Coarsening NAP: 100%|##########| 20/20 [00:05<00:00,  2.99neuron/s]Coarsening NAP: 100%|##########| 20/20 [00:05<00:00,  3.59neuron/s]
